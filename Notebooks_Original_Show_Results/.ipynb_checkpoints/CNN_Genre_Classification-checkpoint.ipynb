{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Train the CNN Genre Classification Model#\n",
        "# Last editted by Pu Zeng, 18/10/2023 #"
      ],
      "metadata": {
        "id": "8mur3UKLoExH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "# import mido\n",
        "import string\n",
        "import numpy as np\n",
        "# from utilis import get_pianoroll_data\n",
        "import pickle\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "# import mido\n",
        "import string\n",
        "import numpy as np\n",
        "# from utilis import get_pianoroll_data\n",
        "import pickle\n",
        "from sklearn import preprocessing\n",
        "import torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #Define device\n",
        "file_dir = \"/content/drive/MyDrive/Milestone 2/\" #Please change"
      ],
      "metadata": {
        "id": "u8eSS9tg62ge"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Processing\n",
        "\n",
        "from tqdm import tqdm\n",
        "X = []\n",
        "y = []\n",
        "for i in tqdm(range(1,10)):\n",
        "    file=open(file_dir+\"music_data\"+str(i)+\".bin\",\"rb\")\n",
        "    music_data = pickle.load(file) #保存list到文件\n",
        "    file.close()\n",
        "    for m in music_data:\n",
        "        if m[2].shape[0]>=1012:\n",
        "            X.append(m[2][500:1012,:])\n",
        "            y.append(m[0])\n",
        "X = np.array(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5ONeVUU7MOU",
        "outputId": "1b1d9ede-50db-493f-8cee-7f8c48ec3f6e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [01:12<00:00,  8.08s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save Processed Data\n",
        "\n",
        "# import pickle\n",
        "# file=open('data','wb')\n",
        "# pickle.dump([X,y], file)\n",
        "# file.close()"
      ],
      "metadata": {
        "id": "e5XascvXafa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Processed Data\n",
        "\n",
        "# import pickle\n",
        "# file=open('data','rb')\n",
        "# X,y = pickle.load(file)\n",
        "# file.close()"
      ],
      "metadata": {
        "id": "NhqJDo0qaomB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform labels into one-hot variables\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "label_dict = {}\n",
        "for cl in le.classes_:\n",
        "    label_dict.update({cl:le.transform([cl])[0]})"
      ],
      "metadata": {
        "id": "vxgTDpaxfTGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, hiddenSize, outChannels, dropoutRate, activate):\n",
        "        super().__init__()\n",
        "        self.outChannels = outChannels\n",
        "        self.activate = nn.Sigmoid() if activate == \"Sigmoid\" else nn.ReLU()\n",
        "        self.conv1 = nn.Conv2d(1, 24, (10,1))\n",
        "        self.pool = nn.MaxPool2d((2, 1))\n",
        "        self.conv2 = nn.Conv2d(24, 48, (10,1))\n",
        "        self.conv3 = nn.Conv2d(48, 96, (10,1))\n",
        "        self.conv4 = nn.Conv2d(96, 192, (10,1))\n",
        "        self.conv5 = nn.Conv2d(192, 192, (10,2))\n",
        "        self.dense1 = nn.Linear(10668*16, hiddenSize)\n",
        "        self.dropout = nn.Dropout(dropoutRate)\n",
        "        self.dense2 = nn.Linear(hiddenSize, 18)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.activate(self.conv1(x)))\n",
        "        x = self.pool(self.activate(self.conv2(x)))\n",
        "        # print(x.shape)\n",
        "        x = self.dropout(self.pool(self.activate(self.conv3(x))))\n",
        "        x = self.pool(self.activate(self.conv4(x)))\n",
        "        x = self.pool(self.activate(self.conv5(x)))\n",
        "        # print(x.shape)\n",
        "        x = x.view(-1, 10668*16)\n",
        "        x = self.dropout(self.activate(self.dense1(x)))\n",
        "        return self.dense2(x)\n",
        "\n",
        "# Number of neurons in the first fully-connected layer\n",
        "hiddenSize = 300\n",
        "# Number of feature filters in second convolutional layer\n",
        "numFilters = 25\n",
        "# Dropout rate\n",
        "dropoutRate = 0.3\n",
        "# Activation function\n",
        "activation = \"ReLU\"\n",
        "# Learning rate\n",
        "learningRate = 0.001\n",
        "# Momentum for SGD optimizer\n",
        "momentum = 0.9\n",
        "# Number of training epochs\n",
        "numEpochs = 50"
      ],
      "metadata": {
        "id": "rds7kBErIyiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Validation function\n",
        "\n",
        "from tqdm import tqdm\n",
        "def train_epoch(cnn,device,dataloader,loss_fn,optimizer):\n",
        "    cnn.train()\n",
        "    cnnRunningLoss = 0\n",
        "    total = 0\n",
        "    R2 = 0\n",
        "    cnnCorrect=0\n",
        "    total1=0\n",
        "    for i, (inputs, labels) in enumerate(dataloader, 0):\n",
        "        optimizer.zero_grad()\n",
        "        inputs = inputs.to(device).reshape(-1,1,512,128) # Transform the input shape\n",
        "\n",
        "        labels = labels.to(device)\n",
        "        # Forward propagation\n",
        "        cnnOutputs = cnn(inputs)\n",
        "        # print(cnnOutputs.shape)\n",
        "        l2_lambda = 0.05\n",
        "        l2_reg = torch.tensor(0.).to(device)\n",
        "        for param in cnn.parameters():\n",
        "            l2_reg += torch.norm(param)\n",
        "        # Backpropagation\n",
        "        cnnLoss = criterion(cnnOutputs, labels)+l2_reg*l2_lambda\n",
        "        cnnLoss.backward()\n",
        "        # Gradient update\n",
        "        optimizer.step()\n",
        "        total += 1\n",
        "        total1+=labels.size(0)\n",
        "        cnnRunningLoss += cnnLoss.item()\n",
        "        _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n",
        "        cnnCorrect += (cnnPredicted == labels).sum().item()\n",
        "    return cnnRunningLoss/total, cnnCorrect/total1\n",
        "\n",
        "def valid_epoch(cnn,device,dataloader,loss_fn):\n",
        "    cnn.eval()\n",
        "    totalLoss = 0\n",
        "    total = 0\n",
        "    total1 = 0\n",
        "    R2 = 0\n",
        "    cnnLoss = 0\n",
        "    cnnCorrect=0\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs = inputs.to(device).reshape(-1,1,512,128)\n",
        "        labels = labels.to(device)\n",
        "        cnnOutputs = cnn(inputs)\n",
        "        cnnLoss = criterion(cnnOutputs, labels)\n",
        "        _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        total1 +=1\n",
        "        totalLoss += cnnLoss.item()\n",
        "        cnnCorrect += (cnnPredicted == labels).sum().item()\n",
        "    accuracy = cnnCorrect / total\n",
        "    cnn.train()\n",
        "    return totalLoss/total1, accuracy"
      ],
      "metadata": {
        "id": "GlsfudU0Z0R6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "X_train_v, X_test, y_train_v, y_test = train_test_split(X, y, test_size=0.2, random_state=99, stratify=y) #First split, so there is no data leakage problems\n",
        "\n",
        "# Transform data into DataSet\n",
        "X_train_v = torch.as_tensor(X_train_v, dtype=torch.float) # an alternative to torch.from_numpy\n",
        "y_train_v = torch.as_tensor(y_train_v, dtype=torch.float)\n",
        "X_test = torch.as_tensor(X_test, dtype=torch.float)\n",
        "y_test = torch.as_tensor(y_test, dtype=torch.float)\n",
        "splits=StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
        "train_dataset = TensorDataset(X_train_v, y_train_v)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "batch_size=128\n",
        "models = []\n",
        "history = {'fold':[], 'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n",
        "\n",
        "#K-Fold validation\n",
        "for fold, (train_idx,val_idx) in enumerate(splits.split(X_train_v,y_train_v)):\n",
        "    print('Fold {}'.format(fold + 1))\n",
        "    t = pd.DataFrame(y_train_v[train_idx], columns = ['class']).reset_index()\n",
        "    idx = []\n",
        "\n",
        "    #Resampling to solve the unbalanced problem\n",
        "    y_train = []\n",
        "    for i in range(0,18):\n",
        "        if i!=label_dict['Unknown']:\n",
        "          idx += list(t[t['class']==i].sample(500,replace=True)['index'])\n",
        "          y_train += [i]*500\n",
        "    X_train = X_train_v[train_idx][idx]\n",
        "\n",
        "    t = pd.DataFrame(y_train_v[val_idx], columns = ['class']).reset_index()\n",
        "    idx = []\n",
        "    y_val = []\n",
        "    for i in range(0,18):\n",
        "        if i!=label_dict['Unknown']:\n",
        "          idx += list(t[t['class']==i].sample(20,replace=True)['index'])\n",
        "          y_val += [i]*20\n",
        "    X_val =  X_train_v[val_idx][idx]\n",
        "\n",
        "    X_train = torch.as_tensor(X_train, dtype=torch.float) # an alternative to torch.from_numpy\n",
        "    y_train = torch.as_tensor(y_train, dtype=torch.float).type(torch.LongTensor)\n",
        "    X_val = torch.as_tensor(X_val, dtype=torch.float)\n",
        "    y_val = torch.as_tensor(y_val, dtype=torch.float).type(torch.LongTensor)\n",
        "\n",
        "    train_dataset = TensorDataset(X_train, y_train)\n",
        "    test_dataset = TensorDataset(X_val, y_val)\n",
        "\n",
        "    from torch.utils.data import Dataset, DataLoader\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    model = CNNModel(hiddenSize, numFilters, dropoutRate, activation).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(list(model.parameters()), lr=learningRate, momentum=momentum)\n",
        "    # optimizer = torch.optim.Adam(list(model.parameters()), lr=learningRate)\n",
        "    best_test = -np.inf\n",
        "    best_model = None # Save the best model\n",
        "    #Train the model\n",
        "    for epoch in range(numEpochs):\n",
        "        train_loss, train_R2=train_epoch(model,device,train_dataloader,criterion,optimizer)\n",
        "        test_loss, test_R2=valid_epoch(model,device,test_dataloader,criterion)\n",
        "        history['fold'].append(fold)\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['test_loss'].append(test_loss)\n",
        "        history['train_acc'].append(train_R2)\n",
        "        history['test_acc'].append(test_R2)\n",
        "        if test_R2>best_test:\n",
        "            test_test = test_R2\n",
        "            best_model = model\n",
        "        print('Train Loss: {}, Train_acc: {}, Test Loss: {}, Test acc: {}'.format(train_loss, train_R2, test_loss, test_R2))\n",
        "    models.append([best_model])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCEmiGU-Z85J",
        "outputId": "cf89fa52-78e9-4a8b-f786-832e5b5c5505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n",
            "Train Loss: 3.861480865263401, Train_acc: 0.4864705882352941, Test Loss: 2.5128855976191433, Test acc: 0.43823529411764706\n",
            "Train Loss: 2.7496522010717177, Train_acc: 0.812235294117647, Test Loss: 3.131469341841611, Test acc: 0.5352941176470588\n",
            "Train Loss: 2.438572135186733, Train_acc: 0.8868235294117647, Test Loss: 4.776198647238991, Test acc: 0.5441176470588235\n",
            "Train Loss: 2.3157789017024792, Train_acc: 0.9177647058823529, Test Loss: 4.31966681913896, Test acc: 0.5264705882352941\n",
            "Train Loss: 2.26237738580632, Train_acc: 0.9251764705882353, Test Loss: 3.218293466351249, Test acc: 0.55\n",
            "Train Loss: 2.1703900533511225, Train_acc: 0.9414117647058824, Test Loss: 4.002490975640037, Test acc: 0.5470588235294118\n",
            "Train Loss: 2.1041423826289356, Train_acc: 0.9487058823529412, Test Loss: 3.7289541092785923, Test acc: 0.5470588235294118\n",
            "Train Loss: 2.0590977122012832, Train_acc: 0.9518823529411765, Test Loss: 4.195340562950481, Test acc: 0.5529411764705883\n",
            "Train Loss: 2.0290077503462483, Train_acc: 0.9510588235294117, Test Loss: 4.320520520210266, Test acc: 0.55\n",
            "Train Loss: 1.9918130183578433, Train_acc: 0.9541176470588235, Test Loss: 3.7982361723076212, Test acc: 0.5441176470588235\n",
            "Train Loss: 1.969593005969112, Train_acc: 0.9558823529411765, Test Loss: 4.536852782422846, Test acc: 0.5411764705882353\n",
            "Train Loss: 1.932746666714661, Train_acc: 0.9527058823529412, Test Loss: 3.4138734232295644, Test acc: 0.5441176470588235\n",
            "Train Loss: 1.8851166156897867, Train_acc: 0.9554117647058824, Test Loss: 3.7635569138960405, Test acc: 0.5441176470588235\n",
            "Train Loss: 1.8385288634694608, Train_acc: 0.9584705882352941, Test Loss: 4.10261889479377, Test acc: 0.5441176470588235\n",
            "Train Loss: 1.8241492379876905, Train_acc: 0.958, Test Loss: 3.6304139982570303, Test acc: 0.5323529411764706\n",
            "Train Loss: 1.7672742493170546, Train_acc: 0.9594117647058824, Test Loss: 4.45691976222125, Test acc: 0.5441176470588235\n",
            "Train Loss: 1.7400718165519542, Train_acc: 0.9587058823529412, Test Loss: 4.253215448422865, Test acc: 0.538235294117647\n",
            "Train Loss: 1.6877206057534182, Train_acc: 0.9609411764705882, Test Loss: 4.91992035779086, Test acc: 0.5294117647058824\n",
            "Train Loss: 1.660045665905888, Train_acc: 0.9611764705882353, Test Loss: 4.3848677277565, Test acc: 0.5470588235294118\n",
            "Train Loss: 1.6346160823241211, Train_acc: 0.9612941176470589, Test Loss: 4.8733105063438416, Test acc: 0.5441176470588235\n",
            "Train Loss: 1.618326517424189, Train_acc: 0.9583529411764706, Test Loss: 4.560106971047142, Test acc: 0.5441176470588235\n",
            "Train Loss: 1.5906297237353217, Train_acc: 0.9612941176470589, Test Loss: 4.103714856234464, Test acc: 0.5294117647058824\n",
            "Train Loss: 1.5592301514811981, Train_acc: 0.9627058823529412, Test Loss: 5.407755922187459, Test acc: 0.5441176470588235\n",
            "Train Loss: 1.5156810238845366, Train_acc: 0.9603529411764706, Test Loss: 5.272476207126271, Test acc: 0.5352941176470588\n",
            "Train Loss: 1.5092107389206277, Train_acc: 0.9574117647058824, Test Loss: 5.309727452018044, Test acc: 0.5441176470588235\n",
            "Train Loss: 1.4662170584936787, Train_acc: 0.9592941176470589, Test Loss: 4.715690412304618, Test acc: 0.5441176470588235\n",
            "Train Loss: 1.4478203309209723, Train_acc: 0.9608235294117647, Test Loss: 4.544540692459453, Test acc: 0.5470588235294118\n",
            "Train Loss: 1.4190288383261602, Train_acc: 0.9605882352941176, Test Loss: 4.249881386756897, Test acc: 0.5411764705882353\n",
            "Train Loss: 1.4036205191361277, Train_acc: 0.9596470588235294, Test Loss: 4.964053695852106, Test acc: 0.5411764705882353\n",
            "Train Loss: 1.3838105833620058, Train_acc: 0.959764705882353, Test Loss: 3.621233441612937, Test acc: 0.55\n",
            "Train Loss: 1.3487449902340882, Train_acc: 0.9609411764705882, Test Loss: 4.543118967251345, Test acc: 0.5470588235294118\n",
            "Train Loss: 1.310985216968938, Train_acc: 0.9627058823529412, Test Loss: 4.819602700796994, Test acc: 0.538235294117647\n",
            "Train Loss: 1.3100497749515045, Train_acc: 0.9584705882352941, Test Loss: 4.8894223462451585, Test acc: 0.5529411764705883\n",
            "Train Loss: 1.2825428278822648, Train_acc: 0.9624705882352941, Test Loss: 4.5332824262705715, Test acc: 0.5470588235294118\n",
            "Train Loss: 1.264174791655146, Train_acc: 0.961764705882353, Test Loss: 4.746723082932559, Test acc: 0.5470588235294118\n",
            "Train Loss: 1.2361020038002415, Train_acc: 0.9616470588235294, Test Loss: 3.9304650263352827, Test acc: 0.538235294117647\n",
            "Train Loss: 1.2406131315948372, Train_acc: 0.959764705882353, Test Loss: 4.255073522979563, Test acc: 0.5411764705882353\n",
            "Train Loss: 1.1853875827072258, Train_acc: 0.9638823529411765, Test Loss: 5.123474757779729, Test acc: 0.5411764705882353\n",
            "Train Loss: 1.1678009467913693, Train_acc: 0.9618823529411765, Test Loss: 5.110099424015392, Test acc: 0.5470588235294118\n",
            "Train Loss: 1.1447458072264391, Train_acc: 0.9622352941176471, Test Loss: 4.656488033858213, Test acc: 0.5411764705882353\n",
            "Train Loss: 1.1249334980222516, Train_acc: 0.9643529411764706, Test Loss: 4.524452545426109, Test acc: 0.5352941176470588\n",
            "Train Loss: 1.1174155614878003, Train_acc: 0.9622352941176471, Test Loss: 4.16451848636974, Test acc: 0.5411764705882353\n",
            "Train Loss: 1.111649656430223, Train_acc: 0.9601176470588235, Test Loss: 4.300570059906352, Test acc: 0.5411764705882353\n",
            "Train Loss: 1.1004094589025455, Train_acc: 0.9605882352941176, Test Loss: 4.14557056535374, Test acc: 0.5352941176470588\n",
            "Train Loss: 1.0671611188497758, Train_acc: 0.9621176470588235, Test Loss: 4.459071110595357, Test acc: 0.5411764705882353\n",
            "Train Loss: 1.045010563126184, Train_acc: 0.9631764705882353, Test Loss: 4.777838823470202, Test acc: 0.5470588235294118\n",
            "Train Loss: 1.0323306682862734, Train_acc: 0.9628235294117647, Test Loss: 4.064557454802773, Test acc: 0.538235294117647\n",
            "Train Loss: 1.030454114863747, Train_acc: 0.9602352941176471, Test Loss: 4.413567526773973, Test acc: 0.538235294117647\n",
            "Train Loss: 1.0159357443339843, Train_acc: 0.961764705882353, Test Loss: 4.5194346417080276, Test acc: 0.5441176470588235\n",
            "Train Loss: 0.9995487863407996, Train_acc: 0.9604705882352941, Test Loss: 4.4081773432818325, Test acc: 0.5323529411764706\n",
            "Fold 2\n",
            "Train Loss: 3.805933194052904, Train_acc: 0.5132941176470588, Test Loss: 2.629730771888386, Test acc: 0.47941176470588237\n",
            "Train Loss: 2.7205695514392136, Train_acc: 0.8215294117647058, Test Loss: 3.2318633036179976, Test acc: 0.5588235294117647\n",
            "Train Loss: 2.423020922151723, Train_acc: 0.8878823529411765, Test Loss: 3.93342539397153, Test acc: 0.5323529411764706\n",
            "Train Loss: 2.299595494019358, Train_acc: 0.9171764705882353, Test Loss: 4.0381195599382576, Test acc: 0.5617647058823529\n",
            "Train Loss: 2.2558304098315705, Train_acc: 0.9295294117647059, Test Loss: 3.6192566698247735, Test acc: 0.5588235294117647\n",
            "Train Loss: 2.181453542601793, Train_acc: 0.943764705882353, Test Loss: 4.20393815907565, Test acc: 0.5588235294117647\n",
            "Train Loss: 2.128040210645002, Train_acc: 0.9522352941176471, Test Loss: 3.9722657203674316, Test acc: 0.5617647058823529\n",
            "Train Loss: 2.065440099490316, Train_acc: 0.9562352941176471, Test Loss: 3.523724003271623, Test acc: 0.5735294117647058\n",
            "Train Loss: 2.012802966107103, Train_acc: 0.9595294117647059, Test Loss: 3.7160592621023003, Test acc: 0.5705882352941176\n",
            "Train Loss: 1.992648572401893, Train_acc: 0.9541176470588235, Test Loss: 3.736355488950556, Test acc: 0.55\n",
            "Train Loss: 1.939089480199312, Train_acc: 0.9588235294117647, Test Loss: 4.727671406485817, Test acc: 0.5647058823529412\n",
            "Train Loss: 1.9173890863146101, Train_acc: 0.9569411764705882, Test Loss: 3.9967683336951514, Test acc: 0.5705882352941176\n",
            "Train Loss: 1.861826693205009, Train_acc: 0.9590588235294117, Test Loss: 4.658654906532981, Test acc: 0.5735294117647058\n",
            "Train Loss: 1.8437153992796302, Train_acc: 0.9581176470588235, Test Loss: 4.82493636824868, Test acc: 0.5617647058823529\n",
            "Train Loss: 1.8101423400685304, Train_acc: 0.9585882352941176, Test Loss: 3.896590904756026, Test acc: 0.5588235294117647\n",
            "Train Loss: 1.7856816057872056, Train_acc: 0.9601176470588235, Test Loss: 3.2546032016927544, Test acc: 0.6029411764705882\n",
            "Train Loss: 1.7380725010893399, Train_acc: 0.9604705882352941, Test Loss: 3.956581462513317, Test acc: 0.5617647058823529\n",
            "Train Loss: 1.7100854932813716, Train_acc: 0.9608235294117647, Test Loss: 3.6763032458045264, Test acc: 0.5705882352941176\n",
            "Train Loss: 1.6939939278408997, Train_acc: 0.9581176470588235, Test Loss: 3.3097749298269097, Test acc: 0.5588235294117647\n",
            "Train Loss: 1.664178833029324, Train_acc: 0.9587058823529412, Test Loss: 2.921316081827337, Test acc: 0.5764705882352941\n",
            "Train Loss: 1.5983592258360153, Train_acc: 0.9629411764705882, Test Loss: 4.354477860710838, Test acc: 0.5882352941176471\n",
            "Train Loss: 1.5900938309224926, Train_acc: 0.96, Test Loss: 3.7546940716830166, Test acc: 0.5735294117647058\n",
            "Train Loss: 1.5602773522075855, Train_acc: 0.9612941176470589, Test Loss: 3.9659001393751665, Test acc: 0.5676470588235294\n",
            "Train Loss: 1.528969751264816, Train_acc: 0.9610588235294117, Test Loss: 3.921949408271096, Test acc: 0.5558823529411765\n",
            "Train Loss: 1.5047615215294343, Train_acc: 0.9621176470588235, Test Loss: 4.087996417825872, Test acc: 0.5647058823529412\n",
            "Train Loss: 1.4831527722509283, Train_acc: 0.9581176470588235, Test Loss: 3.775721549987793, Test acc: 0.5676470588235294\n",
            "Train Loss: 1.4391542000878126, Train_acc: 0.9638823529411765, Test Loss: 4.3483605493198745, Test acc: 0.5705882352941176\n",
            "Train Loss: 1.412845606194403, Train_acc: 0.9636470588235294, Test Loss: 4.851986993442882, Test acc: 0.5852941176470589\n",
            "Train Loss: 1.4094900390259306, Train_acc: 0.9635294117647059, Test Loss: 3.842239184813066, Test acc: 0.5794117647058824\n",
            "Train Loss: 1.346124533871959, Train_acc: 0.9651764705882353, Test Loss: 4.230312444946983, Test acc: 0.5764705882352941\n",
            "Train Loss: 1.32537103147435, Train_acc: 0.9635294117647059, Test Loss: 3.5077834020961416, Test acc: 0.5823529411764706\n",
            "Train Loss: 1.2989489368926315, Train_acc: 0.963764705882353, Test Loss: 4.360472971742803, Test acc: 0.5823529411764706\n",
            "Train Loss: 1.2814150918695264, Train_acc: 0.9618823529411765, Test Loss: 4.289743607694453, Test acc: 0.5735294117647058\n",
            "Train Loss: 1.2624840781204683, Train_acc: 0.9631764705882353, Test Loss: 4.250292669643056, Test acc: 0.5735294117647058\n",
            "Train Loss: 1.233211406639644, Train_acc: 0.9645882352941176, Test Loss: 3.967599402774464, Test acc: 0.5705882352941176\n",
            "Train Loss: 1.224611114290424, Train_acc: 0.9616470588235294, Test Loss: 3.9629600915041836, Test acc: 0.5617647058823529\n",
            "Train Loss: 1.2093946001583473, Train_acc: 0.9595294117647059, Test Loss: 4.380182439630682, Test acc: 0.5852941176470589\n",
            "Train Loss: 1.1727374205015655, Train_acc: 0.9654117647058823, Test Loss: 3.8969530083916406, Test acc: 0.5647058823529412\n",
            "Train Loss: 1.1526122276944326, Train_acc: 0.9647058823529412, Test Loss: 4.339040452783758, Test acc: 0.5647058823529412\n",
            "Train Loss: 1.147215568705609, Train_acc: 0.9624705882352941, Test Loss: 4.193806919184598, Test acc: 0.5676470588235294\n",
            "Train Loss: 1.1184373993174475, Train_acc: 0.9642352941176471, Test Loss: 4.5936630530790845, Test acc: 0.5617647058823529\n",
            "Train Loss: 1.0957233825124295, Train_acc: 0.963764705882353, Test Loss: 4.323754093863747, Test acc: 0.5617647058823529\n",
            "Train Loss: 1.083252489566803, Train_acc: 0.9656470588235294, Test Loss: 4.058630249717019, Test acc: 0.5705882352941176\n",
            "Train Loss: 1.0709582529121773, Train_acc: 0.9625882352941176, Test Loss: 4.282374468716708, Test acc: 0.5529411764705883\n",
            "Train Loss: 1.0771337341993374, Train_acc: 0.9601176470588235, Test Loss: 4.306571591984142, Test acc: 0.5735294117647058\n",
            "Train Loss: 1.0617018422686069, Train_acc: 0.9616470588235294, Test Loss: 3.8588883768428457, Test acc: 0.5617647058823529\n",
            "Train Loss: 1.0454746489238023, Train_acc: 0.9612941176470589, Test Loss: 4.129605596715754, Test acc: 0.5647058823529412\n",
            "Train Loss: 1.0400562895868057, Train_acc: 0.9622352941176471, Test Loss: 3.614599412137812, Test acc: 0.5529411764705883\n",
            "Train Loss: 1.0175473344953436, Train_acc: 0.9635294117647059, Test Loss: 4.025664427063682, Test acc: 0.5617647058823529\n",
            "Train Loss: 0.9913025184681541, Train_acc: 0.9645882352941176, Test Loss: 3.9790199886668813, Test acc: 0.5676470588235294\n",
            "Fold 3\n",
            "Train Loss: 3.8401504486127007, Train_acc: 0.4984705882352941, Test Loss: 2.3545675819570366, Test acc: 0.4676470588235294\n",
            "Train Loss: 2.7127910547686698, Train_acc: 0.827764705882353, Test Loss: 2.8925274447961287, Test acc: 0.5147058823529411\n",
            "Train Loss: 2.4102447355600227, Train_acc: 0.904235294117647, Test Loss: 3.604947355660525, Test acc: 0.5176470588235295\n",
            "Train Loss: 2.302732797493612, Train_acc: 0.9241176470588235, Test Loss: 3.3740256049416284, Test acc: 0.5352941176470588\n",
            "Train Loss: 2.223943108902838, Train_acc: 0.9382352941176471, Test Loss: 3.2815752110698004, Test acc: 0.5441176470588235\n",
            "Train Loss: 2.1447578650668153, Train_acc: 0.9483529411764706, Test Loss: 3.4112161099910736, Test acc: 0.5529411764705883\n",
            "Train Loss: 2.08593672962117, Train_acc: 0.954, Test Loss: 4.8899078802628955, Test acc: 0.5529411764705883\n",
            "Train Loss: 2.0347871991028463, Train_acc: 0.9568235294117647, Test Loss: 4.504942541772669, Test acc: 0.5588235294117647\n",
            "Train Loss: 2.0118496875117597, Train_acc: 0.9575294117647059, Test Loss: 4.603185447779569, Test acc: 0.5558823529411765\n",
            "Train Loss: 1.960085966533288, Train_acc: 0.9596470588235294, Test Loss: 4.889067579399455, Test acc: 0.5617647058823529\n",
            "Train Loss: 1.9411135132151438, Train_acc: 0.9574117647058824, Test Loss: 4.130505383014679, Test acc: 0.5617647058823529\n",
            "Train Loss: 1.899373994285899, Train_acc: 0.9582352941176471, Test Loss: 3.986180478876287, Test acc: 0.5647058823529412\n",
            "Train Loss: 1.8888346687295383, Train_acc: 0.9567058823529412, Test Loss: 4.138559688221324, Test acc: 0.5470588235294118\n",
            "Train Loss: 1.8289454709318347, Train_acc: 0.9608235294117647, Test Loss: 5.000484937971288, Test acc: 0.55\n",
            "Train Loss: 1.7876624093019873, Train_acc: 0.962, Test Loss: 4.859439860690724, Test acc: 0.538235294117647\n",
            "Train Loss: 1.7645239193636673, Train_acc: 0.9602352941176471, Test Loss: 4.737413005395369, Test acc: 0.5294117647058824\n",
            "Train Loss: 1.7399151634452934, Train_acc: 0.9596470588235294, Test Loss: 5.019335863265124, Test acc: 0.5441176470588235\n",
            "Train Loss: 1.7009432988059252, Train_acc: 0.9611764705882353, Test Loss: 4.960577596317638, Test acc: 0.5441176470588235\n",
            "Train Loss: 1.6751327402609633, Train_acc: 0.9602352941176471, Test Loss: 5.013371077450839, Test acc: 0.5352941176470588\n",
            "Train Loss: 1.6555370876663609, Train_acc: 0.9582352941176471, Test Loss: 4.771224834702232, Test acc: 0.5411764705882353\n",
            "Train Loss: 1.6067884573362823, Train_acc: 0.9602352941176471, Test Loss: 4.764105032790791, Test acc: 0.5235294117647059\n",
            "Train Loss: 1.5826273412632763, Train_acc: 0.9598823529411765, Test Loss: 4.787335669452494, Test acc: 0.5470588235294118\n",
            "Train Loss: 1.5663459247216247, Train_acc: 0.959764705882353, Test Loss: 4.208682870323008, Test acc: 0.5411764705882353\n",
            "Train Loss: 1.5199572556000902, Train_acc: 0.9612941176470589, Test Loss: 5.53963760083372, Test acc: 0.5529411764705883\n",
            "Train Loss: 1.4993355655132379, Train_acc: 0.9630588235294117, Test Loss: 4.390399754047394, Test acc: 0.5352941176470588\n",
            "Train Loss: 1.4739959773264433, Train_acc: 0.9603529411764706, Test Loss: 4.879619676958431, Test acc: 0.5205882352941177\n",
            "Train Loss: 1.4390485371862138, Train_acc: 0.9634117647058823, Test Loss: 5.215453025969592, Test acc: 0.5470588235294118\n",
            "Train Loss: 1.415100159949826, Train_acc: 0.9638823529411765, Test Loss: 4.683865121819756, Test acc: 0.5294117647058824\n",
            "Train Loss: 1.3842067669208784, Train_acc: 0.9627058823529412, Test Loss: 4.615182608366013, Test acc: 0.538235294117647\n",
            "Train Loss: 1.3635946395701932, Train_acc: 0.9623529411764706, Test Loss: 4.426191392270002, Test acc: 0.5617647058823529\n",
            "Train Loss: 1.3557687065655128, Train_acc: 0.9603529411764706, Test Loss: 4.680617140098051, Test acc: 0.5352941176470588\n",
            "Train Loss: 1.313236995747215, Train_acc: 0.9643529411764706, Test Loss: 5.027050756595352, Test acc: 0.5323529411764706\n",
            "Train Loss: 1.2998161710294567, Train_acc: 0.961764705882353, Test Loss: 4.751048895445737, Test acc: 0.538235294117647\n",
            "Train Loss: 1.2809786581455316, Train_acc: 0.9612941176470589, Test Loss: 4.9156359813430095, Test acc: 0.5352941176470588\n",
            "Train Loss: 1.258139271485178, Train_acc: 0.9634117647058823, Test Loss: 5.081522245298732, Test acc: 0.5411764705882353\n",
            "Train Loss: 1.2317831126370824, Train_acc: 0.9644705882352941, Test Loss: 4.873070399869572, Test acc: 0.5470588235294118\n",
            "Train Loss: 1.2011723585594865, Train_acc: 0.9648235294117647, Test Loss: 5.1942939189347355, Test acc: 0.55\n",
            "Train Loss: 1.1848904669732976, Train_acc: 0.9652941176470589, Test Loss: 5.2190141989426175, Test acc: 0.5411764705882353\n",
            "Train Loss: 1.1545837109250234, Train_acc: 0.9661176470588235, Test Loss: 5.452252412384206, Test acc: 0.5323529411764706\n",
            "Train Loss: 1.1509238956566143, Train_acc: 0.963764705882353, Test Loss: 4.523015191609209, Test acc: 0.5323529411764706\n",
            "Train Loss: 1.138648803969075, Train_acc: 0.9612941176470589, Test Loss: 4.650548710064455, Test acc: 0.5470588235294118\n",
            "Train Loss: 1.106303646152181, Train_acc: 0.9647058823529412, Test Loss: 4.699301513758573, Test acc: 0.538235294117647\n",
            "Train Loss: 1.1150108206092864, Train_acc: 0.9608235294117647, Test Loss: 3.457132011651993, Test acc: 0.5352941176470588\n",
            "Train Loss: 1.0780448183081204, Train_acc: 0.9649411764705882, Test Loss: 4.087555319070816, Test acc: 0.5352941176470588\n",
            "Train Loss: 1.083538829159916, Train_acc: 0.9622352941176471, Test Loss: 4.463223936882886, Test acc: 0.5441176470588235\n",
            "Train Loss: 1.0451526034595375, Train_acc: 0.965764705882353, Test Loss: 4.77666759761897, Test acc: 0.5558823529411765\n",
            "Train Loss: 1.0195663732693607, Train_acc: 0.9668235294117647, Test Loss: 5.1965572671456775, Test acc: 0.5411764705882353\n",
            "Train Loss: 1.0029778686681188, Train_acc: 0.9667058823529412, Test Loss: 4.631810545921326, Test acc: 0.5588235294117647\n",
            "Train Loss: 0.9961232966498325, Train_acc: 0.963764705882353, Test Loss: 4.843825659968636, Test acc: 0.5470588235294118\n",
            "Train Loss: 0.992201630782364, Train_acc: 0.9638823529411765, Test Loss: 4.52966248718175, Test acc: 0.538235294117647\n",
            "Fold 4\n",
            "Train Loss: 3.8561015487613535, Train_acc: 0.4935294117647059, Test Loss: 2.2160309769890527, Test acc: 0.47058823529411764\n",
            "Train Loss: 2.7562204384265985, Train_acc: 0.8163529411764706, Test Loss: 2.2309726801785557, Test acc: 0.5882352941176471\n",
            "Train Loss: 2.4545619191980004, Train_acc: 0.8861176470588236, Test Loss: 3.241978818720037, Test acc: 0.5970588235294118\n",
            "Train Loss: 2.3497829804743144, Train_acc: 0.9091764705882353, Test Loss: 3.2369478128173133, Test acc: 0.6088235294117647\n",
            "Train Loss: 2.2619483381285703, Train_acc: 0.9311764705882353, Test Loss: 3.311933170665394, Test acc: 0.6205882352941177\n",
            "Train Loss: 2.219541630798713, Train_acc: 0.9402352941176471, Test Loss: 2.9759844649921763, Test acc: 0.6029411764705882\n",
            "Train Loss: 2.135671024932001, Train_acc: 0.9502352941176471, Test Loss: 3.1335596388036553, Test acc: 0.6088235294117647\n",
            "Train Loss: 2.085647125441329, Train_acc: 0.9542352941176471, Test Loss: 3.3285709619522095, Test acc: 0.6147058823529412\n",
            "Train Loss: 2.033082209135357, Train_acc: 0.9521176470588235, Test Loss: 3.742160125212236, Test acc: 0.611764705882353\n",
            "Train Loss: 2.0340454179541507, Train_acc: 0.9532941176470588, Test Loss: 3.557557387785478, Test acc: 0.6205882352941177\n",
            "Train Loss: 1.9679965305149107, Train_acc: 0.9565882352941176, Test Loss: 3.684680711139332, Test acc: 0.6088235294117647\n",
            "Train Loss: 1.9197674989700317, Train_acc: 0.9545882352941176, Test Loss: 3.609317048029466, Test acc: 0.6147058823529412\n",
            "Train Loss: 1.873180265713455, Train_acc: 0.9576470588235294, Test Loss: 3.8728984485973013, Test acc: 0.6088235294117647\n",
            "Train Loss: 1.8473933616975196, Train_acc: 0.9565882352941176, Test Loss: 3.901034940372814, Test acc: 0.611764705882353\n",
            "Train Loss: 1.8047746975619094, Train_acc: 0.9581176470588235, Test Loss: 4.096862668340856, Test acc: 0.611764705882353\n",
            "Train Loss: 1.7793857163952707, Train_acc: 0.9558823529411765, Test Loss: 4.656122641129927, Test acc: 0.611764705882353\n",
            "Train Loss: 1.7608332723603213, Train_acc: 0.9574117647058824, Test Loss: 3.998661599375985, Test acc: 0.6323529411764706\n",
            "Train Loss: 1.754686389202462, Train_acc: 0.9530588235294117, Test Loss: 3.056159322912043, Test acc: 0.6235294117647059\n",
            "Train Loss: 1.7368075905885911, Train_acc: 0.9549411764705882, Test Loss: 3.718833739107305, Test acc: 0.6147058823529412\n",
            "Train Loss: 1.6865307088185073, Train_acc: 0.9582352941176471, Test Loss: 3.0935332016511397, Test acc: 0.6235294117647059\n",
            "Train Loss: 1.6186956512300592, Train_acc: 0.9607058823529412, Test Loss: 4.526906609535217, Test acc: 0.6205882352941177\n",
            "Train Loss: 1.5900360063502663, Train_acc: 0.9590588235294117, Test Loss: 3.6215615489266137, Test acc: 0.6352941176470588\n",
            "Train Loss: 1.557733641083079, Train_acc: 0.9608235294117647, Test Loss: 3.980417555028742, Test acc: 0.6323529411764706\n",
            "Train Loss: 1.5509357842287623, Train_acc: 0.9570588235294117, Test Loss: 3.3335158066316084, Test acc: 0.6235294117647059\n",
            "Train Loss: 1.5293569842675574, Train_acc: 0.9574117647058824, Test Loss: 3.66068417375738, Test acc: 0.6205882352941177\n",
            "Train Loss: 1.4982348483307917, Train_acc: 0.9585882352941176, Test Loss: 3.847021547230807, Test acc: 0.6235294117647059\n",
            "Train Loss: 1.463763982281649, Train_acc: 0.9629411764705882, Test Loss: 3.935359976508401, Test acc: 0.6147058823529412\n",
            "Train Loss: 1.4336820002785302, Train_acc: 0.959764705882353, Test Loss: 3.79528977654197, Test acc: 0.6323529411764706\n",
            "Train Loss: 1.4151708201358193, Train_acc: 0.9590588235294117, Test Loss: 3.7490732886574487, Test acc: 0.6176470588235294\n",
            "Train Loss: 1.3814498302631808, Train_acc: 0.9612941176470589, Test Loss: 3.615098335526206, Test acc: 0.6235294117647059\n",
            "Train Loss: 1.368924766106713, Train_acc: 0.9601176470588235, Test Loss: 3.2149304043162954, Test acc: 0.6352941176470588\n",
            "Train Loss: 1.3374373442248295, Train_acc: 0.962, Test Loss: 4.157011985778809, Test acc: 0.6264705882352941\n",
            "Train Loss: 1.3076109509719045, Train_acc: 0.9627058823529412, Test Loss: 4.314350139011037, Test acc: 0.6352941176470588\n",
            "Train Loss: 1.280545633538325, Train_acc: 0.9630588235294117, Test Loss: 4.450337518345226, Test acc: 0.6235294117647059\n",
            "Train Loss: 1.2603059379678023, Train_acc: 0.9629411764705882, Test Loss: 3.6564119078896264, Test acc: 0.6264705882352941\n",
            "Train Loss: 1.2319732039494622, Train_acc: 0.9629411764705882, Test Loss: 3.876014557751742, Test acc: 0.6147058823529412\n",
            "Train Loss: 1.2257172770069955, Train_acc: 0.9609411764705882, Test Loss: 4.035025910897688, Test acc: 0.6323529411764706\n",
            "Train Loss: 1.2100807943738492, Train_acc: 0.9616470588235294, Test Loss: 3.7899659221822564, Test acc: 0.611764705882353\n",
            "Train Loss: 1.182286558294655, Train_acc: 0.9630588235294117, Test Loss: 3.8188425194133413, Test acc: 0.6235294117647059\n",
            "Train Loss: 1.150190564474665, Train_acc: 0.9647058823529412, Test Loss: 4.190781311555342, Test acc: 0.6235294117647059\n",
            "Train Loss: 1.1364571030874897, Train_acc: 0.9629411764705882, Test Loss: 3.778693659739061, Test acc: 0.6264705882352941\n",
            "Train Loss: 1.1128026294080835, Train_acc: 0.9635294117647059, Test Loss: 3.6503280617974023, Test acc: 0.638235294117647\n",
            "Train Loss: 1.094280823729092, Train_acc: 0.9623529411764706, Test Loss: 3.944614838470112, Test acc: 0.6294117647058823\n",
            "Train Loss: 1.0947179066059285, Train_acc: 0.9623529411764706, Test Loss: 3.402914345264435, Test acc: 0.6294117647058823\n",
            "Train Loss: 1.074226485159164, Train_acc: 0.961764705882353, Test Loss: 3.0744993686676025, Test acc: 0.6411764705882353\n",
            "Train Loss: 1.0664998541649122, Train_acc: 0.9612941176470589, Test Loss: 3.0852739810943604, Test acc: 0.6235294117647059\n",
            "Train Loss: 1.0362756962614847, Train_acc: 0.9638823529411765, Test Loss: 4.230092828924006, Test acc: 0.6176470588235294\n",
            "Train Loss: 1.0210543579625009, Train_acc: 0.9635294117647059, Test Loss: 3.3774676864797417, Test acc: 0.611764705882353\n",
            "Train Loss: 1.058370536431334, Train_acc: 0.9610588235294117, Test Loss: 3.1053407950834795, Test acc: 0.638235294117647\n",
            "Train Loss: 1.0044828102104646, Train_acc: 0.962, Test Loss: 3.398217808116566, Test acc: 0.6352941176470588\n",
            "Fold 5\n",
            "Train Loss: 3.9066827799144543, Train_acc: 0.48505882352941176, Test Loss: 2.314131823453036, Test acc: 0.43529411764705883\n",
            "Train Loss: 2.7524716746538207, Train_acc: 0.8163529411764706, Test Loss: 3.084447058764371, Test acc: 0.5264705882352941\n",
            "Train Loss: 2.467049393438755, Train_acc: 0.886, Test Loss: 3.4925546754490244, Test acc: 0.5235294117647059\n",
            "Train Loss: 2.3183109509317497, Train_acc: 0.920235294117647, Test Loss: 3.979438890110363, Test acc: 0.538235294117647\n",
            "Train Loss: 2.258838459065086, Train_acc: 0.9304705882352942, Test Loss: 3.628055973486467, Test acc: 0.5352941176470588\n",
            "Train Loss: 2.184825763218385, Train_acc: 0.9432941176470588, Test Loss: 4.272675915197893, Test acc: 0.5529411764705883\n",
            "Train Loss: 2.1350704467386232, Train_acc: 0.9464705882352941, Test Loss: 3.6939825361425225, Test acc: 0.538235294117647\n",
            "Train Loss: 2.0755121412133812, Train_acc: 0.9510588235294117, Test Loss: 3.8673332929611206, Test acc: 0.5294117647058824\n",
            "Train Loss: 2.0341315569734215, Train_acc: 0.954, Test Loss: 3.6844759529287163, Test acc: 0.5352941176470588\n",
            "Train Loss: 2.008780161689099, Train_acc: 0.9524705882352941, Test Loss: 4.1910775683142925, Test acc: 0.55\n",
            "Train Loss: 1.9825544921975387, Train_acc: 0.9547058823529412, Test Loss: 4.434954632412303, Test acc: 0.55\n",
            "Train Loss: 1.9375009102032597, Train_acc: 0.9576470588235294, Test Loss: 4.280441847714511, Test acc: 0.5294117647058824\n",
            "Train Loss: 1.9031415079769336, Train_acc: 0.9564705882352941, Test Loss: 5.223962924697182, Test acc: 0.5352941176470588\n",
            "Train Loss: 1.859820260141129, Train_acc: 0.9588235294117647, Test Loss: 4.629738157445734, Test acc: 0.538235294117647\n",
            "Train Loss: 1.833820829265996, Train_acc: 0.9590588235294117, Test Loss: 4.382038311524824, Test acc: 0.5323529411764706\n",
            "Train Loss: 1.8012129350712425, Train_acc: 0.9607058823529412, Test Loss: 4.456049203872681, Test acc: 0.5352941176470588\n",
            "Train Loss: 1.764688167805062, Train_acc: 0.9636470588235294, Test Loss: 4.451117493889549, Test acc: 0.5470588235294118\n",
            "Train Loss: 1.7207308676009787, Train_acc: 0.9611764705882353, Test Loss: 5.290317665446889, Test acc: 0.538235294117647\n",
            "Train Loss: 1.6751870898375834, Train_acc: 0.9624705882352941, Test Loss: 5.217817208983681, Test acc: 0.5323529411764706\n",
            "Train Loss: 1.6556580241461445, Train_acc: 0.9604705882352941, Test Loss: 4.5770627802068535, Test acc: 0.538235294117647\n",
            "Train Loss: 1.608161495592361, Train_acc: 0.9627058823529412, Test Loss: 5.524761785160411, Test acc: 0.55\n",
            "Train Loss: 1.5778645536953346, Train_acc: 0.9643529411764706, Test Loss: 5.400363965467974, Test acc: 0.5294117647058824\n",
            "Train Loss: 1.558715723959127, Train_acc: 0.9628235294117647, Test Loss: 5.141780311411077, Test acc: 0.5294117647058824\n",
            "Train Loss: 1.5194397900337564, Train_acc: 0.9636470588235294, Test Loss: 5.755054192109541, Test acc: 0.5205882352941177\n",
            "Train Loss: 1.530685693697822, Train_acc: 0.9562352941176471, Test Loss: 5.110874457792803, Test acc: 0.5235294117647059\n",
            "Train Loss: 1.5004371444981797, Train_acc: 0.9578823529411765, Test Loss: 4.544843500310725, Test acc: 0.5264705882352941\n",
            "Train Loss: 1.5015672947231091, Train_acc: 0.9574117647058824, Test Loss: 5.068707054311579, Test acc: 0.5235294117647059\n",
            "Train Loss: 1.4565183399315167, Train_acc: 0.9584705882352941, Test Loss: 5.023122668266296, Test acc: 0.5441176470588235\n",
            "Train Loss: 1.4327698152764399, Train_acc: 0.961764705882353, Test Loss: 4.310663125731728, Test acc: 0.5352941176470588\n",
            "Train Loss: 1.425470102550392, Train_acc: 0.9607058823529412, Test Loss: 5.420429338108409, Test acc: 0.5294117647058824\n",
            "Train Loss: 1.395942225043935, Train_acc: 0.9630588235294117, Test Loss: 4.498182751915672, Test acc: 0.538235294117647\n",
            "Train Loss: 1.3574007207289673, Train_acc: 0.9642352941176471, Test Loss: 4.455902630632574, Test acc: 0.5352941176470588\n",
            "Train Loss: 1.3396474732492203, Train_acc: 0.9641176470588235, Test Loss: 4.636888655749234, Test acc: 0.5441176470588235\n",
            "Train Loss: 1.299680380892933, Train_acc: 0.9628235294117647, Test Loss: 5.8004786209626635, Test acc: 0.55\n",
            "Train Loss: 1.2772808186989977, Train_acc: 0.9625882352941176, Test Loss: 4.981857007200068, Test acc: 0.5441176470588235\n",
            "Train Loss: 1.2608772740328222, Train_acc: 0.9622352941176471, Test Loss: 4.989331353794444, Test acc: 0.5411764705882353\n",
            "Train Loss: 1.2290779482153125, Train_acc: 0.9658823529411765, Test Loss: 5.656961571086537, Test acc: 0.55\n",
            "Train Loss: 1.2085215413480772, Train_acc: 0.9663529411764706, Test Loss: 5.452334133061496, Test acc: 0.538235294117647\n",
            "Train Loss: 1.1869144215619654, Train_acc: 0.9655294117647059, Test Loss: 4.895302859219638, Test acc: 0.5323529411764706\n",
            "Train Loss: 1.1775631178590589, Train_acc: 0.9616470588235294, Test Loss: 5.1623993353410205, Test acc: 0.538235294117647\n",
            "Train Loss: 1.1519855153291745, Train_acc: 0.9636470588235294, Test Loss: 4.821997837586836, Test acc: 0.55\n",
            "Train Loss: 1.137812198104715, Train_acc: 0.9642352941176471, Test Loss: 5.71779430996288, Test acc: 0.5352941176470588\n",
            "Train Loss: 1.1228800232249094, Train_acc: 0.9643529411764706, Test Loss: 5.6147676597942, Test acc: 0.5441176470588235\n",
            "Train Loss: 1.1044385928408544, Train_acc: 0.9635294117647059, Test Loss: 5.26954832944003, Test acc: 0.5352941176470588\n",
            "Train Loss: 1.0968932366012631, Train_acc: 0.9621176470588235, Test Loss: 5.436515190384605, Test acc: 0.5352941176470588\n",
            "Train Loss: 1.0811309010014498, Train_acc: 0.9638823529411765, Test Loss: 5.534068150953813, Test acc: 0.5352941176470588\n",
            "Train Loss: 1.0640381585834617, Train_acc: 0.9651764705882353, Test Loss: 4.98016188361428, Test acc: 0.5323529411764706\n",
            "Train Loss: 1.0631007032286852, Train_acc: 0.9638823529411765, Test Loss: 4.5862613482908765, Test acc: 0.5441176470588235\n",
            "Train Loss: 1.0486269494644682, Train_acc: 0.9625882352941176, Test Loss: 4.706585472280329, Test acc: 0.5529411764705883\n",
            "Train Loss: 1.0422317564935613, Train_acc: 0.9624705882352941, Test Loss: 5.003196358680725, Test acc: 0.5411764705882353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save models\n",
        "# import pickle\n",
        "# file=open('/content/drive/MyDrive/CNN_models','wb')\n",
        "# pickle.dump(models, file)\n",
        "# file.close()"
      ],
      "metadata": {
        "id": "AjBRHjXB4UM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file=open('/content/drive/MyDrive/CNN_models','rb')\n",
        "# models = pickle.load(file)\n",
        "# file.close()"
      ],
      "metadata": {
        "id": "glv7G-3y5LhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate the average accuray of the 5 models\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "X_train_v, X_test, y_train_v, y_test = train_test_split(X, y, test_size=0.2, random_state=99, stratify=y)\n",
        "t = pd.DataFrame(y_test, columns = ['class']).reset_index()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "idx = []\n",
        "y_test = []\n",
        "with torch.no_grad():\n",
        "  for i in range(0,18):\n",
        "      if i!=label_dict['Unknown']:\n",
        "        idx += list(t[t['class']==i].sample(20,replace=True)['index'])\n",
        "        y_test += [i]*20\n",
        "  X_test =  X_test[idx]\n",
        "  X_test = torch.as_tensor(X_test, dtype=torch.float)\n",
        "  y_test = torch.as_tensor(y_test, dtype=torch.float).type(torch.LongTensor)\n",
        "\n",
        "  test_dataset = TensorDataset(X_test, y_test)\n",
        "  test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "  acc = []\n",
        "  for best_model in models:\n",
        "    acc.append(valid_epoch(best_model[0],device,test_dataloader,criterion)[1])"
      ],
      "metadata": {
        "id": "u0--vQKT4bln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqE8HFYR4cV1",
        "outputId": "d03c1796-a472-4b35-8519-0780b4779d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5988235294117648"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the accuracy with majority vote\n",
        "outputs = []\n",
        "with torch.no_grad():\n",
        "  for model in models:\n",
        "    model[0].eval()\n",
        "    model_output = []\n",
        "    label_= []\n",
        "    model[0].to(device)\n",
        "    for inputs, labels in test_dataloader:\n",
        "        inputs = inputs.reshape(-1,1,512,128).to(device)\n",
        "        labels = labels.to(device)\n",
        "        cnnOutputs = model[0](inputs)\n",
        "        model_output.append(cnnOutputs)\n",
        "        label_.append(labels)\n",
        "        # del inputs\n",
        "    outputs.append(torch.vstack(model_output))"
      ],
      "metadata": {
        "id": "q1xKu5824cgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shape = outputs[0].shape\n",
        "labels = torch.hstack(label_)\n",
        "cnnresult = torch.vstack(outputs).reshape(-1,shape[0],shape[1]).mean(axis=0).to('cpu')\n",
        "_, cnnPredicted = torch.max(cnnresult.data, 1)\n",
        "cnnCorrect = (cnnPredicted.detach().numpy() == labels.to('cpu').detach().numpy()).sum().item()\n",
        "print(cnnCorrect/len(labels)*100)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confu_m = confusion_matrix(labels.to('cpu'), cnnPredicted.to('cpu'))\n",
        "import seaborn as sns\n",
        "sns.heatmap(confu_m,square=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "Pke06dv24cpn",
        "outputId": "b8eff27a-bb17-44ab-e5a9-8373ab999302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65.88235294117646\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the Precision, Recall, F1 scores of each classes\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "scores = pd.DataFrame(precision_recall_fscore_support(cnnPredicted.to('cpu'), labels.to('cpu'), labels = list(range(18))),index=['precision','recall','f1','support'], columns = list(label_dict)[:18])\n",
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "M2ufDXvU4czd",
        "outputId": "1d0d480c-4cda-4ace-9c61-e0039fd7e362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Ambient      Blues  Children  Classical    Country  Electronic  \\\n",
              "precision     0.85   0.750000   0.45000   0.950000   0.750000    0.400000   \n",
              "recall        0.85   0.882353   1.00000   0.730769   0.789474    0.320000   \n",
              "f1            0.85   0.810811   0.62069   0.826087   0.769231    0.355556   \n",
              "support      20.00  17.000000   9.00000  26.000000  19.000000   25.000000   \n",
              "\n",
              "            Folk       Jazz      Latin        Pop        Rap  Reggae  \\\n",
              "precision   0.60   0.500000   0.600000   0.750000   0.450000     1.0   \n",
              "recall      1.00   0.476190   0.800000   0.652174   0.692308     1.0   \n",
              "f1          0.75   0.487805   0.685714   0.697674   0.545455     1.0   \n",
              "support    12.00  21.000000  15.000000  23.000000  13.000000    20.0   \n",
              "\n",
              "           Religious       Rock       Soul  Soundtracks  Unknown      World  \n",
              "precision   0.650000   0.650000   0.650000     0.800000      0.0   0.400000  \n",
              "recall      1.000000   0.270833   0.565217     0.666667      0.0   0.666667  \n",
              "f1          0.787879   0.382353   0.604651     0.727273      0.0   0.500000  \n",
              "support    13.000000  48.000000  23.000000    24.000000      0.0  12.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bbcc4a2b-7259-4578-a462-12ece42c92c7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ambient</th>\n",
              "      <th>Blues</th>\n",
              "      <th>Children</th>\n",
              "      <th>Classical</th>\n",
              "      <th>Country</th>\n",
              "      <th>Electronic</th>\n",
              "      <th>Folk</th>\n",
              "      <th>Jazz</th>\n",
              "      <th>Latin</th>\n",
              "      <th>Pop</th>\n",
              "      <th>Rap</th>\n",
              "      <th>Reggae</th>\n",
              "      <th>Religious</th>\n",
              "      <th>Rock</th>\n",
              "      <th>Soul</th>\n",
              "      <th>Soundtracks</th>\n",
              "      <th>Unknown</th>\n",
              "      <th>World</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.85</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.45000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.85</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.730769</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.476190</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.652174</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.270833</td>\n",
              "      <td>0.565217</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1</th>\n",
              "      <td>0.85</td>\n",
              "      <td>0.810811</td>\n",
              "      <td>0.62069</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.355556</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.487805</td>\n",
              "      <td>0.685714</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.787879</td>\n",
              "      <td>0.382353</td>\n",
              "      <td>0.604651</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>20.00</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>9.00000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>12.00</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>20.0</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbcc4a2b-7259-4578-a462-12ece42c92c7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bbcc4a2b-7259-4578-a462-12ece42c92c7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bbcc4a2b-7259-4578-a462-12ece42c92c7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-038794a8-b72c-423c-b34b-1b7d3ba586d3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-038794a8-b72c-423c-b34b-1b7d3ba586d3')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-038794a8-b72c-423c-b34b-1b7d3ba586d3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b47e0838-13d4-48a2-a380-b08a97036d91\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('scores')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b47e0838-13d4-48a2-a380-b08a97036d91 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('scores');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the label_dict\n",
        "label_dict = {}\n",
        "for cl in le.classes_:\n",
        "    label_dict.update({cl:le.transform([cl])[0]})\n",
        "label_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn0NCC2dCrTx",
        "outputId": "f2918339-1f7c-487a-ba9d-70d8c0851c76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Ambient': 0,\n",
              " 'Blues': 1,\n",
              " 'Children': 2,\n",
              " 'Classical': 3,\n",
              " 'Country': 4,\n",
              " 'Electronic': 5,\n",
              " 'Folk': 6,\n",
              " 'Jazz': 7,\n",
              " 'Latin': 8,\n",
              " 'Pop': 9,\n",
              " 'Rap': 10,\n",
              " 'Reggae': 11,\n",
              " 'Religious': 12,\n",
              " 'Rock': 13,\n",
              " 'Soul': 14,\n",
              " 'Soundtracks': 15,\n",
              " 'Unknown': 16,\n",
              " 'World': 17}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}