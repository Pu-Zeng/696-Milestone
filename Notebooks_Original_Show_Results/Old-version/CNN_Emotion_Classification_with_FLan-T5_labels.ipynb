{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wRF6FLeb5DXz"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "u8eSS9tg62ge",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# import mido\n",
    "import string\n",
    "import numpy as np\n",
    "# from utilis import get_pianoroll_data\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# import mido\n",
    "import string\n",
    "import numpy as np\n",
    "# from utilis import get_pianoroll_data\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open_file\n",
    "file=open(\"single_word_emotion_music1.bin\",\"rb\")\n",
    "music_data = pickle.load(file) #保存list到文件\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"a-livin'\", 'accaderelo', 'achey', 'acquittaloe', 'adagio',\n",
       "       'adolescent', 'adrift', 'african', 'ah!', 'aha', 'ahdammi', 'ahh',\n",
       "       'ahi', 'amazing', 'amore', 'amoree', 'anger', 'angry', 'arousal',\n",
       "       \"avversita'\", 'awe', 'ayayay', 'beautiful', 'bene', 'comfort',\n",
       "       'confused', 'darkness', 'depressed', \"e'\", 'e.universo', 'ecstasy',\n",
       "       'eh', 'eloquent', 'emo', 'emocionante', 'emotion', 'emotional',\n",
       "       'emozione', 'empathetic', 'enlightened', 'esattamente', 'esattro',\n",
       "       'etu', 'euphoria',\n",
       "       'evtiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii', 'excited',\n",
       "       'fear', 'fearful', 'fearless', 'free', 'freedom', 'frightened',\n",
       "       'frightful', 'good', 'grateful', 'happy', 'happyness',\n",
       "       'heaialcupation', 'heartbreak', 'helpful', 'hopeful', 'hurt',\n",
       "       'hysterical', 'i', \"i'm\", 'iose', 'irritated', 'joy', 'joyous',\n",
       "       'lonely', 'love', 'money', 'negative', 'new', 'nostalgic',\n",
       "       'positive', 'powerful', \"rainin'\", 'sad', 'sadness', 'scared',\n",
       "       'shame', 'strong', 'tender', 'tenderness', 'time', 'tired',\n",
       "       'tiredness', 'uneasy', 'unsure', 'upset', 'vain'], dtype='<U49')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the Flan-T5 Generated Labels\n",
    "np.unique([x[1] for x in music_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1122"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array([x[0].shape[0] for x in music_data])>612).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "a5ONeVUU7MOU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace repetive labels\n",
    "from tqdm import tqdm\n",
    "X = []\n",
    "y = []\n",
    "chosen_label = ['sadness', 'happy', 'love', 'joy', 'negative', 'positive', 'anger',\n",
    "       'awe', 'emotional', 'hopeful', 'angry', 'excited', 'fear', 'hurt',\n",
    "       'fearful']\n",
    "# for i in tqdm(range(1,10)):\n",
    "file=open(\"single_word_emotion_music1.bin\",\"rb\")\n",
    "music_data = pickle.load(file) #保存list到文件\n",
    "file.close()\n",
    "for m in music_data:\n",
    "    if m[0].shape[0]>=612 and m[1] in chosen_label:\n",
    "        X.append(m[0][100:612,:])\n",
    "        if m[1] == 'anger':\n",
    "            m[1] = 'angry'\n",
    "        if m[1] == 'fearful':\n",
    "            m[1] = 'fear'\n",
    "        if m[1] == 'joy':\n",
    "            m[1] = 'happy'\n",
    "        y.append(m[1])\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['angry', 'awe', 'emotional', 'excited', 'fear', 'happy', 'hopeful',\n",
       "       'hurt', 'love', 'negative', 'positive', 'sadness'], dtype='<U9')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique Labels\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform labels into one-hot variable\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "label_dict = {}\n",
    "for cl in le.classes_:\n",
    "    label_dict.update({cl:le.transform([cl])[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define CNN\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, hiddenSize, outChannels, dropoutRate, activate):\n",
    "        super().__init__()\n",
    "        self.outChannels = outChannels\n",
    "        self.activate = nn.Sigmoid() if activate == \"Sigmoid\" else nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(1, 24, (10,1))\n",
    "        self.pool = nn.MaxPool2d((2, 1))\n",
    "        self.conv2 = nn.Conv2d(24, 48, (10,1))\n",
    "        self.conv3 = nn.Conv2d(48, 96, (10,1))\n",
    "        self.conv4 = nn.Conv2d(96, 192, (10,1))\n",
    "        self.conv5 = nn.Conv2d(192, 384, (5,2))\n",
    "        self.conv6 = nn.Conv2d(384, 192, (5,2))\n",
    "        self.dense1 = nn.Linear(48384, hiddenSize)\n",
    "        self.dropout = nn.Dropout(dropoutRate)\n",
    "        self.dense2 = nn.Linear(hiddenSize, 12)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.activate(self.conv1(x)))\n",
    "        x = self.pool(self.activate(self.conv2(x)))\n",
    "        # print(x.shape)\n",
    "        x = self.dropout(self.pool(self.activate(self.conv3(x))))\n",
    "        x = self.pool(self.activate(self.conv4(x)))\n",
    "        x = self.pool(self.activate(self.conv5(x)))\n",
    "        x = self.pool(self.activate(self.conv6(x)))\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 48384)\n",
    "        x = self.dropout(self.activate(self.dense1(x)))\n",
    "        return self.dense2(x)\n",
    "\n",
    "# Number of neurons in the first fully-connected layer\n",
    "hiddenSize = 4096\n",
    "# Number of feature filters in second convolutional layer\n",
    "numFilters = 25\n",
    "# Dropout rate\n",
    "dropoutRate = 0.2\n",
    "# Activation function\n",
    "activation = \"ReLU\"\n",
    "# Learning rate\n",
    "learningRate = 0.005\n",
    "# Momentum for SGD optimizer\n",
    "momentum = 0.9\n",
    "# Number of training epochs\n",
    "numEpochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function - Train and validation\n",
    "from tqdm import tqdm\n",
    "def train_epoch(cnn,device,dataloader,loss_fn,optimizer):\n",
    "    cnn.train()\n",
    "    cnnRunningLoss = 0\n",
    "    total = 0\n",
    "    R2 = 0\n",
    "    cnnCorrect=0\n",
    "    total1=0\n",
    "    for i, (inputs, labels) in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to('cuda').reshape(-1,1,512,128)\n",
    "        \n",
    "        labels = labels.to('cuda')\n",
    "        # Forward propagation\n",
    "        cnnOutputs = cnn(inputs)\n",
    "        # print(cnnOutputs.shape)\n",
    "        l2_lambda = 0.001\n",
    "        l2_reg = torch.tensor(0.).to('cuda')\n",
    "        for param in cnn.parameters():\n",
    "            l2_reg += torch.norm(param)\n",
    "        # Backpropagation\n",
    "        cnnLoss = criterion(cnnOutputs, labels)+l2_reg*l2_lambda\n",
    "        cnnLoss.backward()\n",
    "        # Gradient update\n",
    "        optimizer.step()\n",
    "        total += 1\n",
    "        total1+=labels.size(0)\n",
    "        cnnRunningLoss += cnnLoss.item()\n",
    "        _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n",
    "        cnnCorrect += (cnnPredicted == labels).sum().item()\n",
    "    return cnnRunningLoss/total, cnnCorrect/total1\n",
    "\n",
    "def valid_epoch(cnn,device,dataloader,loss_fn):\n",
    "    cnn.eval()\n",
    "    totalLoss = 0\n",
    "    total = 0\n",
    "    total1 = 0\n",
    "    R2 = 0\n",
    "    cnnLoss = 0\n",
    "    cnnCorrect=0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to('cuda').reshape(-1,1,512,128)\n",
    "        labels = labels.to('cuda')\n",
    "        cnnOutputs = cnn(inputs)\n",
    "        cnnLoss = loss_fn(cnnOutputs, labels)\n",
    "        _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        total1 +=1\n",
    "        totalLoss += cnnLoss.item()\n",
    "        cnnCorrect += (cnnPredicted == labels).sum().item()\n",
    "    accuracy = cnnCorrect / total * 100\n",
    "    cnn.train()\n",
    "    return totalLoss/total1, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Train Loss: 2.2784704471889294, Train_acc: 0.24770833333333334, Test Loss: 2.4256094694137573, Test acc: 23.75\n",
      "Train Loss: 1.369346088484714, Train_acc: 0.570625, Test Loss: 4.2049760818481445, Test acc: 38.75\n",
      "Train Loss: 0.9799566488516959, Train_acc: 0.7070833333333333, Test Loss: 6.448573350906372, Test acc: 37.5\n",
      "Train Loss: 0.9255839601943368, Train_acc: 0.7341666666666666, Test Loss: 6.272913694381714, Test acc: 37.916666666666664\n",
      "Train Loss: 0.8777077809760445, Train_acc: 0.7489583333333333, Test Loss: 5.626957893371582, Test acc: 38.75\n",
      "Train Loss: 0.8399549832469538, Train_acc: 0.7479166666666667, Test Loss: 8.51518177986145, Test acc: 39.58333333333333\n",
      "Train Loss: 0.7893989760624734, Train_acc: 0.7595833333333334, Test Loss: 9.087461948394775, Test acc: 42.5\n",
      "Train Loss: 0.7628405251001057, Train_acc: 0.7610416666666666, Test Loss: 8.253262042999268, Test acc: 47.083333333333336\n",
      "Train Loss: 0.7316033793123145, Train_acc: 0.77125, Test Loss: 13.043965816497803, Test acc: 39.58333333333333\n",
      "Train Loss: 0.7249332070350647, Train_acc: 0.7727083333333333, Test Loss: 15.498488426208496, Test acc: 38.333333333333336\n",
      "Train Loss: 1.484815082267711, Train_acc: 0.6883333333333334, Test Loss: 3.923122525215149, Test acc: 35.0\n",
      "Train Loss: 0.8652741705116472, Train_acc: 0.735625, Test Loss: 5.288608074188232, Test acc: 43.333333333333336\n",
      "Train Loss: 0.7763254564059409, Train_acc: 0.7654166666666666, Test Loss: 8.521246433258057, Test acc: 41.66666666666667\n",
      "Train Loss: 0.8285216579311773, Train_acc: 0.7595833333333334, Test Loss: 7.130499839782715, Test acc: 40.0\n",
      "Train Loss: 0.76910253261265, Train_acc: 0.7689583333333333, Test Loss: 7.7408435344696045, Test acc: 39.58333333333333\n",
      "Train Loss: 0.7705092884992298, Train_acc: 0.7622916666666667, Test Loss: 6.685652732849121, Test acc: 40.833333333333336\n",
      "Train Loss: 0.7441557394830804, Train_acc: 0.7685416666666667, Test Loss: 10.550910949707031, Test acc: 46.25\n",
      "Train Loss: 0.7251982234026256, Train_acc: 0.7733333333333333, Test Loss: 13.566817283630371, Test acc: 46.25\n",
      "Train Loss: 0.7241995162085483, Train_acc: 0.7739583333333333, Test Loss: 13.856053352355957, Test acc: 44.166666666666664\n",
      "Train Loss: 0.7258126500405764, Train_acc: 0.7729166666666667, Test Loss: 16.021291732788086, Test acc: 46.25\n",
      "Fold 2\n",
      "Train Loss: 2.234913308369486, Train_acc: 0.23604166666666668, Test Loss: 2.5240657329559326, Test acc: 24.583333333333332\n",
      "Train Loss: 1.3230207044827311, Train_acc: 0.5925, Test Loss: 3.1784993410110474, Test acc: 35.0\n",
      "Train Loss: 0.9805335496601305, Train_acc: 0.6877083333333334, Test Loss: 6.145141363143921, Test acc: 39.58333333333333\n",
      "Train Loss: 0.93149239609116, Train_acc: 0.7129166666666666, Test Loss: 5.263727426528931, Test acc: 34.166666666666664\n",
      "Train Loss: 0.860158350906874, Train_acc: 0.7277083333333333, Test Loss: 7.857141494750977, Test acc: 35.41666666666667\n",
      "Train Loss: 0.8702366085428941, Train_acc: 0.738125, Test Loss: 6.5934484004974365, Test acc: 44.583333333333336\n",
      "Train Loss: 0.8589185429246802, Train_acc: 0.7322916666666667, Test Loss: 9.212225198745728, Test acc: 43.75\n",
      "Train Loss: 0.8728361521896563, Train_acc: 0.7322916666666667, Test Loss: 6.539017915725708, Test acc: 43.333333333333336\n",
      "Train Loss: 0.7915779822751096, Train_acc: 0.7429166666666667, Test Loss: 16.30257511138916, Test acc: 42.083333333333336\n",
      "Train Loss: 0.8397751842674456, Train_acc: 0.7360416666666667, Test Loss: 6.9975221157073975, Test acc: 38.333333333333336\n",
      "Train Loss: 0.8416049731405157, Train_acc: 0.7425, Test Loss: 4.304640173912048, Test acc: 36.25\n",
      "Train Loss: 0.8028848892764041, Train_acc: 0.7408333333333333, Test Loss: 7.7673094272613525, Test acc: 36.666666666666664\n",
      "Train Loss: 0.7772948443889618, Train_acc: 0.7460416666666667, Test Loss: 9.250657081604004, Test acc: 40.833333333333336\n",
      "Train Loss: 0.7728089580410406, Train_acc: 0.7445833333333334, Test Loss: 10.200040340423584, Test acc: 38.333333333333336\n",
      "Train Loss: 0.7650569081306458, Train_acc: 0.7477083333333333, Test Loss: 11.15378189086914, Test acc: 44.166666666666664\n",
      "Train Loss: 0.765925573675256, Train_acc: 0.7466666666666667, Test Loss: 11.926674842834473, Test acc: 42.916666666666664\n",
      "Train Loss: 0.7739718446606084, Train_acc: 0.7491666666666666, Test Loss: 10.263957738876343, Test acc: 41.66666666666667\n",
      "Train Loss: 0.8617289466293234, Train_acc: 0.7408333333333333, Test Loss: 5.67901611328125, Test acc: 41.66666666666667\n",
      "Train Loss: 0.8023663335724881, Train_acc: 0.7458333333333333, Test Loss: 6.327139139175415, Test acc: 40.416666666666664\n",
      "Train Loss: 0.7697915183870416, Train_acc: 0.7497916666666666, Test Loss: 7.403616428375244, Test acc: 40.416666666666664\n",
      "Fold 3\n",
      "Train Loss: 2.334676777061663, Train_acc: 0.22333333333333333, Test Loss: 2.0650664567947388, Test acc: 26.25\n",
      "Train Loss: 1.5103923599970968, Train_acc: 0.560625, Test Loss: 4.139209747314453, Test acc: 36.666666666666664\n",
      "Train Loss: 1.01398209051082, Train_acc: 0.6902083333333333, Test Loss: 4.192676544189453, Test acc: 35.41666666666667\n",
      "Train Loss: 0.8930031798387829, Train_acc: 0.7339583333333334, Test Loss: 5.880712509155273, Test acc: 39.58333333333333\n",
      "Train Loss: 0.8354096867536244, Train_acc: 0.7485416666666667, Test Loss: 6.836291074752808, Test acc: 38.75\n",
      "Train Loss: 0.8100424063833136, Train_acc: 0.7547916666666666, Test Loss: 6.6857969760894775, Test acc: 37.916666666666664\n",
      "Train Loss: 0.8510504019887823, Train_acc: 0.7527083333333333, Test Loss: 6.1306068897247314, Test acc: 38.333333333333336\n",
      "Train Loss: 0.782441363522881, Train_acc: 0.7579166666666667, Test Loss: 9.145859241485596, Test acc: 35.833333333333336\n",
      "Train Loss: 0.7422253897315577, Train_acc: 0.7652083333333334, Test Loss: 13.225038051605225, Test acc: 39.58333333333333\n",
      "Train Loss: 0.8095459467486331, Train_acc: 0.7527083333333333, Test Loss: 6.87035608291626, Test acc: 35.833333333333336\n",
      "Train Loss: 0.8017978072166443, Train_acc: 0.755, Test Loss: 6.748704195022583, Test acc: 39.166666666666664\n",
      "Train Loss: 0.7420762400878104, Train_acc: 0.76625, Test Loss: 10.835301399230957, Test acc: 39.166666666666664\n",
      "Train Loss: 0.7385759337952262, Train_acc: 0.7633333333333333, Test Loss: 12.763699531555176, Test acc: 39.166666666666664\n",
      "Train Loss: 0.7335546346087205, Train_acc: 0.7635416666666667, Test Loss: 14.09914255142212, Test acc: 39.58333333333333\n",
      "Train Loss: 0.730583485804106, Train_acc: 0.763125, Test Loss: 15.782683849334717, Test acc: 39.58333333333333\n",
      "Train Loss: 0.7337552293350822, Train_acc: 0.7622916666666667, Test Loss: 17.035401344299316, Test acc: 39.58333333333333\n",
      "Train Loss: 0.7545511440226906, Train_acc: 0.7595833333333334, Test Loss: 13.45176887512207, Test acc: 40.833333333333336\n",
      "Train Loss: 0.7527262552788383, Train_acc: 0.76125, Test Loss: 12.223665237426758, Test acc: 38.333333333333336\n",
      "Train Loss: 0.7347448891714999, Train_acc: 0.764375, Test Loss: 15.957998752593994, Test acc: 39.58333333333333\n",
      "Train Loss: 0.7309956754508772, Train_acc: 0.7645833333333333, Test Loss: 16.773180961608887, Test acc: 40.0\n",
      "Fold 4\n",
      "Train Loss: 2.3126644805858008, Train_acc: 0.239375, Test Loss: 2.408545970916748, Test acc: 20.0\n",
      "Train Loss: 1.4589655744402033, Train_acc: 0.5704166666666667, Test Loss: 4.388216018676758, Test acc: 22.083333333333332\n",
      "Train Loss: 0.9525583621702696, Train_acc: 0.716875, Test Loss: 3.928557872772217, Test acc: 22.916666666666664\n",
      "Train Loss: 0.8204035680545004, Train_acc: 0.7602083333333334, Test Loss: 6.425017595291138, Test acc: 24.166666666666668\n",
      "Train Loss: 0.7733932796277498, Train_acc: 0.77125, Test Loss: 6.858770847320557, Test acc: 21.666666666666668\n",
      "Train Loss: 0.6963765291791213, Train_acc: 0.7870833333333334, Test Loss: 9.66285514831543, Test acc: 24.583333333333332\n",
      "Train Loss: 0.7843807951400155, Train_acc: 0.7695833333333333, Test Loss: 7.299453973770142, Test acc: 23.75\n",
      "Train Loss: 0.7182515224343852, Train_acc: 0.7910416666666666, Test Loss: 5.524077892303467, Test acc: 28.333333333333332\n",
      "Train Loss: 0.6571968323306033, Train_acc: 0.801875, Test Loss: 7.940598964691162, Test acc: 23.333333333333332\n",
      "Train Loss: 0.6307254025810644, Train_acc: 0.8020833333333334, Test Loss: 11.440192699432373, Test acc: 24.166666666666668\n",
      "Train Loss: 0.6237598563495436, Train_acc: 0.8004166666666667, Test Loss: 14.21944808959961, Test acc: 24.583333333333332\n",
      "Train Loss: 0.6896352485606545, Train_acc: 0.7941666666666667, Test Loss: 6.795161724090576, Test acc: 22.5\n",
      "Train Loss: 0.6329687543605503, Train_acc: 0.80125, Test Loss: 9.994763851165771, Test acc: 25.0\n",
      "Train Loss: 0.6491521714549315, Train_acc: 0.795, Test Loss: 8.141991138458252, Test acc: 22.5\n",
      "Train Loss: 0.6617960796544426, Train_acc: 0.7983333333333333, Test Loss: 9.322301864624023, Test acc: 22.5\n",
      "Train Loss: 0.6398216211482098, Train_acc: 0.7997916666666667, Test Loss: 8.927711963653564, Test acc: 22.916666666666664\n",
      "Train Loss: 0.6676007352377239, Train_acc: 0.8008333333333333, Test Loss: 6.806930303573608, Test acc: 27.916666666666668\n",
      "Train Loss: 0.6287559098319003, Train_acc: 0.803125, Test Loss: 9.033936500549316, Test acc: 22.083333333333332\n",
      "Train Loss: 0.6184582420085606, Train_acc: 0.8033333333333333, Test Loss: 11.27371597290039, Test acc: 21.666666666666668\n",
      "Train Loss: 0.6204309894850379, Train_acc: 0.804375, Test Loss: 10.367360591888428, Test acc: 26.25\n",
      "Fold 5\n",
      "Train Loss: 2.2451517080005847, Train_acc: 0.25416666666666665, Test Loss: 2.3697922229766846, Test acc: 21.25\n",
      "Train Loss: 1.2474310162820315, Train_acc: 0.6122916666666667, Test Loss: 5.583430886268616, Test acc: 26.25\n",
      "Train Loss: 1.0160136818885803, Train_acc: 0.7220833333333333, Test Loss: 5.385157585144043, Test acc: 31.666666666666664\n",
      "Train Loss: 0.9021091774890297, Train_acc: 0.74375, Test Loss: 6.041749715805054, Test acc: 34.166666666666664\n",
      "Train Loss: 0.8668368599916759, Train_acc: 0.750625, Test Loss: 4.7354700565338135, Test acc: 37.5\n",
      "Train Loss: 0.8144647808451402, Train_acc: 0.7620833333333333, Test Loss: 7.210623741149902, Test acc: 38.75\n",
      "Train Loss: 0.8061136964120363, Train_acc: 0.7622916666666667, Test Loss: 7.659982442855835, Test acc: 32.916666666666664\n",
      "Train Loss: 0.8072266437505421, Train_acc: 0.7614583333333333, Test Loss: 7.775840520858765, Test acc: 35.41666666666667\n",
      "Train Loss: 0.7736639411825883, Train_acc: 0.7672916666666667, Test Loss: 6.161728143692017, Test acc: 33.33333333333333\n",
      "Train Loss: 0.7463277170532628, Train_acc: 0.7704166666666666, Test Loss: 9.964473962783813, Test acc: 31.666666666666664\n",
      "Train Loss: 0.7293405768118406, Train_acc: 0.7725, Test Loss: 13.509600162506104, Test acc: 31.666666666666664\n",
      "Train Loss: 0.7222612688415929, Train_acc: 0.7741666666666667, Test Loss: 16.16575002670288, Test acc: 33.33333333333333\n",
      "Train Loss: 0.7173027364831221, Train_acc: 0.775, Test Loss: 18.783091068267822, Test acc: 33.33333333333333\n",
      "Train Loss: 0.7145599581693348, Train_acc: 0.774375, Test Loss: 21.216666221618652, Test acc: 33.33333333333333\n",
      "Train Loss: 0.8271048727788424, Train_acc: 0.7622916666666667, Test Loss: 5.710874080657959, Test acc: 32.5\n",
      "Train Loss: 0.7724376728660182, Train_acc: 0.7654166666666666, Test Loss: 6.597464203834534, Test acc: 37.5\n",
      "Train Loss: 0.7298688590526581, Train_acc: 0.7729166666666667, Test Loss: 10.329952716827393, Test acc: 36.666666666666664\n",
      "Train Loss: 0.7272404698949111, Train_acc: 0.7735416666666667, Test Loss: 12.951377391815186, Test acc: 32.916666666666664\n",
      "Train Loss: 0.7207735918070141, Train_acc: 0.7747916666666667, Test Loss: 16.73523235321045, Test acc: 32.5\n",
      "Train Loss: 0.7154478383691687, Train_acc: 0.775, Test Loss: 18.76708221435547, Test acc: 34.166666666666664\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "X_train_v, X_test, y_train_v, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) # Split to aviod data leakage\n",
    "\n",
    "X_train_v = torch.as_tensor(X_train_v, dtype=torch.float) # an alternative to torch.from_numpy\n",
    "y_train_v = torch.as_tensor(y_train_v, dtype=torch.float)\n",
    "X_test = torch.as_tensor(X_test, dtype=torch.float)\n",
    "y_test = torch.as_tensor(y_test, dtype=torch.float)\n",
    "splits=StratifiedKFold(n_splits=5,shuffle=True,random_state=99)\n",
    "train_dataset = TensorDataset(X_train_v, y_train_v)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size=128\n",
    "models = []\n",
    "history = {'fold':[], 'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(X_train_v,y_train_v)):\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "    t = pd.DataFrame(y_train_v[train_idx], columns = ['class']).reset_index()\n",
    "    idx = []\n",
    "    # Resampling to form a balanced dataset\n",
    "    y_train = []\n",
    "    for i in range(0,12):\n",
    "      idx += list(t[t['class']==i].sample(400,replace=True)['index'])\n",
    "      y_train += [i]*400\n",
    "    X_train = X_train_v[train_idx][idx]\n",
    "\n",
    "    t = pd.DataFrame(y_train_v[val_idx], columns = ['class']).reset_index()\n",
    "    idx = []\n",
    "    y_val = []\n",
    "    for i in range(0,12):\n",
    "      # print(i)\n",
    "      if i in t['class'].values:\n",
    "          idx += list(t[t['class']==i].sample(20,replace=True)['index'])\n",
    "          y_val += [i]*20\n",
    "    X_val =  X_train_v[val_idx][idx]\n",
    "\n",
    "    X_train = torch.as_tensor(X_train, dtype=torch.float) # an alternative to torch.from_numpy\n",
    "    y_train = torch.as_tensor(y_train, dtype=torch.float).type(torch.LongTensor)\n",
    "    X_val = torch.as_tensor(X_val, dtype=torch.float)\n",
    "    y_val = torch.as_tensor(y_val, dtype=torch.float).type(torch.LongTensor)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "    \n",
    "    model = CNNModel(hiddenSize, numFilters, dropoutRate, activation).to('cuda')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(list(model.parameters()), lr=learningRate, momentum=momentum)\n",
    "    # optimizer = torch.optim.Adam(list(model.parameters()), lr=learningRate)\n",
    "    best_test = -np.inf\n",
    "    best_model = None\n",
    "    #Train the model\n",
    "    for epoch in range(numEpochs):\n",
    "        train_loss, train_R2=train_epoch(model,device,train_dataloader,criterion,optimizer)\n",
    "        test_loss, test_R2=valid_epoch(model,device,test_dataloader,criterion)\n",
    "        history['fold'].append(fold)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['train_acc'].append(train_R2)\n",
    "        history['test_acc'].append(test_R2)   \n",
    "        if test_R2>best_test:\n",
    "            test_test = test_R2\n",
    "            best_model = model\n",
    "        print('Train Loss: {}, Train_acc: {}, Test Loss: {}, Test acc: {}'.format(train_loss, train_R2, test_loss, test_R2))\n",
    "    models.append([best_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the average accuracy of the 5-fold best models\n",
    "X_train_v, X_test, y_train_v, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "t = pd.DataFrame(y_test, columns = ['class']).reset_index()\n",
    "idx = []\n",
    "y_test = []\n",
    "for i in range(0,12):\n",
    "    if i in t['class'].values:\n",
    "        idx += list(t[t['class']==i].sample(20,replace=True)['index'])\n",
    "        y_test += [i]*20\n",
    "X_test =  X_test[idx]\n",
    "X_test = torch.as_tensor(X_test, dtype=torch.float)\n",
    "y_test = torch.as_tensor(y_test, dtype=torch.float).type(torch.LongTensor)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "acc=[]\n",
    "for best_model in models:\n",
    "    acc.append(valid_epoch(best_model[0],device,test_dataloader,criterion)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.91666666666667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the accuray with majority votes\n",
    "outputs = []    \n",
    "for model in models:\n",
    "  model[0].eval()\n",
    "  model_output = []\n",
    "  label_= []\n",
    "  model[0].to('cpu')\n",
    "  for inputs, labels in test_dataloader:\n",
    "      inputs = inputs.to('cpu').reshape(-1,1,512,128)\n",
    "      labels = labels.to('cpu')\n",
    "      cnnOutputs = model[0](inputs)\n",
    "      model_output.append(cnnOutputs)\n",
    "      label_.append(labels)\n",
    "  outputs.append(torch.vstack(model_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnnresult = torch.vstack(outputs).reshape(-1,shape[0],shape[1]).mean(axis=0)\n",
    "labels = np.hstack(label_)\n",
    "_, cnnPredicted = torch.max(cnnresult.data, 1)\n",
    "cnnCorrect = (cnnPredicted.detach().numpy() == labels).sum().item()\n",
    "cnnCorrect/len(labels)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confu_m = confusion_matrix(labels, cnnPredicted)\n",
    "import seaborn as sns\n",
    "sns.heatmap(confu_m,square=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry': 0,\n",
       " 'awe': 1,\n",
       " 'emotional': 2,\n",
       " 'excited': 3,\n",
       " 'fear': 4,\n",
       " 'happy': 5,\n",
       " 'hopeful': 6,\n",
       " 'hurt': 7,\n",
       " 'love': 8,\n",
       " 'negative': 9,\n",
       " 'positive': 10,\n",
       " 'sadness': 11}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the labels\n",
    "label_dict = {}\n",
    "for cl in le.classes_:\n",
    "    label_dict.update({cl:le.transform([cl])[0]})\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angry</th>\n",
       "      <th>awe</th>\n",
       "      <th>emotional</th>\n",
       "      <th>excited</th>\n",
       "      <th>fear</th>\n",
       "      <th>happy</th>\n",
       "      <th>hopeful</th>\n",
       "      <th>hurt</th>\n",
       "      <th>love</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.150943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.219178</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.576923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               angry        awe  emotional  excited      fear      happy  \\\n",
       "precision   0.400000   0.750000   0.350000     0.25  0.350000   0.550000   \n",
       "recall      0.150943   1.000000   0.583333     1.00  1.000000   0.148649   \n",
       "f1          0.219178   0.857143   0.437500     0.40  0.518519   0.234043   \n",
       "support    53.000000  15.000000  12.000000     5.00  7.000000  74.000000   \n",
       "\n",
       "           hopeful      hurt       love   negative  positive    sadness  \n",
       "precision      0.0  0.300000   0.350000   0.550000  0.200000   0.750000  \n",
       "recall         0.0  1.000000   0.368421   1.000000  0.666667   0.468750  \n",
       "f1             0.0  0.461538   0.358974   0.709677  0.307692   0.576923  \n",
       "support        0.0  6.000000  19.000000  11.000000  6.000000  32.000000  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the evaluation scores\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "scores = pd.DataFrame(precision_recall_fscore_support(cnnPredicted, labels, labels = list(range(12))),index=['precision','recall','f1','support'], columns = list(label_dict)[:12])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open('midi_test_data','rb')\n",
    "music_data = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Across_The_Stars(StarWar_II_Love_Theme) happy negative sadness\n",
      "PAL1_theme-仙剑1 happy love sadness\n",
      "上海滩 happy sadness negative\n",
      "月光奏鸣曲 happy love negative\n",
      "枉凝眉 happy positive love\n",
      "水调歌头·明月几时有 sadness love hurt\n",
      "沧海一声笑 love angry sadness\n",
      "笑傲江湖 sadness happy negative\n",
      "铁血丹心 happy negative sadness\n",
      "难念的经-天龙八部 sadness happy love\n",
      "青花瓷 happy negative love\n"
     ]
    }
   ],
   "source": [
    "# Try the classification on some pure or Chinese music\n",
    "X_test_1 = []\n",
    "name = []\n",
    "for m in music_data:\n",
    "    if m[0].shape[0]>=612:\n",
    "        X_test_1.append(m[0][100:612,:])\n",
    "        name.append(m[1])\n",
    "X_test_1 = np.array(X_test_1)\n",
    "y_test_1 = models[0][0](torch.as_tensor(X_test_1.reshape(-1,1,512,128), dtype=torch.float))\n",
    "label = torch.argsort(-y_test_1).to('cpu').numpy()\n",
    "for i in range(len(label)):\n",
    "    print(name[i],le.classes_[label[i][0]], le.classes_[label[i][1]], le.classes_[label[i][2]])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
