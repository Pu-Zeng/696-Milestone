{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3-ChWZxV6Q4f",
    "outputId": "40700328-f8eb-48ad-e076-40ac59995dc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/MyDrive/Milestone 2/music_data.zip\n",
      "  inflating: /content/drive/MyDrive/Milestone 2/music_data1.bin  \n",
      "  inflating: /content/drive/MyDrive/Milestone 2/music_data2.bin  \n",
      "  inflating: /content/drive/MyDrive/Milestone 2/music_data3.bin  \n",
      "  inflating: /content/drive/MyDrive/Milestone 2/music_data4.bin  \n",
      "  inflating: /content/drive/MyDrive/Milestone 2/music_data5.bin  \n",
      "  inflating: /content/drive/MyDrive/Milestone 2/music_data6.bin  \n",
      "  inflating: /content/drive/MyDrive/Milestone 2/music_data7.bin  \n",
      "  inflating: /content/drive/MyDrive/Milestone 2/music_data8.bin  \n",
      "  inflating: /content/drive/MyDrive/Milestone 2/music_data9.bin  \n"
     ]
    }
   ],
   "source": [
    "!unzip \"/content/drive/MyDrive/Milestone 2/music_data.zip\" -d \"/content/drive/MyDrive/Milestone 2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wRF6FLeb5DXz"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "u8eSS9tg62ge",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# import mido\n",
    "import string\n",
    "import numpy as np\n",
    "# from utilis import get_pianoroll_data\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# import mido\n",
    "import string\n",
    "import numpy as np\n",
    "# from utilis import get_pianoroll_data\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file=open(\"single_word_emotion_music1.bin\",\"rb\")\n",
    "music_data = pickle.load(file) #保存list到文件\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"a-livin'\", 'accaderelo', 'achey', 'acquittaloe', 'adagio',\n",
       "       'adolescent', 'adrift', 'african', 'ah!', 'aha', 'ahdammi', 'ahh',\n",
       "       'ahi', 'amazing', 'amore', 'amoree', 'anger', 'angry', 'arousal',\n",
       "       \"avversita'\", 'awe', 'ayayay', 'beautiful', 'bene', 'comfort',\n",
       "       'confused', 'darkness', 'depressed', \"e'\", 'e.universo', 'ecstasy',\n",
       "       'eh', 'eloquent', 'emo', 'emocionante', 'emotion', 'emotional',\n",
       "       'emozione', 'empathetic', 'enlightened', 'esattamente', 'esattro',\n",
       "       'etu', 'euphoria',\n",
       "       'evtiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii', 'excited',\n",
       "       'fear', 'fearful', 'fearless', 'free', 'freedom', 'frightened',\n",
       "       'frightful', 'good', 'grateful', 'happy', 'happyness',\n",
       "       'heaialcupation', 'heartbreak', 'helpful', 'hopeful', 'hurt',\n",
       "       'hysterical', 'i', \"i'm\", 'iose', 'irritated', 'joy', 'joyous',\n",
       "       'lonely', 'love', 'money', 'negative', 'new', 'nostalgic',\n",
       "       'positive', 'powerful', \"rainin'\", 'sad', 'sadness', 'scared',\n",
       "       'shame', 'strong', 'tender', 'tenderness', 'time', 'tired',\n",
       "       'tiredness', 'uneasy', 'unsure', 'upset', 'vain'], dtype='<U49')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([x[1] for x in music_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1122"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array([x[0].shape[0] for x in music_data])>612).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "a5ONeVUU7MOU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "X = []\n",
    "y = []\n",
    "chosen_label = ['sadness', 'happy', 'love', 'joy', 'negative', 'positive', 'anger',\n",
    "       'awe', 'emotional', 'hopeful', 'angry', 'excited', 'fear', 'hurt',\n",
    "       'fearful']\n",
    "# for i in tqdm(range(1,10)):\n",
    "file=open(\"single_word_emotion_music1.bin\",\"rb\")\n",
    "music_data = pickle.load(file) #保存list到文件\n",
    "file.close()\n",
    "for m in music_data:\n",
    "    if m[0].shape[0]>=612 and m[1] in chosen_label:\n",
    "        X.append(m[0][100:612,:])\n",
    "        if m[1] == 'anger':\n",
    "            m[1] = 'angry'\n",
    "        if m[1] == 'fearful':\n",
    "            m[1] = 'fear'\n",
    "        if m[1] == 'joy':\n",
    "            m[1] = 'happy'\n",
    "        y.append(m[1])\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['angry', 'awe', 'emotional', 'excited', 'fear', 'happy', 'hopeful',\n",
       "       'hurt', 'love', 'negative', 'positive', 'sadness'], dtype='<U9')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import torch\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "label_dict = {}\n",
    "for cl in le.classes_:\n",
    "    label_dict.update({cl:le.transform([cl])[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, hiddenSize, outChannels, dropoutRate, activate):\n",
    "        super().__init__()\n",
    "        self.outChannels = outChannels\n",
    "        self.activate = nn.Sigmoid() if activate == \"Sigmoid\" else nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(1, 24, (10,1))\n",
    "        self.pool = nn.MaxPool2d((2, 1))\n",
    "        self.conv2 = nn.Conv2d(24, 48, (10,1))\n",
    "        self.conv3 = nn.Conv2d(48, 96, (10,1))\n",
    "        self.conv4 = nn.Conv2d(96, 192, (10,1))\n",
    "        self.conv5 = nn.Conv2d(192, 384, (5,2))\n",
    "        self.conv6 = nn.Conv2d(384, 192, (5,2))\n",
    "        self.dense1 = nn.Linear(48384, hiddenSize)\n",
    "        self.dropout = nn.Dropout(dropoutRate)\n",
    "        self.dense2 = nn.Linear(hiddenSize, 12)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.activate(self.conv1(x)))\n",
    "        x = self.pool(self.activate(self.conv2(x)))\n",
    "        # print(x.shape)\n",
    "        x = self.dropout(self.pool(self.activate(self.conv3(x))))\n",
    "        x = self.pool(self.activate(self.conv4(x)))\n",
    "        x = self.pool(self.activate(self.conv5(x)))\n",
    "        x = self.pool(self.activate(self.conv6(x)))\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 48384)\n",
    "        x = self.dropout(self.activate(self.dense1(x)))\n",
    "        return self.dense2(x)\n",
    "\n",
    "# Number of neurons in the first fully-connected layer\n",
    "hiddenSize = 4096\n",
    "# Number of feature filters in second convolutional layer\n",
    "numFilters = 25\n",
    "# Dropout rate\n",
    "dropoutRate = 0.2\n",
    "# Activation function\n",
    "activation = \"ReLU\"\n",
    "# Learning rate\n",
    "learningRate = 0.005\n",
    "# Momentum for SGD optimizer\n",
    "momentum = 0.9\n",
    "# Number of training epochs\n",
    "numEpochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train_epoch(cnn,device,dataloader,loss_fn,optimizer):\n",
    "    cnn.train()\n",
    "    cnnRunningLoss = 0\n",
    "    total = 0\n",
    "    R2 = 0\n",
    "    cnnCorrect=0\n",
    "    total1=0\n",
    "    for i, (inputs, labels) in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to('cuda').reshape(-1,1,512,128)\n",
    "        \n",
    "        labels = labels.to('cuda')\n",
    "        # Forward propagation\n",
    "        cnnOutputs = cnn(inputs)\n",
    "        # print(cnnOutputs.shape)\n",
    "        l2_lambda = 0.001\n",
    "        l2_reg = torch.tensor(0.).to('cuda')\n",
    "        for param in cnn.parameters():\n",
    "            l2_reg += torch.norm(param)\n",
    "        # Backpropagation\n",
    "        cnnLoss = criterion(cnnOutputs, labels)+l2_reg*l2_lambda\n",
    "        cnnLoss.backward()\n",
    "        # Gradient update\n",
    "        optimizer.step()\n",
    "        total += 1\n",
    "        total1+=labels.size(0)\n",
    "        cnnRunningLoss += cnnLoss.item()\n",
    "        _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n",
    "        cnnCorrect += (cnnPredicted == labels).sum().item()\n",
    "    return cnnRunningLoss/total, cnnCorrect/total1\n",
    "\n",
    "def valid_epoch(cnn,device,dataloader,loss_fn):\n",
    "    cnn.eval()\n",
    "    totalLoss = 0\n",
    "    total = 0\n",
    "    total1 = 0\n",
    "    R2 = 0\n",
    "    cnnLoss = 0\n",
    "    cnnCorrect=0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to('cuda').reshape(-1,1,512,128)\n",
    "        labels = labels.to('cuda')\n",
    "        cnnOutputs = cnn(inputs)\n",
    "        cnnLoss = loss_fn(cnnOutputs, labels)\n",
    "        _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        total1 +=1\n",
    "        totalLoss += cnnLoss.item()\n",
    "        cnnCorrect += (cnnPredicted == labels).sum().item()\n",
    "    accuracy = cnnCorrect / total * 100\n",
    "    cnn.train()\n",
    "    return totalLoss/total1, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "         2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,\n",
       "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,\n",
       "         7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,\n",
       "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "         9,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "        10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "        11, 11, 11, 11, 11, 11])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Train Loss: 2.2784704471889294, Train_acc: 0.24770833333333334, Test Loss: 2.4256094694137573, Test acc: 23.75\n",
      "Train Loss: 1.369346088484714, Train_acc: 0.570625, Test Loss: 4.2049760818481445, Test acc: 38.75\n",
      "Train Loss: 0.9799566488516959, Train_acc: 0.7070833333333333, Test Loss: 6.448573350906372, Test acc: 37.5\n",
      "Train Loss: 0.9255839601943368, Train_acc: 0.7341666666666666, Test Loss: 6.272913694381714, Test acc: 37.916666666666664\n",
      "Train Loss: 0.8777077809760445, Train_acc: 0.7489583333333333, Test Loss: 5.626957893371582, Test acc: 38.75\n",
      "Train Loss: 0.8399549832469538, Train_acc: 0.7479166666666667, Test Loss: 8.51518177986145, Test acc: 39.58333333333333\n",
      "Train Loss: 0.7893989760624734, Train_acc: 0.7595833333333334, Test Loss: 9.087461948394775, Test acc: 42.5\n",
      "Train Loss: 0.7628405251001057, Train_acc: 0.7610416666666666, Test Loss: 8.253262042999268, Test acc: 47.083333333333336\n",
      "Train Loss: 0.7316033793123145, Train_acc: 0.77125, Test Loss: 13.043965816497803, Test acc: 39.58333333333333\n",
      "Train Loss: 0.7249332070350647, Train_acc: 0.7727083333333333, Test Loss: 15.498488426208496, Test acc: 38.333333333333336\n",
      "Train Loss: 1.484815082267711, Train_acc: 0.6883333333333334, Test Loss: 3.923122525215149, Test acc: 35.0\n",
      "Train Loss: 0.8652741705116472, Train_acc: 0.735625, Test Loss: 5.288608074188232, Test acc: 43.333333333333336\n",
      "Train Loss: 0.7763254564059409, Train_acc: 0.7654166666666666, Test Loss: 8.521246433258057, Test acc: 41.66666666666667\n",
      "Train Loss: 0.8285216579311773, Train_acc: 0.7595833333333334, Test Loss: 7.130499839782715, Test acc: 40.0\n",
      "Train Loss: 0.76910253261265, Train_acc: 0.7689583333333333, Test Loss: 7.7408435344696045, Test acc: 39.58333333333333\n",
      "Train Loss: 0.7705092884992298, Train_acc: 0.7622916666666667, Test Loss: 6.685652732849121, Test acc: 40.833333333333336\n",
      "Train Loss: 0.7441557394830804, Train_acc: 0.7685416666666667, Test Loss: 10.550910949707031, Test acc: 46.25\n",
      "Train Loss: 0.7251982234026256, Train_acc: 0.7733333333333333, Test Loss: 13.566817283630371, Test acc: 46.25\n",
      "Train Loss: 0.7241995162085483, Train_acc: 0.7739583333333333, Test Loss: 13.856053352355957, Test acc: 44.166666666666664\n",
      "Train Loss: 0.7258126500405764, Train_acc: 0.7729166666666667, Test Loss: 16.021291732788086, Test acc: 46.25\n",
      "Fold 2\n",
      "Train Loss: 2.234913308369486, Train_acc: 0.23604166666666668, Test Loss: 2.5240657329559326, Test acc: 24.583333333333332\n",
      "Train Loss: 1.3230207044827311, Train_acc: 0.5925, Test Loss: 3.1784993410110474, Test acc: 35.0\n",
      "Train Loss: 0.9805335496601305, Train_acc: 0.6877083333333334, Test Loss: 6.145141363143921, Test acc: 39.58333333333333\n",
      "Train Loss: 0.93149239609116, Train_acc: 0.7129166666666666, Test Loss: 5.263727426528931, Test acc: 34.166666666666664\n",
      "Train Loss: 0.860158350906874, Train_acc: 0.7277083333333333, Test Loss: 7.857141494750977, Test acc: 35.41666666666667\n",
      "Train Loss: 0.8702366085428941, Train_acc: 0.738125, Test Loss: 6.5934484004974365, Test acc: 44.583333333333336\n",
      "Train Loss: 0.8589185429246802, Train_acc: 0.7322916666666667, Test Loss: 9.212225198745728, Test acc: 43.75\n",
      "Train Loss: 0.8728361521896563, Train_acc: 0.7322916666666667, Test Loss: 6.539017915725708, Test acc: 43.333333333333336\n",
      "Train Loss: 0.7915779822751096, Train_acc: 0.7429166666666667, Test Loss: 16.30257511138916, Test acc: 42.083333333333336\n",
      "Train Loss: 0.8397751842674456, Train_acc: 0.7360416666666667, Test Loss: 6.9975221157073975, Test acc: 38.333333333333336\n",
      "Train Loss: 0.8416049731405157, Train_acc: 0.7425, Test Loss: 4.304640173912048, Test acc: 36.25\n",
      "Train Loss: 0.8028848892764041, Train_acc: 0.7408333333333333, Test Loss: 7.7673094272613525, Test acc: 36.666666666666664\n",
      "Train Loss: 0.7772948443889618, Train_acc: 0.7460416666666667, Test Loss: 9.250657081604004, Test acc: 40.833333333333336\n",
      "Train Loss: 0.7728089580410406, Train_acc: 0.7445833333333334, Test Loss: 10.200040340423584, Test acc: 38.333333333333336\n",
      "Train Loss: 0.7650569081306458, Train_acc: 0.7477083333333333, Test Loss: 11.15378189086914, Test acc: 44.166666666666664\n",
      "Train Loss: 0.765925573675256, Train_acc: 0.7466666666666667, Test Loss: 11.926674842834473, Test acc: 42.916666666666664\n",
      "Train Loss: 0.7739718446606084, Train_acc: 0.7491666666666666, Test Loss: 10.263957738876343, Test acc: 41.66666666666667\n",
      "Train Loss: 0.8617289466293234, Train_acc: 0.7408333333333333, Test Loss: 5.67901611328125, Test acc: 41.66666666666667\n",
      "Train Loss: 0.8023663335724881, Train_acc: 0.7458333333333333, Test Loss: 6.327139139175415, Test acc: 40.416666666666664\n",
      "Train Loss: 0.7697915183870416, Train_acc: 0.7497916666666666, Test Loss: 7.403616428375244, Test acc: 40.416666666666664\n",
      "Fold 3\n",
      "Train Loss: 2.334676777061663, Train_acc: 0.22333333333333333, Test Loss: 2.0650664567947388, Test acc: 26.25\n",
      "Train Loss: 1.5103923599970968, Train_acc: 0.560625, Test Loss: 4.139209747314453, Test acc: 36.666666666666664\n",
      "Train Loss: 1.01398209051082, Train_acc: 0.6902083333333333, Test Loss: 4.192676544189453, Test acc: 35.41666666666667\n",
      "Train Loss: 0.8930031798387829, Train_acc: 0.7339583333333334, Test Loss: 5.880712509155273, Test acc: 39.58333333333333\n",
      "Train Loss: 0.8354096867536244, Train_acc: 0.7485416666666667, Test Loss: 6.836291074752808, Test acc: 38.75\n",
      "Train Loss: 0.8100424063833136, Train_acc: 0.7547916666666666, Test Loss: 6.6857969760894775, Test acc: 37.916666666666664\n",
      "Train Loss: 0.8510504019887823, Train_acc: 0.7527083333333333, Test Loss: 6.1306068897247314, Test acc: 38.333333333333336\n",
      "Train Loss: 0.782441363522881, Train_acc: 0.7579166666666667, Test Loss: 9.145859241485596, Test acc: 35.833333333333336\n",
      "Train Loss: 0.7422253897315577, Train_acc: 0.7652083333333334, Test Loss: 13.225038051605225, Test acc: 39.58333333333333\n",
      "Train Loss: 0.8095459467486331, Train_acc: 0.7527083333333333, Test Loss: 6.87035608291626, Test acc: 35.833333333333336\n",
      "Train Loss: 0.8017978072166443, Train_acc: 0.755, Test Loss: 6.748704195022583, Test acc: 39.166666666666664\n",
      "Train Loss: 0.7420762400878104, Train_acc: 0.76625, Test Loss: 10.835301399230957, Test acc: 39.166666666666664\n",
      "Train Loss: 0.7385759337952262, Train_acc: 0.7633333333333333, Test Loss: 12.763699531555176, Test acc: 39.166666666666664\n",
      "Train Loss: 0.7335546346087205, Train_acc: 0.7635416666666667, Test Loss: 14.09914255142212, Test acc: 39.58333333333333\n",
      "Train Loss: 0.730583485804106, Train_acc: 0.763125, Test Loss: 15.782683849334717, Test acc: 39.58333333333333\n",
      "Train Loss: 0.7337552293350822, Train_acc: 0.7622916666666667, Test Loss: 17.035401344299316, Test acc: 39.58333333333333\n",
      "Train Loss: 0.7545511440226906, Train_acc: 0.7595833333333334, Test Loss: 13.45176887512207, Test acc: 40.833333333333336\n",
      "Train Loss: 0.7527262552788383, Train_acc: 0.76125, Test Loss: 12.223665237426758, Test acc: 38.333333333333336\n",
      "Train Loss: 0.7347448891714999, Train_acc: 0.764375, Test Loss: 15.957998752593994, Test acc: 39.58333333333333\n",
      "Train Loss: 0.7309956754508772, Train_acc: 0.7645833333333333, Test Loss: 16.773180961608887, Test acc: 40.0\n",
      "Fold 4\n",
      "Train Loss: 2.3126644805858008, Train_acc: 0.239375, Test Loss: 2.408545970916748, Test acc: 20.0\n",
      "Train Loss: 1.4589655744402033, Train_acc: 0.5704166666666667, Test Loss: 4.388216018676758, Test acc: 22.083333333333332\n",
      "Train Loss: 0.9525583621702696, Train_acc: 0.716875, Test Loss: 3.928557872772217, Test acc: 22.916666666666664\n",
      "Train Loss: 0.8204035680545004, Train_acc: 0.7602083333333334, Test Loss: 6.425017595291138, Test acc: 24.166666666666668\n",
      "Train Loss: 0.7733932796277498, Train_acc: 0.77125, Test Loss: 6.858770847320557, Test acc: 21.666666666666668\n",
      "Train Loss: 0.6963765291791213, Train_acc: 0.7870833333333334, Test Loss: 9.66285514831543, Test acc: 24.583333333333332\n",
      "Train Loss: 0.7843807951400155, Train_acc: 0.7695833333333333, Test Loss: 7.299453973770142, Test acc: 23.75\n",
      "Train Loss: 0.7182515224343852, Train_acc: 0.7910416666666666, Test Loss: 5.524077892303467, Test acc: 28.333333333333332\n",
      "Train Loss: 0.6571968323306033, Train_acc: 0.801875, Test Loss: 7.940598964691162, Test acc: 23.333333333333332\n",
      "Train Loss: 0.6307254025810644, Train_acc: 0.8020833333333334, Test Loss: 11.440192699432373, Test acc: 24.166666666666668\n",
      "Train Loss: 0.6237598563495436, Train_acc: 0.8004166666666667, Test Loss: 14.21944808959961, Test acc: 24.583333333333332\n",
      "Train Loss: 0.6896352485606545, Train_acc: 0.7941666666666667, Test Loss: 6.795161724090576, Test acc: 22.5\n",
      "Train Loss: 0.6329687543605503, Train_acc: 0.80125, Test Loss: 9.994763851165771, Test acc: 25.0\n",
      "Train Loss: 0.6491521714549315, Train_acc: 0.795, Test Loss: 8.141991138458252, Test acc: 22.5\n",
      "Train Loss: 0.6617960796544426, Train_acc: 0.7983333333333333, Test Loss: 9.322301864624023, Test acc: 22.5\n",
      "Train Loss: 0.6398216211482098, Train_acc: 0.7997916666666667, Test Loss: 8.927711963653564, Test acc: 22.916666666666664\n",
      "Train Loss: 0.6676007352377239, Train_acc: 0.8008333333333333, Test Loss: 6.806930303573608, Test acc: 27.916666666666668\n",
      "Train Loss: 0.6287559098319003, Train_acc: 0.803125, Test Loss: 9.033936500549316, Test acc: 22.083333333333332\n",
      "Train Loss: 0.6184582420085606, Train_acc: 0.8033333333333333, Test Loss: 11.27371597290039, Test acc: 21.666666666666668\n",
      "Train Loss: 0.6204309894850379, Train_acc: 0.804375, Test Loss: 10.367360591888428, Test acc: 26.25\n",
      "Fold 5\n",
      "Train Loss: 2.2451517080005847, Train_acc: 0.25416666666666665, Test Loss: 2.3697922229766846, Test acc: 21.25\n",
      "Train Loss: 1.2474310162820315, Train_acc: 0.6122916666666667, Test Loss: 5.583430886268616, Test acc: 26.25\n",
      "Train Loss: 1.0160136818885803, Train_acc: 0.7220833333333333, Test Loss: 5.385157585144043, Test acc: 31.666666666666664\n",
      "Train Loss: 0.9021091774890297, Train_acc: 0.74375, Test Loss: 6.041749715805054, Test acc: 34.166666666666664\n",
      "Train Loss: 0.8668368599916759, Train_acc: 0.750625, Test Loss: 4.7354700565338135, Test acc: 37.5\n",
      "Train Loss: 0.8144647808451402, Train_acc: 0.7620833333333333, Test Loss: 7.210623741149902, Test acc: 38.75\n",
      "Train Loss: 0.8061136964120363, Train_acc: 0.7622916666666667, Test Loss: 7.659982442855835, Test acc: 32.916666666666664\n",
      "Train Loss: 0.8072266437505421, Train_acc: 0.7614583333333333, Test Loss: 7.775840520858765, Test acc: 35.41666666666667\n",
      "Train Loss: 0.7736639411825883, Train_acc: 0.7672916666666667, Test Loss: 6.161728143692017, Test acc: 33.33333333333333\n",
      "Train Loss: 0.7463277170532628, Train_acc: 0.7704166666666666, Test Loss: 9.964473962783813, Test acc: 31.666666666666664\n",
      "Train Loss: 0.7293405768118406, Train_acc: 0.7725, Test Loss: 13.509600162506104, Test acc: 31.666666666666664\n",
      "Train Loss: 0.7222612688415929, Train_acc: 0.7741666666666667, Test Loss: 16.16575002670288, Test acc: 33.33333333333333\n",
      "Train Loss: 0.7173027364831221, Train_acc: 0.775, Test Loss: 18.783091068267822, Test acc: 33.33333333333333\n",
      "Train Loss: 0.7145599581693348, Train_acc: 0.774375, Test Loss: 21.216666221618652, Test acc: 33.33333333333333\n",
      "Train Loss: 0.8271048727788424, Train_acc: 0.7622916666666667, Test Loss: 5.710874080657959, Test acc: 32.5\n",
      "Train Loss: 0.7724376728660182, Train_acc: 0.7654166666666666, Test Loss: 6.597464203834534, Test acc: 37.5\n",
      "Train Loss: 0.7298688590526581, Train_acc: 0.7729166666666667, Test Loss: 10.329952716827393, Test acc: 36.666666666666664\n",
      "Train Loss: 0.7272404698949111, Train_acc: 0.7735416666666667, Test Loss: 12.951377391815186, Test acc: 32.916666666666664\n",
      "Train Loss: 0.7207735918070141, Train_acc: 0.7747916666666667, Test Loss: 16.73523235321045, Test acc: 32.5\n",
      "Train Loss: 0.7154478383691687, Train_acc: 0.775, Test Loss: 18.76708221435547, Test acc: 34.166666666666664\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "X_train_v, X_test, y_train_v, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_train_v = torch.as_tensor(X_train_v, dtype=torch.float) # an alternative to torch.from_numpy\n",
    "y_train_v = torch.as_tensor(y_train_v, dtype=torch.float)\n",
    "X_test = torch.as_tensor(X_test, dtype=torch.float)\n",
    "y_test = torch.as_tensor(y_test, dtype=torch.float)\n",
    "splits=StratifiedKFold(n_splits=5,shuffle=True,random_state=99)\n",
    "train_dataset = TensorDataset(X_train_v, y_train_v)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size=128\n",
    "models = []\n",
    "history = {'fold':[], 'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(X_train_v,y_train_v)):\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "    t = pd.DataFrame(y_train_v[train_idx], columns = ['class']).reset_index()\n",
    "    idx = []\n",
    "    y_train = []\n",
    "    for i in range(0,12):\n",
    "      idx += list(t[t['class']==i].sample(400,replace=True)['index'])\n",
    "      y_train += [i]*400\n",
    "    X_train = X_train_v[train_idx][idx]\n",
    "\n",
    "    t = pd.DataFrame(y_train_v[val_idx], columns = ['class']).reset_index()\n",
    "    idx = []\n",
    "    y_val = []\n",
    "    for i in range(0,12):\n",
    "      # print(i)\n",
    "      if i in t['class'].values:\n",
    "          idx += list(t[t['class']==i].sample(20,replace=True)['index'])\n",
    "          y_val += [i]*20\n",
    "    X_val =  X_train_v[val_idx][idx]\n",
    "\n",
    "    X_train = torch.as_tensor(X_train, dtype=torch.float) # an alternative to torch.from_numpy\n",
    "    y_train = torch.as_tensor(y_train, dtype=torch.float).type(torch.LongTensor)\n",
    "    X_val = torch.as_tensor(X_val, dtype=torch.float)\n",
    "    y_val = torch.as_tensor(y_val, dtype=torch.float).type(torch.LongTensor)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "    \n",
    "    model = CNNModel(hiddenSize, numFilters, dropoutRate, activation).to('cuda')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(list(model.parameters()), lr=learningRate, momentum=momentum)\n",
    "    # optimizer = torch.optim.Adam(list(model.parameters()), lr=learningRate)\n",
    "    best_test = -np.inf\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(numEpochs):\n",
    "        train_loss, train_R2=train_epoch(model,device,train_dataloader,criterion,optimizer)\n",
    "        test_loss, test_R2=valid_epoch(model,device,test_dataloader,criterion)\n",
    "        history['fold'].append(fold)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['train_acc'].append(train_R2)\n",
    "        history['test_acc'].append(test_R2)   \n",
    "        if test_R2>best_test:\n",
    "            test_test = test_R2\n",
    "            best_model = model\n",
    "        print('Train Loss: {}, Train_acc: {}, Test Loss: {}, Test acc: {}'.format(train_loss, train_R2, test_loss, test_R2))\n",
    "    models.append([best_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_v, X_test, y_train_v, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "t = pd.DataFrame(y_test, columns = ['class']).reset_index()\n",
    "idx = []\n",
    "y_test = []\n",
    "for i in range(0,12):\n",
    "    if i in t['class'].values:\n",
    "        idx += list(t[t['class']==i].sample(20,replace=True)['index'])\n",
    "        y_test += [i]*20\n",
    "X_test =  X_test[idx]\n",
    "X_test = torch.as_tensor(X_test, dtype=torch.float)\n",
    "y_test = torch.as_tensor(y_test, dtype=torch.float).type(torch.LongTensor)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "acc=[]\n",
    "for best_model in models:\n",
    "    acc.append(valid_epoch(best_model[0],device,test_dataloader,criterion)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.91666666666667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(models,device,dataloader,loss_fn):\n",
    "    outputs = []    \n",
    "    for model in models:\n",
    "      model[0].eval()\n",
    "      model_output = []\n",
    "      for inputs, labels in dataloader:\n",
    "          inputs = inputs.to('cuda').reshape(-1,512,128)\n",
    "          labels = labels.to('cuda')\n",
    "          cnnOutputs = model[0](inputs)\n",
    "          model_output.append(cnnOutputs)\n",
    "      outputs.append(torch.tensor(model_output))\n",
    "\n",
    "    # totalLoss = 0\n",
    "    # total = 0\n",
    "    # total1 = 0\n",
    "    # R2 = 0\n",
    "    # cnnLoss = 0\n",
    "    # cnnCorrect=0\n",
    "    # cnnLoss = criterion(cnnOutputs, labels)\n",
    "    # _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n",
    "    # total += labels.size(0)\n",
    "    # total1 +=1\n",
    "    # totalLoss += cnnLoss.item()\n",
    "    # cnnCorrect += (cnnPredicted == labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = []    \n",
    "for model in models:\n",
    "  model[0].eval()\n",
    "  model_output = []\n",
    "  label_= []\n",
    "  model[0].to('cpu')\n",
    "  for inputs, labels in test_dataloader:\n",
    "      inputs = inputs.to('cpu').reshape(-1,1,512,128)\n",
    "      labels = labels.to('cpu')\n",
    "      cnnOutputs = model[0](inputs)\n",
    "      model_output.append(cnnOutputs)\n",
    "      label_.append(labels)\n",
    "  outputs.append(torch.vstack(model_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([240, 12])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = outputs[0].shape\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnnresult = torch.vstack(outputs).reshape(-1,shape[0],shape[1]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = np.hstack(label_)\n",
    "_, cnnPredicted = torch.max(cnnresult.data, 1)\n",
    "cnnCorrect = (cnnPredicted.detach().numpy() == labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnnCorrect/len(labels)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confu_m = confusion_matrix(labels, cnnPredicted)\n",
    "import seaborn as sns\n",
    "sns.heatmap(confu_m,square=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry': 0,\n",
       " 'awe': 1,\n",
       " 'emotional': 2,\n",
       " 'excited': 3,\n",
       " 'fear': 4,\n",
       " 'happy': 5,\n",
       " 'hopeful': 6,\n",
       " 'hurt': 7,\n",
       " 'love': 8,\n",
       " 'negative': 9,\n",
       " 'positive': 10,\n",
       " 'sadness': 11}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {}\n",
    "for cl in le.classes_:\n",
    "    label_dict.update({cl:le.transform([cl])[0]})\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angry</th>\n",
       "      <th>awe</th>\n",
       "      <th>emotional</th>\n",
       "      <th>excited</th>\n",
       "      <th>fear</th>\n",
       "      <th>happy</th>\n",
       "      <th>hopeful</th>\n",
       "      <th>hurt</th>\n",
       "      <th>love</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.150943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.219178</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.576923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               angry        awe  emotional  excited      fear      happy  \\\n",
       "precision   0.400000   0.750000   0.350000     0.25  0.350000   0.550000   \n",
       "recall      0.150943   1.000000   0.583333     1.00  1.000000   0.148649   \n",
       "f1          0.219178   0.857143   0.437500     0.40  0.518519   0.234043   \n",
       "support    53.000000  15.000000  12.000000     5.00  7.000000  74.000000   \n",
       "\n",
       "           hopeful      hurt       love   negative  positive    sadness  \n",
       "precision      0.0  0.300000   0.350000   0.550000  0.200000   0.750000  \n",
       "recall         0.0  1.000000   0.368421   1.000000  0.666667   0.468750  \n",
       "f1             0.0  0.461538   0.358974   0.709677  0.307692   0.576923  \n",
       "support        0.0  6.000000  19.000000  11.000000  6.000000  32.000000  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "scores = pd.DataFrame(precision_recall_fscore_support(cnnPredicted, labels, labels = list(range(12))),index=['precision','recall','f1','support'], columns = list(label_dict)[:12])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open('midi_test_data','rb')\n",
    "music_data = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test_1 = []\n",
    "name = []\n",
    "for m in music_data:\n",
    "    if m[0].shape[0]>=612:\n",
    "        X_test_1.append(m[0][100:612,:])\n",
    "        name.append(m[1])\n",
    "X_test_1 = np.array(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 512, 128)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test_1 = models[0][0](torch.as_tensor(X_test_1.reshape(-1,1,512,128), dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Across_The_Stars(StarWar_II_Love_Theme) happy negative sadness\n",
      "PAL1_theme-仙剑1 happy love sadness\n",
      "上海滩 happy sadness negative\n",
      "月光奏鸣曲 happy love negative\n",
      "枉凝眉 happy positive love\n",
      "水调歌头·明月几时有 sadness love hurt\n",
      "沧海一声笑 love angry sadness\n",
      "笑傲江湖 sadness happy negative\n",
      "铁血丹心 happy negative sadness\n",
      "难念的经-天龙八部 sadness happy love\n",
      "青花瓷 happy negative love\n"
     ]
    }
   ],
   "source": [
    "label = torch.argsort(-y_test_1).to('cpu').numpy()\n",
    "for i in range(len(label)):\n",
    "    print(name[i],le.classes_[label[i][0]], le.classes_[label[i][1]], le.classes_[label[i][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WzuA94i88EpO",
    "outputId": "39fb0326-c3dd-42d7-b1ea-7c5f690b9541",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cnn\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      2\u001b[0m cnnCorrect \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      3\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cnn' is not defined"
     ]
    }
   ],
   "source": [
    "cnn.eval()\n",
    "cnnCorrect = 0\n",
    "total = 0\n",
    "for inputs, labels in test_dataloader:\n",
    "    inputs = inputs.to('cuda').reshape(-1,1,512,128)\n",
    "    labels = labels.to('cuda')\n",
    "    cnnOutputs = cnn(inputs)\n",
    "    _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    cnnCorrect += np.sum([labels[i] in torch.argsort(cnnOutputs)[:, -4:][i] for i in range(len(labels))])\n",
    "print('CNN validation accuracy: {}%'.format(cnnCorrect / total * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRRi_Ai2_jU7",
    "outputId": "d22defa3-b353-4960-b27e-ed65f1af9d9e",
    "tags": []
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 588.00 MiB (GPU 0; 31.74 GiB total capacity; 28.79 GiB already allocated; 464.31 MiB free; 30.88 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m512\u001b[39m,\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m     12\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m cnnOutputs \u001b[38;5;241m=\u001b[39m best_model[\u001b[38;5;241m0\u001b[39m](inputs)\n\u001b[1;32m     14\u001b[0m _, cnnPredicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(cnnOutputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[7], line 21\u001b[0m, in \u001b[0;36mCNNModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x))))\n\u001b[1;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv4(x)))\n\u001b[1;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv5(x)))\n",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 588.00 MiB (GPU 0; 31.74 GiB total capacity; 28.79 GiB already allocated; 464.31 MiB free; 30.88 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = []\n",
    "f,axes = plt.subplots(1,5, figsize=(20,4))\n",
    "for i, best_model in enumerate(models):\n",
    "    best_model[0].eval()\n",
    "    best_model[0].to('cuda')\n",
    "    cnnCorrect = 0\n",
    "    total = 0\n",
    "    pred = []\n",
    "    t_label = []\n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs = inputs.to('cuda').reshape(-1,1,512,128)\n",
    "        labels = labels.to('cuda')\n",
    "        cnnOutputs = best_model[0](inputs)\n",
    "        _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        t_label += labels.tolist()\n",
    "        pred += cnnOutputs.tolist()\n",
    "        cnnCorrect += np.sum([labels[i] in torch.argsort(cnnOutputs)[:, -3:][i] for i in range(len(labels))])\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    confu_m = confusion_matrix(t_label, pred)\n",
    "    import seaborn as sns\n",
    "    sns.heatmap(confu_m,square=False, ax=axes[i])\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    scores.append([pd.DataFrame(precision_recall_fscore_support(pred, t_label, labels = list(range(12))),index=['precision','recall','f1','support'], columns = list(label_dict)[:12])])\n",
    "    # scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angry</th>\n",
       "      <th>awe</th>\n",
       "      <th>emotional</th>\n",
       "      <th>excited</th>\n",
       "      <th>fear</th>\n",
       "      <th>happy</th>\n",
       "      <th>hopeful</th>\n",
       "      <th>hurt</th>\n",
       "      <th>love</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.45000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.115942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.179775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.62069</td>\n",
       "      <td>0.464286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               angry  awe  emotional    excited      fear      happy  hopeful  \\\n",
       "precision   0.500000  0.0   0.250000   1.000000  0.200000   0.400000      0.0   \n",
       "recall      0.833333  0.0   0.833333   0.277778  1.000000   0.115942      0.0   \n",
       "f1          0.625000  0.0   0.384615   0.434783  0.333333   0.179775      0.0   \n",
       "support    12.000000  0.0   6.000000  72.000000  4.000000  69.000000      0.0   \n",
       "\n",
       "           hurt       love   negative  positive    sadness  \n",
       "precision   0.0   0.200000   0.500000   0.45000   0.650000  \n",
       "recall      0.0   0.400000   0.454545   1.00000   0.361111  \n",
       "f1          0.0   0.266667   0.476190   0.62069   0.464286  \n",
       "support     0.0  10.000000  22.000000   9.00000  36.000000  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "z3xGBJynBQ-x",
    "outputId": "7a5e350b-f83e-449c-9d10-ab38a7621f49",
    "tags": []
   },
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m----> 2\u001b[0m pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m confu_m \u001b[38;5;241m=\u001b[39m confusion_matrix(t_label, pred)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/numpy/core/fromnumeric.py:1242\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m-> 1242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margmax\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred = np.argmax(pred, axis=1)\n",
    "confu_m = confusion_matrix(t_label, pred)\n",
    "import seaborn as sns\n",
    "sns.heatmap(confu_m,square=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kn0NCC2dCrTx",
    "outputId": "f2918339-1f7c-487a-ba9d-70d8c0851c76",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry': 0,\n",
       " 'awe': 1,\n",
       " 'emotional': 2,\n",
       " 'excited': 3,\n",
       " 'fear': 4,\n",
       " 'happy': 5,\n",
       " 'hopeful': 6,\n",
       " 'hurt': 7,\n",
       " 'love': 8,\n",
       " 'negative': 9,\n",
       " 'positive': 10,\n",
       " 'sadness': 11}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {}\n",
    "for cl in le.classes_:\n",
    "    label_dict.update({cl:le.transform([cl])[0]})\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ECh6NJTDAZI",
    "outputId": "f91a6302-758d-4401-b469-b906f6d63ab4",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4266666666666667"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = (np.array(t_label)!=16)\n",
    "(pred[idx] == np.array(t_label)[idx]).sum()/len(pred[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "GWGJSFyoDnzh",
    "outputId": "4ed5e9ca-e9cf-44a7-b6e3-ef34729e57fa",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "12 columns passed, passed data had 15 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/pandas/core/internals/construction.py:969\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/pandas/core/internals/construction.py:1017\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[0;32m-> 1017\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1019\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_mi_list:\n\u001b[1;32m   1022\u001b[0m \n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 12 columns passed, passed data had 15 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_recall_fscore_support\n\u001b[0;32m----> 2\u001b[0m scores \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(precision_recall_fscore_support(pred, t_label, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m15\u001b[39m))),index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupport\u001b[39m\u001b[38;5;124m'\u001b[39m], columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(label_dict)[:\u001b[38;5;241m15\u001b[39m])\n\u001b[1;32m      3\u001b[0m scores\n",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/pandas/core/frame.py:746\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    745\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 746\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m nested_data_to_arrays(\n\u001b[1;32m    747\u001b[0m         \u001b[38;5;66;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;00m\n\u001b[1;32m    748\u001b[0m         \u001b[38;5;66;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;00m\n\u001b[1;32m    749\u001b[0m         data,\n\u001b[1;32m    750\u001b[0m         columns,\n\u001b[1;32m    751\u001b[0m         index,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    752\u001b[0m         dtype,\n\u001b[1;32m    753\u001b[0m     )\n\u001b[1;32m    754\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    755\u001b[0m         arrays,\n\u001b[1;32m    756\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    759\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    760\u001b[0m     )\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/pandas/core/internals/construction.py:510\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[0;32m--> 510\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m to_arrays(data, columns, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    511\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/pandas/core/internals/construction.py:875\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    872\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m    873\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m--> 875\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m _finalize_columns_and_data(arr, columns, dtype)\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/pandas/core/internals/construction.py:972\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    969\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[0;32m--> 972\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[1;32m    975\u001b[0m     contents \u001b[38;5;241m=\u001b[39m _convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: 12 columns passed, passed data had 15 columns"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "scores = pd.DataFrame(precision_recall_fscore_support(pred, t_label, labels = list(range(15))),index=['precision','recall','f1','support'], columns = list(label_dict)[:15])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4sI6ilxkD0ZB",
    "outputId": "8dc8ccbe-ffa8-4cdb-d789-aac99c79a484",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision     0.426667\n",
       "recall        0.533124\n",
       "f1            0.430355\n",
       "support      20.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CtA905R9OigX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
