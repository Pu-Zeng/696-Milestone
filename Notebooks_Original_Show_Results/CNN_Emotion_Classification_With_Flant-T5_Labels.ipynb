{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the CNN Emotion Regression Model with MIDI data#\n",
    "# Last editted by Pu Zeng, 19/10/2023 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "u8eSS9tg62ge",
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Detected that PyTorch and torchvision were compiled with different CUDA versions. PyTorch has CUDA Version=11.8 and torchvision has CUDA Version=11.7. Please reinstall the torchvision that matches your PyTorch install.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_40680\\2696542321.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfetch_california_housing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programing\\anaconda3\\lib\\site-packages\\torchvision\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programing\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_optical_flow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFlyingChairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlyingThings3D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHD1K\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKittiFlow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSintel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m from ._stereo_matching import (\n\u001b[0;32m      3\u001b[0m     \u001b[0mCarlaStereo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mCREStereo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mETH3DStereo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programing\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\_optical_flow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_read_png_16\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_read_pfm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_str_arg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mVisionDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programing\\anaconda3\\lib\\site-packages\\torchvision\\io\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_load_gpu_decoder\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_HAS_GPU_VIDEO_DECODER\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0m_HAS_GPU_VIDEO_DECODER\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programing\\anaconda3\\lib\\site-packages\\torchvision\\io\\_load_gpu_decoder.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_load_library\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0m_load_library\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Decoder\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programing\\anaconda3\\lib\\site-packages\\torchvision\\extension.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m \u001b[0m_check_cuda_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\programing\\anaconda3\\lib\\site-packages\\torchvision\\extension.py\u001b[0m in \u001b[0;36m_check_cuda_version\u001b[1;34m()\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mt_minor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_version\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mt_major\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtv_major\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt_minor\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtv_minor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             raise RuntimeError(\n\u001b[0m\u001b[0;32m     81\u001b[0m                 \u001b[1;34m\"Detected that PyTorch and torchvision were compiled with different CUDA versions. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                 \u001b[1;34mf\"PyTorch has CUDA Version={t_major}.{t_minor} and torchvision has \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Detected that PyTorch and torchvision were compiled with different CUDA versions. PyTorch has CUDA Version=11.8 and torchvision has CUDA Version=11.7. Please reinstall the torchvision that matches your PyTorch install."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# import mido\n",
    "import string\n",
    "import numpy as np\n",
    "# from utilis import get_pianoroll_data\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# import mido\n",
    "import string\n",
    "import numpy as np\n",
    "# from utilis import get_pianoroll_data\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file=open(\"lakh_emotion.bin\",\"rb\")\n",
    "music_data = pickle.load(file) #保存list到文件\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"a-livin'\", 'achey', 'ah', 'ah!',\n",
       "       \"ahah,ahva,vava.we'll take a dream on a sunday,we'll take a life,take a holiday.take a lie,take a dreamer,dream\",\n",
       "       'ahh', 'ahum', 'amazing', 'anger', 'angry', 'arousal', 'awe',\n",
       "       'bad', 'big', 'bitter', 'bittersweet', 'calm', 'cold', 'confused',\n",
       "       'darkness', 'ecstasy', 'ecstatic', 'eloquent',\n",
       "       'emertimenessed by midnight cinglight tying live phonebovelingney, ry where thing no more foremertimenessed by summertimemertimenesss-summertimemertime',\n",
       "       'emotion', 'emotional', 'emozione', 'enlightened', 'esattino',\n",
       "       'ethereal', 'euphoria',\n",
       "       'evtiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii', 'excited',\n",
       "       'fear', 'fearful', 'foolish', 'free as a bird', 'frightful',\n",
       "       \"frozen inside without your touch without your love, darling only you are the life among the dead of this i, i can't believe i couldn't see kept in the dark, but you were there in front of me]\",\n",
       "       'good', 'grateful', 'happy', 'happyness', 'hate', 'heart',\n",
       "       'heartbreaking', 'heartbroken', 'helpful', 'hopeful', 'hurt',\n",
       "       'hurts', 'hysterical', 'i',\n",
       "       'i and getgie you you getgiei and getgie you you getgiei and lyaly out in stuff you you and getgiei and getgies hoodoobie scooshoo scoobe',\n",
       "       'i lay down with an angel', 'i loved them so.',\n",
       "       \"i'm your top prime cut of meat, i'm your choice. i wanna be elected. i'm my top prime cut of meat, i'm your choice. i wanna be elected.\",\n",
       "       'joy', 'joyous', 'light', 'love', 'mean', 'na na na', 'negative',\n",
       "       'numbness',\n",
       "       \"ooooooooo,ooo.ooooooooo,ooo.if you,if you could return,don't let it burn,don't let it fade.i'm sure i'm not being rude\",\n",
       "       'positive', 'powerful', 'proud', 'raining', 'sad', 'sadness',\n",
       "       'shame',\n",
       "       'she feels she is a woman and she is a man and she is a woman and she is a man and she is a woman and she is a woman and she is a woman and she is a woman and',\n",
       "       'shock', 'sorrow', 'strange', 'strong', 'surprise', 'tenderness',\n",
       "       'time', 'tired', 'tiredness', 'trouble', 'uneasy', 'unsure',\n",
       "       'upset', 'vain',\n",
       "       \"webutwell and how nyr ilyed one but thing peenden itn't and how nyr y you buting we'velems you'relieve how thing how thing is answers but\",\n",
       "       'woo',\n",
       "       \"you have seen digcing Friday looking wheresic getting you anybody nightsic's with sicrything you're and youcingyounglyventeen.dancingfeelbourine.youhaving see digc\"],\n",
       "      dtype='<U191')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the original labels generated by Flan-T5\n",
    "np.unique([x[1] for x in music_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "a5ONeVUU7MOU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selected the most common one word labels\n",
    "from tqdm import tqdm\n",
    "X = []\n",
    "y = []\n",
    "chosen_label = ['sadness', 'happy', 'love', 'joy', 'negative', 'positive', 'anger',\n",
    "       'awe', 'emotional', 'hopeful', 'angry', 'excited', 'fear', 'hurt',\n",
    "       'fearful']\n",
    "# for i in tqdm(range(1,10)):\n",
    "file=open(\"lakh_emotion.bin\",\"rb\")\n",
    "music_data = pickle.load(file) #保存list到文件\n",
    "file.close()\n",
    "for m in music_data:\n",
    "    if m[1] in chosen_label:\n",
    "        X.append(m[0])\n",
    "        if m[1] == 'anger':\n",
    "            m[1] = 'angry'\n",
    "        if m[1] == 'fearful':\n",
    "            m[1] = 'fear'\n",
    "        if m[1] == 'joy':\n",
    "            m[1] = 'happy'\n",
    "        y.append(m[1])\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the number of classes\n",
    "num_labels = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform labels into one-hot variable\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "label_dict = {}\n",
    "for cl in le.classes_:\n",
    "    label_dict.update({cl:le.transform([cl])[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, hiddenSize, outChannels, dropoutRate, activate):\n",
    "        super().__init__()\n",
    "        self.outChannels = outChannels\n",
    "        self.activate = nn.Sigmoid() if activate == \"Sigmoid\" else nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(1, 24, (10,1))\n",
    "        self.pool = nn.MaxPool2d((2, 1))\n",
    "        self.conv2 = nn.Conv2d(24, 48, (10,1))\n",
    "        self.conv3 = nn.Conv2d(48, 96, (10,1))\n",
    "        self.conv4 = nn.Conv2d(96, 192, (10,1))\n",
    "        self.conv5 = nn.Conv2d(192, 384, (5,2))\n",
    "        self.conv6 = nn.Conv2d(384, 192, (5,2))\n",
    "        self.dense1 = nn.Linear(48384, hiddenSize)\n",
    "        self.dropout = nn.Dropout(dropoutRate)\n",
    "        self.dense2 = nn.Linear(hiddenSize, num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.activate(self.conv1(x)))\n",
    "        x = self.pool(self.activate(self.conv2(x)))\n",
    "        # print(x.shape)\n",
    "        x = self.dropout(self.pool(self.activate(self.conv3(x))))\n",
    "        x = self.pool(self.activate(self.conv4(x)))\n",
    "        x = self.pool(self.activate(self.conv5(x)))\n",
    "        x = self.pool(self.activate(self.conv6(x)))\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 48384)\n",
    "        x = self.dropout(self.activate(self.dense1(x)))\n",
    "        return self.dense2(x)\n",
    "\n",
    "# Number of neurons in the first fully-connected layer\n",
    "hiddenSize = 4096\n",
    "# Number of feature filters in second convolutional layer\n",
    "numFilters = 25\n",
    "# Dropout rate\n",
    "dropoutRate = 0.2\n",
    "# Activation function\n",
    "activation = \"ReLU\"\n",
    "# Learning rate\n",
    "learningRate = 0.005\n",
    "# Momentum for SGD optimizer\n",
    "momentum = 0.9\n",
    "# Number of training epochs\n",
    "numEpochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define Trian and Validation function\n",
    "from tqdm import tqdm\n",
    "def train_epoch(cnn,device,dataloader,loss_fn,optimizer):\n",
    "    cnn.train()\n",
    "    cnnRunningLoss = 0\n",
    "    total = 0\n",
    "    R2 = 0\n",
    "    cnnCorrect=0\n",
    "    total1=0\n",
    "    for i, (inputs, labels) in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to('cuda').reshape(-1,1,512,128)\n",
    "        \n",
    "        labels = labels.to('cuda')\n",
    "        # Forward propagation\n",
    "        cnnOutputs = cnn(inputs)\n",
    "        # print(cnnOutputs.shape)\n",
    "        l2_lambda = 0.001\n",
    "        l2_reg = torch.tensor(0.).to('cuda')\n",
    "        for param in cnn.parameters():\n",
    "            l2_reg += torch.norm(param)\n",
    "        # Backpropagation\n",
    "        cnnLoss = criterion(cnnOutputs, labels)+l2_reg*l2_lambda\n",
    "        cnnLoss.backward()\n",
    "        # Gradient update\n",
    "        optimizer.step()\n",
    "        total += 1\n",
    "        total1+=labels.size(0)\n",
    "        cnnRunningLoss += cnnLoss.item()\n",
    "        _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n",
    "        cnnCorrect += (cnnPredicted == labels).sum().item()\n",
    "    return cnnRunningLoss/total, cnnCorrect/total1\n",
    "\n",
    "def valid_epoch(cnn,device,dataloader,loss_fn):\n",
    "    cnn.eval()\n",
    "    totalLoss = 0\n",
    "    total = 0\n",
    "    total1 = 0\n",
    "    R2 = 0\n",
    "    cnnLoss = 0\n",
    "    cnnCorrect=0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to('cuda').reshape(-1,1,512,128)\n",
    "        labels = labels.to('cuda')\n",
    "        cnnOutputs = cnn(inputs)\n",
    "        cnnLoss = loss_fn(cnnOutputs, labels)\n",
    "        _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        total1 +=1\n",
    "        totalLoss += cnnLoss.item()\n",
    "        cnnCorrect += (cnnPredicted == labels).sum().item()\n",
    "    accuracy = cnnCorrect / total * 100\n",
    "    cnn.train()\n",
    "    return totalLoss/total1, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Train Loss: 2.544879150390625, Train_acc: 0.11, Test Loss: 2.511772036552429, Test acc: 10.833333333333334\n",
      "Train Loss: 2.3728294134140016, Train_acc: 0.18, Test Loss: 2.6150710582733154, Test acc: 15.833333333333332\n",
      "Train Loss: 2.0665850758552553, Train_acc: 0.32083333333333336, Test Loss: 2.725834608078003, Test acc: 24.166666666666668\n",
      "Train Loss: 1.8275741457939148, Train_acc: 0.44416666666666665, Test Loss: 2.853182077407837, Test acc: 20.416666666666668\n",
      "Train Loss: 1.5240383625030518, Train_acc: 0.5291666666666667, Test Loss: 3.3484232425689697, Test acc: 33.33333333333333\n",
      "Train Loss: 1.381859004497528, Train_acc: 0.59, Test Loss: 3.337221145629883, Test acc: 36.25\n",
      "Train Loss: 1.2434839844703673, Train_acc: 0.6158333333333333, Test Loss: 4.394578695297241, Test acc: 36.666666666666664\n",
      "Train Loss: 1.1272317469120026, Train_acc: 0.6358333333333334, Test Loss: 5.6733386516571045, Test acc: 32.916666666666664\n",
      "Train Loss: 1.1377168953418733, Train_acc: 0.65, Test Loss: 4.991016626358032, Test acc: 37.083333333333336\n",
      "Train Loss: 1.122369545698166, Train_acc: 0.6575, Test Loss: 4.697638034820557, Test acc: 39.58333333333333\n",
      "Train Loss: 1.0316920936107636, Train_acc: 0.6733333333333333, Test Loss: 8.28153944015503, Test acc: 37.083333333333336\n",
      "Train Loss: 1.1001813769340516, Train_acc: 0.6591666666666667, Test Loss: 6.924990177154541, Test acc: 33.75\n",
      "Train Loss: 1.3850169897079467, Train_acc: 0.6341666666666667, Test Loss: 3.1229599714279175, Test acc: 35.41666666666667\n",
      "Train Loss: 1.1204024493694305, Train_acc: 0.6675, Test Loss: 4.685003995895386, Test acc: 35.41666666666667\n",
      "Train Loss: 1.0623291611671448, Train_acc: 0.6733333333333333, Test Loss: 7.919297218322754, Test acc: 35.833333333333336\n",
      "Train Loss: 1.167781263589859, Train_acc: 0.665, Test Loss: 4.21962034702301, Test acc: 37.083333333333336\n",
      "Train Loss: 1.098397082090378, Train_acc: 0.6791666666666667, Test Loss: 4.067560911178589, Test acc: 37.916666666666664\n",
      "Train Loss: 1.0632552921772003, Train_acc: 0.6808333333333333, Test Loss: 6.1634604930877686, Test acc: 31.666666666666664\n",
      "Train Loss: 1.120047289133072, Train_acc: 0.6683333333333333, Test Loss: 5.353693723678589, Test acc: 38.75\n",
      "Train Loss: 1.0233109056949616, Train_acc: 0.6741666666666667, Test Loss: 6.257636308670044, Test acc: 37.916666666666664\n",
      "Fold 2\n",
      "Train Loss: 2.5545032739639284, Train_acc: 0.09166666666666666, Test Loss: 2.4644877910614014, Test acc: 10.416666666666668\n",
      "Train Loss: 2.462624716758728, Train_acc: 0.16833333333333333, Test Loss: 2.3854830265045166, Test acc: 18.333333333333332\n",
      "Train Loss: 2.131000506877899, Train_acc: 0.2816666666666667, Test Loss: 2.491751194000244, Test acc: 30.416666666666664\n",
      "Train Loss: 1.9499094009399414, Train_acc: 0.42, Test Loss: 2.1320987939834595, Test acc: 35.0\n",
      "Train Loss: 1.631064248085022, Train_acc: 0.5275, Test Loss: 2.6388367414474487, Test acc: 37.5\n",
      "Train Loss: 1.3613142013549804, Train_acc: 0.6025, Test Loss: 3.3039153814315796, Test acc: 42.5\n",
      "Train Loss: 1.3288440942764281, Train_acc: 0.63, Test Loss: 2.6270430088043213, Test acc: 45.0\n",
      "Train Loss: 1.1789943814277648, Train_acc: 0.6766666666666666, Test Loss: 2.979269862174988, Test acc: 50.0\n",
      "Train Loss: 1.131811761856079, Train_acc: 0.6925, Test Loss: 3.5524041652679443, Test acc: 48.333333333333336\n",
      "Train Loss: 1.1107047200202942, Train_acc: 0.695, Test Loss: 2.9956291913986206, Test acc: 49.583333333333336\n",
      "Train Loss: 0.9828047335147858, Train_acc: 0.7408333333333333, Test Loss: 4.858733534812927, Test acc: 48.333333333333336\n",
      "Train Loss: 0.9014075577259064, Train_acc: 0.7433333333333333, Test Loss: 7.411664247512817, Test acc: 47.5\n",
      "Train Loss: 1.119134259223938, Train_acc: 0.7241666666666666, Test Loss: 3.777834415435791, Test acc: 47.083333333333336\n",
      "Train Loss: 1.0032642960548401, Train_acc: 0.7308333333333333, Test Loss: 3.930729627609253, Test acc: 50.0\n",
      "Train Loss: 1.0732817113399507, Train_acc: 0.7141666666666666, Test Loss: 3.829172134399414, Test acc: 48.333333333333336\n",
      "Train Loss: 0.9356981992721558, Train_acc: 0.7466666666666667, Test Loss: 3.742967367172241, Test acc: 51.66666666666667\n",
      "Train Loss: 0.8891672194004059, Train_acc: 0.75, Test Loss: 4.932244420051575, Test acc: 47.5\n",
      "Train Loss: 0.9581585884094238, Train_acc: 0.7391666666666666, Test Loss: 4.452365040779114, Test acc: 47.91666666666667\n",
      "Train Loss: 0.8930047690868378, Train_acc: 0.75, Test Loss: 6.306432485580444, Test acc: 51.24999999999999\n",
      "Train Loss: 0.8533963143825531, Train_acc: 0.7591666666666667, Test Loss: 5.020928740501404, Test acc: 48.75\n",
      "Fold 3\n",
      "Train Loss: 2.560968351364136, Train_acc: 0.08083333333333333, Test Loss: 2.4714207649230957, Test acc: 12.5\n",
      "Train Loss: 2.508251428604126, Train_acc: 0.13083333333333333, Test Loss: 2.4322283267974854, Test acc: 10.0\n",
      "Train Loss: 2.313735103607178, Train_acc: 0.2175, Test Loss: 2.05124169588089, Test acc: 32.916666666666664\n",
      "Train Loss: 1.989303183555603, Train_acc: 0.37416666666666665, Test Loss: 2.0108593702316284, Test acc: 37.083333333333336\n",
      "Train Loss: 1.6717199683189392, Train_acc: 0.48083333333333333, Test Loss: 2.153808116912842, Test acc: 39.58333333333333\n",
      "Train Loss: 1.553624939918518, Train_acc: 0.5441666666666667, Test Loss: 2.1678813695907593, Test acc: 40.833333333333336\n",
      "Train Loss: 1.2863410592079163, Train_acc: 0.61, Test Loss: 2.9429831504821777, Test acc: 37.5\n",
      "Train Loss: 1.13173406124115, Train_acc: 0.6516666666666666, Test Loss: 4.069437503814697, Test acc: 40.833333333333336\n",
      "Train Loss: 1.1258812308311463, Train_acc: 0.6816666666666666, Test Loss: 3.1697425842285156, Test acc: 43.333333333333336\n",
      "Train Loss: 1.0746334075927735, Train_acc: 0.6933333333333334, Test Loss: 3.4769952297210693, Test acc: 42.916666666666664\n",
      "Train Loss: 1.0637965738773345, Train_acc: 0.6991666666666667, Test Loss: 3.6784942150115967, Test acc: 42.916666666666664\n",
      "Train Loss: 1.1404019713401794, Train_acc: 0.6891666666666667, Test Loss: 3.954128861427307, Test acc: 42.083333333333336\n",
      "Train Loss: 1.0938625514507294, Train_acc: 0.695, Test Loss: 3.8988049030303955, Test acc: 42.5\n",
      "Train Loss: 0.9811626136302948, Train_acc: 0.7091666666666666, Test Loss: 4.825376510620117, Test acc: 42.5\n",
      "Train Loss: 0.9277391374111176, Train_acc: 0.7266666666666667, Test Loss: 6.392435789108276, Test acc: 41.66666666666667\n",
      "Train Loss: 1.005551928281784, Train_acc: 0.7183333333333334, Test Loss: 5.781272888183594, Test acc: 32.916666666666664\n",
      "Train Loss: 1.138105219602585, Train_acc: 0.6925, Test Loss: 3.185735583305359, Test acc: 44.166666666666664\n",
      "Train Loss: 0.99078528881073, Train_acc: 0.7041666666666667, Test Loss: 3.4801121950149536, Test acc: 43.75\n",
      "Train Loss: 0.8934655606746673, Train_acc: 0.7283333333333334, Test Loss: 5.343132734298706, Test acc: 43.333333333333336\n",
      "Train Loss: 0.8473319590091706, Train_acc: 0.7358333333333333, Test Loss: 7.822657346725464, Test acc: 42.5\n",
      "Fold 4\n",
      "Train Loss: 2.559342956542969, Train_acc: 0.09916666666666667, Test Loss: 2.452831268310547, Test acc: 20.416666666666668\n",
      "Train Loss: 2.5128020286560058, Train_acc: 0.17333333333333334, Test Loss: 2.3327715396881104, Test acc: 15.0\n",
      "Train Loss: 2.3461933612823485, Train_acc: 0.19833333333333333, Test Loss: 2.0538865327835083, Test acc: 30.833333333333336\n",
      "Train Loss: 2.0538366079330443, Train_acc: 0.34833333333333333, Test Loss: 1.957014560699463, Test acc: 38.333333333333336\n",
      "Train Loss: 1.8041269540786744, Train_acc: 0.4558333333333333, Test Loss: 1.9690687656402588, Test acc: 43.75\n",
      "Train Loss: 1.5338083505630493, Train_acc: 0.5183333333333333, Test Loss: 1.9607114791870117, Test acc: 42.916666666666664\n",
      "Train Loss: 1.3538433074951173, Train_acc: 0.5866666666666667, Test Loss: 2.034568727016449, Test acc: 49.166666666666664\n",
      "Train Loss: 1.2008211016654968, Train_acc: 0.6441666666666667, Test Loss: 2.36414897441864, Test acc: 48.75\n",
      "Train Loss: 1.0734818160533905, Train_acc: 0.6583333333333333, Test Loss: 3.368625044822693, Test acc: 47.91666666666667\n",
      "Train Loss: 1.0541631698608398, Train_acc: 0.6808333333333333, Test Loss: 3.112055778503418, Test acc: 48.75\n",
      "Train Loss: 0.9689188420772552, Train_acc: 0.7075, Test Loss: 3.755692481994629, Test acc: 50.416666666666664\n",
      "Train Loss: 1.0327105939388275, Train_acc: 0.6991666666666667, Test Loss: 3.0484797954559326, Test acc: 47.91666666666667\n",
      "Train Loss: 0.9986433386802673, Train_acc: 0.7066666666666667, Test Loss: 3.6084762811660767, Test acc: 49.166666666666664\n",
      "Train Loss: 0.9431548953056336, Train_acc: 0.7141666666666666, Test Loss: 4.554520845413208, Test acc: 49.583333333333336\n",
      "Train Loss: 1.0930129885673523, Train_acc: 0.7008333333333333, Test Loss: 3.59356951713562, Test acc: 44.166666666666664\n",
      "Train Loss: 1.011724317073822, Train_acc: 0.6975, Test Loss: 3.3969324827194214, Test acc: 47.083333333333336\n",
      "Train Loss: 1.0032617926597596, Train_acc: 0.7058333333333333, Test Loss: 3.3896045684814453, Test acc: 47.91666666666667\n",
      "Train Loss: 0.9082905769348144, Train_acc: 0.7291666666666666, Test Loss: 3.9628350734710693, Test acc: 51.24999999999999\n",
      "Train Loss: 0.8927402019500732, Train_acc: 0.7333333333333333, Test Loss: 5.908162355422974, Test acc: 45.416666666666664\n",
      "Train Loss: 1.0033084273338317, Train_acc: 0.7183333333333334, Test Loss: 3.33485209941864, Test acc: 47.91666666666667\n",
      "Fold 5\n",
      "Train Loss: 2.5527090311050413, Train_acc: 0.10916666666666666, Test Loss: 2.471941590309143, Test acc: 13.750000000000002\n",
      "Train Loss: 2.4661985635757446, Train_acc: 0.15583333333333332, Test Loss: 2.470752716064453, Test acc: 11.666666666666666\n",
      "Train Loss: 2.1348279237747194, Train_acc: 0.2775, Test Loss: 2.665808916091919, Test acc: 15.0\n",
      "Train Loss: 2.0348750829696653, Train_acc: 0.3675, Test Loss: 2.2837284803390503, Test acc: 21.666666666666668\n",
      "Train Loss: 1.722294545173645, Train_acc: 0.4625, Test Loss: 2.575242757797241, Test acc: 27.500000000000004\n",
      "Train Loss: 1.5965646624565124, Train_acc: 0.5083333333333333, Test Loss: 2.511627674102783, Test acc: 35.41666666666667\n",
      "Train Loss: 1.5462178468704224, Train_acc: 0.5691666666666667, Test Loss: 2.424227714538574, Test acc: 37.5\n",
      "Train Loss: 1.243674063682556, Train_acc: 0.62, Test Loss: 5.0181052684783936, Test acc: 40.0\n",
      "Train Loss: 1.5803727865219117, Train_acc: 0.5758333333333333, Test Loss: 2.0358394980430603, Test acc: 42.916666666666664\n",
      "Train Loss: 1.2901570200920105, Train_acc: 0.6258333333333334, Test Loss: 3.2064383029937744, Test acc: 43.333333333333336\n",
      "Train Loss: 1.1005243122577668, Train_acc: 0.6508333333333334, Test Loss: 5.420256853103638, Test acc: 47.083333333333336\n",
      "Train Loss: 1.2617688596248626, Train_acc: 0.6583333333333333, Test Loss: 2.888223648071289, Test acc: 39.58333333333333\n",
      "Train Loss: 1.2966224789619445, Train_acc: 0.6266666666666667, Test Loss: 2.6218141317367554, Test acc: 42.5\n",
      "Train Loss: 1.1010893285274506, Train_acc: 0.66, Test Loss: 3.726750373840332, Test acc: 45.416666666666664\n",
      "Train Loss: 1.1660788118839265, Train_acc: 0.6566666666666666, Test Loss: 4.261751770973206, Test acc: 43.333333333333336\n",
      "Train Loss: 1.141684067249298, Train_acc: 0.6708333333333333, Test Loss: 3.280975341796875, Test acc: 46.25\n",
      "Train Loss: 1.0624887943267822, Train_acc: 0.6816666666666666, Test Loss: 4.4720213413238525, Test acc: 49.166666666666664\n",
      "Train Loss: 0.9713901817798615, Train_acc: 0.6966666666666667, Test Loss: 5.5121910572052, Test acc: 45.0\n",
      "Train Loss: 1.0712769269943236, Train_acc: 0.6916666666666667, Test Loss: 5.066340446472168, Test acc: 45.83333333333333\n",
      "Train Loss: 1.3756625175476074, Train_acc: 0.6533333333333333, Test Loss: 2.7743427753448486, Test acc: 44.166666666666664\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "X_train_v, X_test, y_train_v, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) # First Split the dataset and use the training set for 5-fold validation\n",
    "\n",
    "X_train_v = torch.as_tensor(X_train_v, dtype=torch.float) # an alternative to torch.from_numpy\n",
    "y_train_v = torch.as_tensor(y_train_v, dtype=torch.float)\n",
    "X_test = torch.as_tensor(X_test, dtype=torch.float)\n",
    "y_test = torch.as_tensor(y_test, dtype=torch.float)\n",
    "splits=StratifiedKFold(n_splits=5,shuffle=True,random_state=99)\n",
    "train_dataset = TensorDataset(X_train_v, y_train_v)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size=128\n",
    "models = []\n",
    "history = {'fold':[], 'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(X_train_v,y_train_v)):\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "    t = pd.DataFrame(y_train_v[train_idx], columns = ['class']).reset_index()\n",
    "    idx = []\n",
    "    # Resample to avoid unbalanced dataset\n",
    "    y_train = []\n",
    "    for i in range(0,num_labels):\n",
    "      idx += list(t[t['class']==i].sample(100,replace=True)['index'])\n",
    "      y_train += [i]*100\n",
    "    X_train = X_train_v[train_idx][idx]\n",
    "\n",
    "    t = pd.DataFrame(y_train_v[val_idx], columns = ['class']).reset_index()\n",
    "    idx = []\n",
    "    y_val = []\n",
    "    for i in range(0,num_labels):\n",
    "      # print(i)\n",
    "      if i in t['class'].values:\n",
    "          idx += list(t[t['class']==i].sample(20,replace=True)['index'])\n",
    "          y_val += [i]*20\n",
    "    X_val =  X_train_v[val_idx][idx]\n",
    "\n",
    "    X_train = torch.as_tensor(X_train, dtype=torch.float) # an alternative to torch.from_numpy\n",
    "    y_train = torch.as_tensor(y_train, dtype=torch.float).type(torch.LongTensor)\n",
    "    X_val = torch.as_tensor(X_val, dtype=torch.float)\n",
    "    y_val = torch.as_tensor(y_val, dtype=torch.float).type(torch.LongTensor)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "    \n",
    "    model = CNNModel(hiddenSize, numFilters, dropoutRate, activation).to('cuda')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(list(model.parameters()), lr=learningRate, momentum=momentum)\n",
    "    # optimizer = torch.optim.Adam(list(model.parameters()), lr=learningRate)\n",
    "    best_test = -np.inf\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(numEpochs):\n",
    "        train_loss, train_R2=train_epoch(model,device,train_dataloader,criterion,optimizer)\n",
    "        test_loss, test_R2=valid_epoch(model,device,test_dataloader,criterion)\n",
    "        history['fold'].append(fold)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['train_acc'].append(train_R2)\n",
    "        history['test_acc'].append(test_R2)   \n",
    "        if test_R2>best_test:\n",
    "            test_test = test_R2\n",
    "            best_model = model\n",
    "        print('Train Loss: {}, Train_acc: {}, Test Loss: {}, Test acc: {}'.format(train_loss, train_R2, test_loss, test_R2))\n",
    "    models.append([best_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Caculate the average accuray\n",
    "t = pd.DataFrame(y_test, columns = ['class']).reset_index()\n",
    "idx = []\n",
    "y_test = []\n",
    "for i in range(0,num_labels):\n",
    "    if i in t['class'].values:\n",
    "        idx += list(t[t['class']==i].sample(20,replace=True)['index'])\n",
    "        y_test += [i]*20\n",
    "X_test =  X_test[idx]\n",
    "X_test = torch.as_tensor(X_test, dtype=torch.float)\n",
    "y_test = torch.as_tensor(y_test, dtype=torch.float).type(torch.LongTensor)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "acc=[]\n",
    "for best_model in models:\n",
    "    acc.append(valid_epoch(best_model[0],device,test_dataloader,criterion)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.583333333333336"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.66666666666667"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = []    \n",
    "for model in models:\n",
    "  model[0].eval()\n",
    "  model_output = []\n",
    "  label_= []\n",
    "  model[0].to('cpu')\n",
    "  for inputs, labels in test_dataloader:\n",
    "      inputs = inputs.to('cpu').reshape(-1,1,512,128)\n",
    "      labels = labels.to('cpu')\n",
    "      cnnOutputs = model[0](inputs)\n",
    "      model_output.append(cnnOutputs)\n",
    "      label_.append(labels)\n",
    "  outputs.append(torch.vstack(model_output))\n",
    "cnnresult = torch.vstack(outputs).reshape(-1,shape[0],shape[1]).mean(axis=0)\n",
    "labels = np.hstack(label_)\n",
    "_, cnnPredicted = torch.max(cnnresult.data, 1)\n",
    "cnnCorrect = (cnnPredicted.detach().numpy() == labels).sum().item()\n",
    "cnnCorrect/len(labels)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confu_m = confusion_matrix(labels, cnnPredicted)\n",
    "import seaborn as sns\n",
    "sns.heatmap(confu_m,square=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry': 0,\n",
       " 'awe': 1,\n",
       " 'emotional': 2,\n",
       " 'excited': 3,\n",
       " 'fear': 4,\n",
       " 'happy': 5,\n",
       " 'hopeful': 6,\n",
       " 'hurt': 7,\n",
       " 'love': 8,\n",
       " 'negative': 9,\n",
       " 'positive': 10,\n",
       " 'sadness': 11}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {}\n",
    "for cl in le.classes_:\n",
    "    label_dict.update({cl:le.transform([cl])[0]})\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angry</th>\n",
       "      <th>awe</th>\n",
       "      <th>emotional</th>\n",
       "      <th>excited</th>\n",
       "      <th>fear</th>\n",
       "      <th>happy</th>\n",
       "      <th>hopeful</th>\n",
       "      <th>hurt</th>\n",
       "      <th>love</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.342857</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.390244</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               angry        awe  emotional   excited       fear      happy  \\\n",
       "precision   0.300000   1.000000   0.650000  0.400000   1.000000   0.500000   \n",
       "recall      0.400000   0.952381   0.590909  1.000000   0.294118   0.714286   \n",
       "f1          0.342857   0.975610   0.619048  0.571429   0.454545   0.588235   \n",
       "support    15.000000  21.000000  22.000000  8.000000  68.000000  14.000000   \n",
       "\n",
       "             hopeful  hurt       love   negative   positive    sadness  \n",
       "precision   0.450000   0.0   0.350000   0.400000   0.650000   0.500000  \n",
       "recall      0.818182   0.0   0.500000   0.380952   0.928571   0.312500  \n",
       "f1          0.580645   0.0   0.411765   0.390244   0.764706   0.384615  \n",
       "support    11.000000   0.0  14.000000  21.000000  14.000000  32.000000  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "scores = pd.DataFrame(precision_recall_fscore_support(cnnPredicted, labels, labels = list(range(12))),index=['precision','recall','f1','support'], columns = list(label_dict)[:12])\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
