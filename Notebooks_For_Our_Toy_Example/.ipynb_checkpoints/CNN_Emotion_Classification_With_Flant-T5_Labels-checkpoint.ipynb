{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the CNN Emotion Regression Model with MIDI data#\n",
    "# Last editted by Pu Zeng, 19/10/2023 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "u8eSS9tg62ge",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# import mido\n",
    "import string\n",
    "import numpy as np\n",
    "# from utilis import get_pianoroll_data\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# import mido\n",
    "import string\n",
    "import numpy as np\n",
    "# from utilis import get_pianoroll_data\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All content numbers is 1\n",
      "Total number of muisc 20\n",
      "Total number of muisc 41\n",
      "Total number of muisc 61\n",
      "Total number of muisc 82\n",
      "Total number of muisc 102\n",
      "Total number of muisc 123\n",
      "Total number of muisc 143\n",
      "Total number of muisc 164\n",
      "Total number of muisc 184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 29.41it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:01,  1.11s/it]\n",
      "2it [00:01,  1.26it/s]\n",
      "3it [00:02,  1.44it/s]\n",
      "4it [00:02,  1.44it/s]C:\\Milestone 2\\Milestone 2\\696-Milestone\\Data_Preprocessing\\Emotion_MIDI2.py:73: RuntimeWarning: invalid value encountered in divide\n",
      "  roll = (roll/count).T\n",
      "\n",
      "5it [00:03,  1.54it/s]\n",
      "6it [00:04,  1.51it/s]\n",
      "7it [00:05,  1.36it/s]\n",
      "8it [00:06,  1.18it/s]\n",
      "9it [00:07,  1.01it/s]\n",
      "10it [00:08,  1.00s/it]\n",
      "11it [00:09,  1.14it/s]\n",
      "12it [00:09,  1.44it/s]\n",
      "13it [00:10,  1.41it/s]\n",
      "14it [00:10,  1.37it/s]\n",
      "15it [00:12,  1.08it/s]D:\\programing\\anaconda3\\lib\\site-packages\\pretty_midi\\pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n",
      "\n",
      "16it [00:12,  1.27it/s]\n",
      "17it [00:13,  1.42it/s]\n",
      "18it [00:13,  1.55it/s]\n",
      "19it [00:14,  1.33it/s]\n",
      "20it [00:15,  1.28it/s]\n",
      "20it [00:15,  1.28it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00,  1.87it/s]\n",
      "2it [00:01,  1.26it/s]\n",
      "3it [00:02,  1.12it/s]\n",
      "4it [00:03,  1.10it/s]\n",
      "5it [00:04,  1.26it/s]\n",
      "6it [00:05,  1.14it/s]\n",
      "7it [00:06,  1.12it/s]\n",
      "8it [00:06,  1.17it/s]\n",
      "9it [00:08,  1.01s/it]\n",
      "10it [00:09,  1.03s/it]\n",
      "11it [00:10,  1.05s/it]\n",
      "12it [00:11,  1.03s/it]\n",
      "13it [00:12,  1.00s/it]\n",
      "14it [00:13,  1.01it/s]\n",
      "15it [00:14,  1.01s/it]\n",
      "16it [00:14,  1.08it/s]\n",
      "17it [00:15,  1.33it/s]\n",
      "18it [00:15,  1.37it/s]\n",
      "19it [00:16,  1.35it/s]\n",
      "20it [00:17,  1.46it/s]\n",
      "21it [00:17,  1.55it/s]\n",
      "21it [00:17,  1.18it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:01,  1.19s/it]\n",
      "2it [00:01,  1.10it/s]\n",
      "3it [00:02,  1.25it/s]\n",
      "4it [00:03,  1.18it/s]\n",
      "5it [00:04,  1.36it/s]\n",
      "6it [00:04,  1.26it/s]\n",
      "7it [00:05,  1.35it/s]\n",
      "8it [00:06,  1.33it/s]\n",
      "9it [00:06,  1.40it/s]\n",
      "10it [00:08,  1.04it/s]\n",
      "11it [00:09,  1.12s/it]\n",
      "12it [00:11,  1.11s/it]\n",
      "13it [00:12,  1.08s/it]\n",
      "14it [00:12,  1.05it/s]\n",
      "15it [00:13,  1.07it/s]\n",
      "16it [00:14,  1.20it/s]\n",
      "17it [00:15,  1.08it/s]\n",
      "18it [00:16,  1.02s/it]\n",
      "19it [00:17,  1.03it/s]\n",
      "20it [00:18,  1.06s/it]\n",
      "20it [00:18,  1.07it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:01,  1.13s/it]\n",
      "2it [00:01,  1.10it/s]\n",
      "3it [00:03,  1.02s/it]\n",
      "4it [00:03,  1.08it/s]\n",
      "5it [00:04,  1.02it/s]\n",
      "6it [00:05,  1.14it/s]\n",
      "7it [00:06,  1.01it/s]\n",
      "8it [00:07,  1.09it/s]\n",
      "9it [00:08,  1.05it/s]\n",
      "10it [00:08,  1.30it/s]\n",
      "11it [00:09,  1.21it/s]\n",
      "12it [00:10,  1.27it/s]\n",
      "13it [00:11,  1.34it/s]\n",
      "14it [00:12,  1.31it/s]\n",
      "15it [00:13,  1.17it/s]\n",
      "16it [00:13,  1.35it/s]\n",
      "17it [00:14,  1.23it/s]\n",
      "18it [00:15,  1.22it/s]\n",
      "19it [00:16,  1.25it/s]\n",
      "20it [00:16,  1.42it/s]\n",
      "21it [00:17,  1.31it/s]\n",
      "21it [00:17,  1.20it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00,  1.01it/s]\n",
      "2it [00:01,  1.16it/s]\n",
      "3it [00:01,  1.77it/s]\n",
      "4it [00:02,  1.64it/s]\n",
      "5it [00:03,  1.55it/s]\n",
      "6it [00:04,  1.43it/s]\n",
      "7it [00:04,  1.41it/s]\n",
      "8it [00:06,  1.12it/s]\n",
      "9it [00:07,  1.08it/s]\n",
      "10it [00:07,  1.18it/s]\n",
      "11it [00:08,  1.23it/s]\n",
      "12it [00:09,  1.28it/s]\n",
      "13it [00:10,  1.04s/it]\n",
      "14it [00:11,  1.03it/s]\n",
      "15it [00:13,  1.19s/it]\n",
      "16it [00:14,  1.11s/it]\n",
      "17it [00:15,  1.12s/it]\n",
      "18it [00:16,  1.11s/it]\n",
      "19it [00:17,  1.03s/it]\n",
      "20it [00:17,  1.21it/s]\n",
      "20it [00:17,  1.12it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:02,  2.35s/it]\n",
      "2it [00:03,  1.60s/it]\n",
      "3it [00:04,  1.15s/it]\n",
      "4it [00:05,  1.15s/it]\n",
      "5it [00:05,  1.07it/s]\n",
      "6it [00:06,  1.13it/s]\n",
      "7it [00:07,  1.27it/s]\n",
      "8it [00:07,  1.27it/s]\n",
      "9it [00:08,  1.43it/s]\n",
      "10it [00:09,  1.33it/s]\n",
      "11it [00:10,  1.29it/s]\n",
      "12it [00:11,  1.14it/s]\n",
      "13it [00:12,  1.15it/s]\n",
      "14it [00:12,  1.19it/s]\n",
      "15it [00:13,  1.27it/s]\n",
      "16it [00:14,  1.21it/s]\n",
      "17it [00:15,  1.25it/s]\n",
      "18it [00:15,  1.68it/s]\n",
      "19it [00:15,  1.62it/s]\n",
      "20it [00:16,  1.52it/s]\n",
      "21it [00:18,  1.11it/s]\n",
      "21it [00:18,  1.16it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:01,  1.40s/it]\n",
      "2it [00:01,  1.36it/s]\n",
      "3it [00:02,  1.44it/s]\n",
      "4it [00:03,  1.45it/s]\n",
      "5it [00:03,  1.33it/s]\n",
      "6it [00:04,  1.29it/s]\n",
      "7it [00:05,  1.32it/s]\n",
      "8it [00:06,  1.38it/s]\n",
      "9it [00:06,  1.44it/s]\n",
      "10it [00:07,  1.72it/s]\n",
      "11it [00:07,  2.02it/s]\n",
      "12it [00:08,  1.37it/s]\n",
      "13it [00:09,  1.50it/s]\n",
      "14it [00:10,  1.27it/s]\n",
      "15it [00:10,  1.56it/s]\n",
      "16it [00:11,  1.42it/s]\n",
      "17it [00:12,  1.23it/s]\n",
      "18it [00:13,  1.30it/s]\n",
      "19it [00:13,  1.36it/s]\n",
      "20it [00:14,  1.37it/s]\n",
      "20it [00:14,  1.39it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:01,  1.36s/it]\n",
      "2it [00:01,  1.34it/s]\n",
      "3it [00:03,  1.43s/it]\n",
      "4it [00:04,  1.08s/it]\n",
      "5it [00:05,  1.03it/s]\n",
      "6it [00:06,  1.07it/s]\n",
      "7it [00:06,  1.16it/s]\n",
      "8it [00:07,  1.13it/s]\n",
      "9it [00:09,  1.03s/it]\n",
      "10it [00:09,  1.04it/s]\n",
      "11it [00:11,  1.23s/it]\n",
      "12it [00:12,  1.05it/s]\n",
      "13it [00:12,  1.22it/s]\n",
      "14it [00:13,  1.32it/s]\n",
      "15it [00:13,  1.45it/s]\n",
      "16it [00:14,  1.25it/s]\n",
      "17it [00:15,  1.35it/s]\n",
      "18it [00:16,  1.13it/s]\n",
      "19it [00:17,  1.03it/s]\n",
      "20it [00:19,  1.31s/it]\n",
      "21it [00:20,  1.25s/it]\n",
      "21it [00:20,  1.00it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00,  4.19it/s]\n",
      "2it [00:01,  1.20it/s]\n",
      "3it [00:02,  1.20it/s]\n",
      "4it [00:03,  1.07s/it]\n",
      "5it [00:04,  1.06s/it]\n",
      "6it [00:05,  1.02it/s]\n",
      "7it [00:05,  1.38it/s]\n",
      "8it [00:06,  1.48it/s]\n",
      "9it [00:07,  1.44it/s]\n",
      "10it [00:07,  1.60it/s]\n",
      "11it [00:08,  1.30it/s]\n",
      "12it [00:09,  1.48it/s]\n",
      "13it [00:10,  1.29it/s]\n",
      "14it [00:11,  1.23it/s]\n",
      "15it [00:11,  1.37it/s]\n",
      "16it [00:11,  1.60it/s]\n",
      "17it [00:12,  1.47it/s]\n",
      "18it [00:13,  1.34it/s]\n",
      "19it [00:14,  1.30it/s]\n",
      "20it [00:15,  1.11it/s]\n",
      "20it [00:15,  1.27it/s]\n"
     ]
    }
   ],
   "source": [
    "!python ../Data_Preprocessing/Emotion_MIDI2.py ../Toy_Dataset/Lakh/ ./Processed_Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (817 > 512). Running this sequence through the model will result in indexing errors\n",
      "\n",
      "  6%|▌         | 1/18 [02:27<41:52, 147.81s/it]\n",
      " 17%|█▋        | 3/18 [02:27<09:35, 38.36s/it] \n",
      " 28%|██▊       | 5/18 [02:28<04:02, 18.69s/it]\n",
      " 56%|█████▌    | 10/18 [02:28<00:52,  6.61s/it]\n",
      " 89%|████████▉ | 16/18 [02:28<00:06,  3.15s/it]\n",
      "100%|██████████| 18/18 [02:28<00:00,  8.25s/it]\n",
      "\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]\n",
      " 10%|▉         | 2/21 [00:00<00:01, 10.49it/s]\n",
      " 48%|████▊     | 10/21 [00:00<00:00, 32.93it/s]\n",
      " 67%|██████▋   | 14/21 [00:00<00:00, 30.63it/s]\n",
      " 86%|████████▌ | 18/21 [00:00<00:00, 30.59it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 27.21it/s]\n",
      "\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]\n",
      " 11%|█         | 2/19 [00:00<00:01, 12.89it/s]\n",
      " 26%|██▋       | 5/19 [00:00<00:00, 18.32it/s]\n",
      " 47%|████▋     | 9/19 [00:00<00:00, 22.18it/s]\n",
      " 63%|██████▎   | 12/19 [00:00<00:00, 19.47it/s]\n",
      " 74%|███████▎  | 14/19 [00:00<00:00, 18.48it/s]\n",
      " 95%|█████████▍| 18/19 [00:00<00:00, 21.56it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 21.33it/s]\n",
      "\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]\n",
      " 29%|██▊       | 6/21 [00:00<00:00, 39.19it/s]\n",
      " 48%|████▊     | 10/21 [00:00<00:00, 26.78it/s]\n",
      " 71%|███████▏  | 15/21 [00:00<00:00, 30.87it/s]\n",
      " 95%|█████████▌| 20/21 [00:00<00:00, 31.36it/s]\n",
      "100%|██████████| 21/21 [00:00<00:00, 32.74it/s]\n",
      "\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]\n",
      " 47%|████▋     | 9/19 [00:00<00:00, 61.99it/s]\n",
      " 84%|████████▍ | 16/19 [00:00<00:00, 40.46it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 37.08it/s]\n",
      "\n",
      "  0%|          | 0/19 [00:00<?, ?it/s]\n",
      " 16%|█▌        | 3/19 [00:00<00:00, 17.33it/s]\n",
      " 53%|█████▎    | 10/19 [00:00<00:00, 32.19it/s]\n",
      " 74%|███████▎  | 14/19 [00:00<00:00, 25.79it/s]\n",
      " 89%|████████▉ | 17/19 [00:00<00:00, 19.92it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 22.26it/s]\n",
      "\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\n",
      " 17%|█▋        | 3/18 [00:00<00:00, 17.80it/s]\n",
      " 33%|███▎      | 6/18 [00:00<00:00, 19.39it/s]\n",
      " 61%|██████    | 11/18 [00:00<00:00, 27.15it/s]\n",
      " 78%|███████▊  | 14/18 [00:00<00:00, 24.15it/s]\n",
      " 94%|█████████▍| 17/18 [00:00<00:00, 23.03it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 22.41it/s]\n",
      "\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]\n",
      " 15%|█▌        | 3/20 [00:00<00:00, 19.16it/s]\n",
      " 45%|████▌     | 9/20 [00:00<00:00, 31.31it/s]\n",
      " 65%|██████▌   | 13/20 [00:00<00:00, 25.06it/s]\n",
      " 80%|████████  | 16/20 [00:00<00:00, 20.73it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 25.53it/s]\n",
      "\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\n",
      " 22%|██▏       | 4/18 [00:00<00:00, 23.66it/s]\n",
      " 50%|█████     | 9/18 [00:00<00:00, 30.42it/s]\n",
      " 72%|███████▏  | 13/18 [00:00<00:00, 30.71it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 34.27it/s]\n"
     ]
    }
   ],
   "source": [
    "!python ../Data_Preprocessing/Emotion_Label.py ./Processed_Data/ ./Processed_Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file=open(\"./Processed_Data/lakh_emotion.bin\",\"rb\")\n",
    "music_data = pickle.load(file) #保存list到文件\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['amazing', 'anger', 'angry', 'awe', 'emotional', 'excited', 'fear',\n",
       "       'happy', 'hopeful', 'hurt', 'joy', 'joyous', 'love', 'negative',\n",
       "       'positive', 'powerful', 'sad', 'sadness', 'strong', 'uneasy',\n",
       "       'upset'], dtype='<U9')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the labels\n",
    "np.unique([x[1] for x in music_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "a5ONeVUU7MOU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selected the most common one word labels\n",
    "from tqdm import tqdm\n",
    "X = []\n",
    "y = []\n",
    "chosen_label = ['sadness', 'happy', 'love', 'joy', 'negative', 'positive', 'anger',\n",
    "       'awe', 'emotional', 'hopeful', 'angry', 'excited', 'fear', 'hurt',\n",
    "       'fearful']\n",
    "# for i in tqdm(range(1,10)):\n",
    "file=open(\"./Processed_Data/lakh_emotion.bin\",\"rb\")\n",
    "music_data = pickle.load(file) #保存list到文件\n",
    "file.close()\n",
    "for m in music_data:\n",
    "    if m[1] in chosen_label:\n",
    "        X.append(m[0])\n",
    "        if m[1] == 'anger':\n",
    "            m[1] = 'angry'\n",
    "        if m[1] == 'fearful':\n",
    "            m[1] = 'fear'\n",
    "        if m[1] == 'joy':\n",
    "            m[1] = 'happy'\n",
    "        y.append(m[1])\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n",
    "X_new = []\n",
    "y_new = []\n",
    "for l in np.unique(y):\n",
    "    n = (y==l).sum()\n",
    "    if n>=6:\n",
    "        X_new += list(X[y==l])\n",
    "        y_new += list(y[y==l])\n",
    "X = X_new\n",
    "y = y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform labels into one-hot variable\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "label_dict = {}\n",
    "for cl in le.classes_:\n",
    "    label_dict.update({cl:le.transform([cl])[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, hiddenSize, outChannels, dropoutRate, activate):\n",
    "        super().__init__()\n",
    "        self.outChannels = outChannels\n",
    "        self.activate = nn.Sigmoid() if activate == \"Sigmoid\" else nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(1, 24, (10,1))\n",
    "        self.pool = nn.MaxPool2d((2, 1))\n",
    "        self.conv2 = nn.Conv2d(24, 48, (10,1))\n",
    "        self.conv3 = nn.Conv2d(48, 96, (10,1))\n",
    "        self.conv4 = nn.Conv2d(96, 192, (10,1))\n",
    "        self.conv5 = nn.Conv2d(192, 384, (5,2))\n",
    "        self.conv6 = nn.Conv2d(384, 192, (5,2))\n",
    "        self.dense1 = nn.Linear(48384, hiddenSize)\n",
    "        self.dropout = nn.Dropout(dropoutRate)\n",
    "        self.dense2 = nn.Linear(hiddenSize, num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.activate(self.conv1(x)))\n",
    "        x = self.pool(self.activate(self.conv2(x)))\n",
    "        # print(x.shape)\n",
    "        x = self.dropout(self.pool(self.activate(self.conv3(x))))\n",
    "        x = self.pool(self.activate(self.conv4(x)))\n",
    "        x = self.pool(self.activate(self.conv5(x)))\n",
    "        x = self.pool(self.activate(self.conv6(x)))\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 48384)\n",
    "        x = self.dropout(self.activate(self.dense1(x)))\n",
    "        return self.dense2(x)\n",
    "\n",
    "# Number of neurons in the first fully-connected layer\n",
    "hiddenSize = 4096\n",
    "# Number of feature filters in second convolutional layer\n",
    "numFilters = 25\n",
    "# Dropout rate\n",
    "dropoutRate = 0.2\n",
    "# Activation function\n",
    "activation = \"ReLU\"\n",
    "# Learning rate\n",
    "learningRate = 0.005\n",
    "# Momentum for SGD optimizer\n",
    "momentum = 0.9\n",
    "# Number of training epochs\n",
    "numEpochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define Trian and Validation function\n",
    "\n",
    "from tqdm import tqdm\n",
    "def train_epoch(cnn,device,dataloader,loss_fn,optimizer):\n",
    "    cnn.train()\n",
    "    cnnRunningLoss = 0\n",
    "    total = 0\n",
    "    R2 = 0\n",
    "    cnnCorrect=0\n",
    "    total1=0\n",
    "    for i, (inputs, labels) in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to('cuda').reshape(-1,1,512,128)\n",
    "        \n",
    "        labels = labels.to('cuda')\n",
    "        # Forward propagation\n",
    "        cnnOutputs = cnn(inputs)\n",
    "        # print(cnnOutputs.shape)\n",
    "        l2_lambda = 0.001\n",
    "        l2_reg = torch.tensor(0.).to('cuda')\n",
    "        for param in cnn.parameters():\n",
    "            l2_reg += torch.norm(param)\n",
    "        # Backpropagation\n",
    "        cnnLoss = criterion(cnnOutputs, labels)+l2_reg*l2_lambda\n",
    "        cnnLoss.backward()\n",
    "        # Gradient update\n",
    "        optimizer.step()\n",
    "        total += 1\n",
    "        total1+=labels.size(0)\n",
    "        cnnRunningLoss += cnnLoss.item()\n",
    "        _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n",
    "        cnnCorrect += (cnnPredicted == labels).sum().item()\n",
    "    return cnnRunningLoss/total, cnnCorrect/total1\n",
    "\n",
    "def valid_epoch(cnn,device,dataloader,loss_fn):\n",
    "    cnn.eval()\n",
    "    totalLoss = 0\n",
    "    total = 0\n",
    "    total1 = 0\n",
    "    R2 = 0\n",
    "    cnnLoss = 0\n",
    "    cnnCorrect=0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to('cuda').reshape(-1,1,512,128)\n",
    "        labels = labels.to('cuda')\n",
    "        cnnOutputs = cnn(inputs)\n",
    "        cnnLoss = loss_fn(cnnOutputs, labels)\n",
    "        _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        total1 +=1\n",
    "        totalLoss += cnnLoss.item()\n",
    "        cnnCorrect += (cnnPredicted == labels).sum().item()\n",
    "    accuracy = cnnCorrect / total * 100\n",
    "    cnn.train()\n",
    "    return totalLoss/total1, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12364\\AppData\\Local\\Temp\\ipykernel_28416\\3559418041.py:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:248.)\n",
      "  X_train_v = torch.as_tensor(X_train_v, dtype=torch.float) # an alternative to torch.from_numpy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Train Loss: 0.7697036862373352, Train_acc: 0.49, Test Loss: 0.6761884093284607, Test acc: 72.5\n",
      "Train Loss: 0.7461711168289185, Train_acc: 0.55, Test Loss: 0.6458510160446167, Test acc: 72.5\n",
      "Train Loss: 0.724836140871048, Train_acc: 0.555, Test Loss: 0.6015775203704834, Test acc: 72.5\n",
      "Train Loss: 0.6888376772403717, Train_acc: 0.555, Test Loss: 0.5476967692375183, Test acc: 72.5\n",
      "Train Loss: 0.6587979793548584, Train_acc: 0.555, Test Loss: 0.485847145318985, Test acc: 72.5\n",
      "Train Loss: 0.6181513965129852, Train_acc: 0.545, Test Loss: 0.4175747334957123, Test acc: 80.0\n",
      "Train Loss: 0.5705884993076324, Train_acc: 0.715, Test Loss: 0.34797707200050354, Test acc: 100.0\n",
      "Train Loss: 0.48794566094875336, Train_acc: 0.87, Test Loss: 0.28369516134262085, Test acc: 100.0\n",
      "Train Loss: 0.426048144698143, Train_acc: 0.9, Test Loss: 0.2043382227420807, Test acc: 100.0\n",
      "Train Loss: 0.3805948942899704, Train_acc: 0.9, Test Loss: 0.11149951070547104, Test acc: 100.0\n",
      "Train Loss: 0.33308058977127075, Train_acc: 0.9, Test Loss: 0.06959861516952515, Test acc: 100.0\n",
      "Train Loss: 0.3163900375366211, Train_acc: 0.9, Test Loss: 0.05531807988882065, Test acc: 100.0\n",
      "Train Loss: 0.284813791513443, Train_acc: 0.9, Test Loss: 0.05172526091337204, Test acc: 100.0\n",
      "Train Loss: 0.25483912229537964, Train_acc: 0.91, Test Loss: 0.05248630791902542, Test acc: 100.0\n",
      "Train Loss: 0.2549119219183922, Train_acc: 0.92, Test Loss: 0.03908716142177582, Test acc: 100.0\n",
      "Train Loss: 0.2539883852005005, Train_acc: 0.9, Test Loss: 0.03573928773403168, Test acc: 100.0\n",
      "Train Loss: 0.24073848873376846, Train_acc: 0.91, Test Loss: 0.029592037200927734, Test acc: 100.0\n",
      "Train Loss: 0.22387440502643585, Train_acc: 0.935, Test Loss: 0.02419864758849144, Test acc: 100.0\n",
      "Train Loss: 0.215408593416214, Train_acc: 0.935, Test Loss: 0.021133307367563248, Test acc: 100.0\n",
      "Train Loss: 0.21606924384832382, Train_acc: 0.935, Test Loss: 0.020383838564157486, Test acc: 100.0\n",
      "Fold 2\n",
      "Train Loss: 0.7592563033103943, Train_acc: 0.69, Test Loss: 0.6468126177787781, Test acc: 87.5\n",
      "Train Loss: 0.7072233557701111, Train_acc: 0.635, Test Loss: 0.5837342143058777, Test acc: 50.0\n",
      "Train Loss: 0.6420026421546936, Train_acc: 0.66, Test Loss: 0.5263938307762146, Test acc: 50.0\n",
      "Train Loss: 0.620351642370224, Train_acc: 0.65, Test Loss: 0.4924496114253998, Test acc: 67.5\n",
      "Train Loss: 0.4735764265060425, Train_acc: 0.87, Test Loss: 0.491900771856308, Test acc: 87.5\n",
      "Train Loss: 0.3709782809019089, Train_acc: 0.93, Test Loss: 0.5055752992630005, Test acc: 87.5\n",
      "Train Loss: 0.3026963025331497, Train_acc: 0.93, Test Loss: 0.3662284314632416, Test acc: 87.5\n",
      "Train Loss: 0.26443684101104736, Train_acc: 0.93, Test Loss: 0.3417172431945801, Test acc: 87.5\n",
      "Train Loss: 0.25674568116664886, Train_acc: 0.93, Test Loss: 0.35099607706069946, Test acc: 87.5\n",
      "Train Loss: 0.26999469101428986, Train_acc: 0.93, Test Loss: 0.3244456648826599, Test acc: 87.5\n",
      "Train Loss: 0.2411995679140091, Train_acc: 0.93, Test Loss: 0.22770635783672333, Test acc: 87.5\n",
      "Train Loss: 0.22930698096752167, Train_acc: 0.93, Test Loss: 0.4184454083442688, Test acc: 65.0\n",
      "Train Loss: 0.24598154425621033, Train_acc: 0.94, Test Loss: 0.3399161696434021, Test acc: 87.5\n",
      "Train Loss: 0.46781256794929504, Train_acc: 0.905, Test Loss: 0.41943439841270447, Test acc: 87.5\n",
      "Train Loss: 0.26128238439559937, Train_acc: 0.93, Test Loss: 0.12954097986221313, Test acc: 100.0\n",
      "Train Loss: 0.337852418422699, Train_acc: 0.905, Test Loss: 0.19312456250190735, Test acc: 87.5\n",
      "Train Loss: 0.2185715287923813, Train_acc: 0.93, Test Loss: 0.39392247796058655, Test acc: 87.5\n",
      "Train Loss: 0.23601152002811432, Train_acc: 0.93, Test Loss: 0.4999849200248718, Test acc: 87.5\n",
      "Train Loss: 0.25212667882442474, Train_acc: 0.93, Test Loss: 0.534103274345398, Test acc: 87.5\n",
      "Train Loss: 0.2707640379667282, Train_acc: 0.93, Test Loss: 0.5107189416885376, Test acc: 87.5\n",
      "Fold 3\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 792723456 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28416\\3559418041.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mtest_dataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNNModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhiddenSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumFilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropoutRate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearningRate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28416\\233391211.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, hiddenSize, outChannels, dropoutRate, activate)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m192\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m384\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv6\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m384\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m192\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m48384\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhiddenSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdropoutRate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhiddenSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\programing\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0min_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfactory_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfactory_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 792723456 bytes."
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "X_train_v, X_test, y_train_v, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) # First Split the dataset and use the training set for 5-fold validation\n",
    "\n",
    "X_train_v = torch.as_tensor(X_train_v, dtype=torch.float) # an alternative to torch.from_numpy\n",
    "y_train_v = torch.as_tensor(y_train_v, dtype=torch.float)\n",
    "X_test = torch.as_tensor(X_test, dtype=torch.float)\n",
    "y_test = torch.as_tensor(y_test, dtype=torch.float)\n",
    "splits=StratifiedKFold(n_splits=5,shuffle=True,random_state=99)\n",
    "train_dataset = TensorDataset(X_train_v, y_train_v)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size=128\n",
    "models = []\n",
    "history = {'fold':[], 'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(X_train_v,y_train_v)):\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "    t = pd.DataFrame(y_train_v[train_idx], columns = ['class']).reset_index()\n",
    "    idx = []\n",
    "    # Resample to avoid unbalanced dataset\n",
    "    y_train = []\n",
    "    for i in range(0,num_labels):\n",
    "      idx += list(t[t['class']==i].sample(100,replace=True)['index'])\n",
    "      y_train += [i]*100\n",
    "    X_train = X_train_v[train_idx][idx]\n",
    "\n",
    "    t = pd.DataFrame(y_train_v[val_idx], columns = ['class']).reset_index()\n",
    "    idx = []\n",
    "    y_val = []\n",
    "    for i in range(0,num_labels):\n",
    "      # print(i)\n",
    "      if i in t['class'].values:\n",
    "          idx += list(t[t['class']==i].sample(20,replace=True)['index'])\n",
    "          y_val += [i]*20\n",
    "    X_val =  X_train_v[val_idx][idx]\n",
    "\n",
    "    X_train = torch.as_tensor(X_train, dtype=torch.float) # an alternative to torch.from_numpy\n",
    "    y_train = torch.as_tensor(y_train, dtype=torch.float).type(torch.LongTensor)\n",
    "    X_val = torch.as_tensor(X_val, dtype=torch.float)\n",
    "    y_val = torch.as_tensor(y_val, dtype=torch.float).type(torch.LongTensor)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "    \n",
    "    model = CNNModel(hiddenSize, numFilters, dropoutRate, activation).to('cuda')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(list(model.parameters()), lr=learningRate, momentum=momentum)\n",
    "    # optimizer = torch.optim.Adam(list(model.parameters()), lr=learningRate)\n",
    "    best_test = -np.inf\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(numEpochs):\n",
    "        train_loss, train_R2=train_epoch(model,device,train_dataloader,criterion,optimizer)\n",
    "        test_loss, test_R2=valid_epoch(model,device,test_dataloader,criterion)\n",
    "        history['fold'].append(fold)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['train_acc'].append(train_R2)\n",
    "        history['test_acc'].append(test_R2)   \n",
    "        if test_R2>best_test:\n",
    "            test_test = test_R2\n",
    "            best_model = model\n",
    "        print('Train Loss: {}, Train_acc: {}, Test Loss: {}, Test acc: {}'.format(train_loss, train_R2, test_loss, test_R2))\n",
    "    models.append([best_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Caculate the average accuray\n",
    "X_train_v, X_test, y_train_v, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "t = pd.DataFrame(y_test, columns = ['class']).reset_index()\n",
    "idx = []\n",
    "y_test = []\n",
    "for i in range(0,num_labels):\n",
    "    if i in t['class'].values:\n",
    "        idx += list(t[t['class']==i].sample(20,replace=True)['index'])\n",
    "        y_test += [i]*20\n",
    "X_test =  X_test[idx]\n",
    "X_test = torch.as_tensor(X_test, dtype=torch.float)\n",
    "y_test = torch.as_tensor(y_test, dtype=torch.float).type(torch.LongTensor)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "acc=[]\n",
    "for best_model in models:\n",
    "    acc.append(valid_epoch(best_model[0],device,test_dataloader,criterion)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.27272727272727"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.54545454545454"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the accuray of the ensemble model\n",
    "outputs = []    \n",
    "for model in models:\n",
    "  model[0].eval()\n",
    "  model_output = []\n",
    "  label_= []\n",
    "  model[0].to('cpu')\n",
    "  for inputs, labels in test_dataloader:\n",
    "      inputs = inputs.to('cpu').reshape(-1,1,512,128)\n",
    "      labels = labels.to('cpu')\n",
    "      cnnOutputs = model[0](inputs)\n",
    "      model_output.append(cnnOutputs)\n",
    "      label_.append(labels)\n",
    "  outputs.append(torch.vstack(model_output))\n",
    "cnnresult = torch.vstack(outputs).reshape(-1,shape[0],shape[1]).mean(axis=0)\n",
    "labels = np.hstack(label_)\n",
    "_, cnnPredicted = torch.max(cnnresult.data, 1)\n",
    "cnnCorrect = (cnnPredicted.detach().numpy() == labels).sum().item()\n",
    "cnnCorrect/len(labels)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confu_m = confusion_matrix(labels, cnnPredicted)\n",
    "import seaborn as sns\n",
    "sns.heatmap(confu_m,square=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry': 0,\n",
       " 'awe': 1,\n",
       " 'emotional': 2,\n",
       " 'excited': 3,\n",
       " 'fear': 4,\n",
       " 'happy': 5,\n",
       " 'hopeful': 6,\n",
       " 'hurt': 7,\n",
       " 'love': 8,\n",
       " 'negative': 9,\n",
       " 'positive': 10,\n",
       " 'sadness': 11}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {}\n",
    "for cl in le.classes_:\n",
    "    label_dict.update({cl:le.transform([cl])[0]})\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angry</th>\n",
       "      <th>awe</th>\n",
       "      <th>emotional</th>\n",
       "      <th>excited</th>\n",
       "      <th>fear</th>\n",
       "      <th>happy</th>\n",
       "      <th>hopeful</th>\n",
       "      <th>hurt</th>\n",
       "      <th>love</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.45000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.377358</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.62069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               angry   awe  emotional    excited       fear      happy  \\\n",
       "precision   0.550000   1.0   0.750000   0.650000   1.000000   0.600000   \n",
       "recall      0.846154   1.0   0.600000   1.000000   0.377358   0.333333   \n",
       "f1          0.666667   1.0   0.666667   0.787879   0.547945   0.428571   \n",
       "support    13.000000  20.0  25.000000  13.000000  53.000000  36.000000   \n",
       "\n",
       "           hopeful  hurt       love   negative  positive  sadness  \n",
       "precision  0.45000   0.0   0.350000   0.200000      0.45      0.0  \n",
       "recall     1.00000   0.0   0.368421   0.333333      0.90      0.0  \n",
       "f1         0.62069   0.0   0.358974   0.250000      0.60      0.0  \n",
       "support    9.00000   0.0  19.000000  12.000000     10.00     10.0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "scores = pd.DataFrame(precision_recall_fscore_support(cnnPredicted, labels, labels = list(range(12))),index=['precision','recall','f1','support'], columns = list(label_dict)[:12])\n",
    "scores"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
