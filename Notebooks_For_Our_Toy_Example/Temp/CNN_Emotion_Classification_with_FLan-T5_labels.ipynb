{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "u8eSS9tg62ge",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# import mido\n",
    "import string\n",
    "import numpy as np\n",
    "# from utilis import get_pianoroll_data\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# import mido\n",
    "import string\n",
    "import numpy as np\n",
    "# from utilis import get_pianoroll_data\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "All content numbers is 18\n",
      "Total number of muisc 182\n",
      "Total number of muisc 434\n",
      "Total number of muisc 691\n",
      "Total number of muisc 942\n",
      "Total number of muisc 1248\n",
      "Total number of muisc 1568\n",
      "Total number of muisc 1885\n",
      "Total number of muisc 2180\n",
      "Total number of muisc 2417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]\n",
      " 83%|████████▎ | 15/18 [00:00<00:00, 129.85it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 58.34it/s] \n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "3it [00:00, 10.43it/s]\n",
      "6it [00:00, 16.84it/s]\n",
      "11it [00:00, 24.84it/s]\n",
      "15it [00:00, 28.82it/s]\n",
      "22it [00:00, 31.46it/s]\n",
      "56it [00:00, 93.99it/s]\n",
      "66it [00:01, 60.94it/s]\n",
      "74it [00:01, 52.76it/s]\n",
      "81it [00:01, 40.83it/s]\n",
      "86it [00:02, 37.24it/s]\n",
      "91it [00:02, 37.37it/s]\n",
      "105it [00:02, 54.26it/s]\n",
      "118it [00:02, 69.16it/s]\n",
      "143it [00:02, 107.74it/s]\n",
      "157it [00:02, 97.57it/s] \n",
      "169it [00:02, 87.04it/s]\n",
      "180it [00:03, 76.59it/s]\n",
      "189it [00:03, 57.25it/s]\n",
      "197it [00:03, 47.33it/s]\n",
      "211it [00:03, 60.57it/s]\n",
      "221it [00:03, 52.89it/s]\n",
      "228it [00:04, 51.92it/s]\n",
      "235it [00:04, 53.71it/s]\n",
      "243it [00:04, 55.18it/s]\n",
      "255it [00:04, 68.49it/s]\n",
      "263it [00:04, 40.42it/s]\n",
      "269it [00:05, 43.48it/s]\n",
      "275it [00:05, 42.35it/s]\n",
      "281it [00:05, 44.18it/s]\n",
      "287it [00:05, 26.34it/s]\n",
      "292it [00:06, 22.38it/s]\n",
      "296it [00:06, 23.33it/s]\n",
      "301it [00:06, 26.06it/s]\n",
      "305it [00:06, 21.77it/s]\n",
      "308it [00:07, 14.70it/s]\n",
      "311it [00:07, 13.09it/s]\n",
      "313it [00:07, 12.04it/s]\n",
      "320it [00:07, 18.31it/s]\n",
      "323it [00:07, 18.12it/s]\n",
      "328it [00:08, 21.12it/s]\n",
      "331it [00:08, 16.39it/s]\n",
      "333it [00:08, 11.25it/s]\n",
      "335it [00:09,  8.33it/s]\n",
      "337it [00:09,  7.86it/s]\n",
      "339it [00:10,  7.15it/s]\n",
      "342it [00:10,  9.08it/s]\n",
      "346it [00:10, 11.83it/s]\n",
      "348it [00:10, 12.22it/s]\n",
      "355it [00:10, 18.67it/s]\n",
      "358it [00:10, 18.03it/s]\n",
      "360it [00:11, 15.22it/s]\n",
      "363it [00:11, 17.68it/s]\n",
      "366it [00:11, 18.92it/s]\n",
      "393it [00:11, 68.55it/s]\n",
      "402it [00:11, 46.67it/s]\n",
      "409it [00:12, 41.38it/s]\n",
      "415it [00:12, 28.87it/s]\n",
      "422it [00:12, 31.33it/s]\n",
      "427it [00:13, 19.21it/s]\n",
      "430it [00:13, 31.56it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "1it [00:00,  5.61it/s]\n",
      "2it [00:00,  4.67it/s]\n",
      "3it [00:00,  5.60it/s]\n",
      "6it [00:00,  8.12it/s]\n",
      "11it [00:00, 15.92it/s]\n",
      "16it [00:01, 22.00it/s]\n",
      "19it [00:01, 20.53it/s]\n",
      "22it [00:01, 10.81it/s]\n",
      "24it [00:02,  8.09it/s]\n",
      "26it [00:02,  8.26it/s]\n",
      "28it [00:02,  8.91it/s]\n",
      "31it [00:02, 11.56it/s]\n",
      "33it [00:03,  9.19it/s]\n",
      "35it [00:03, 10.26it/s]\n",
      "37it [00:03,  9.95it/s]\n",
      "39it [00:03, 11.21it/s]\n",
      "41it [00:03,  9.95it/s]\n",
      "47it [00:04, 15.59it/s]\n",
      "50it [00:04, 14.25it/s]\n",
      "52it [00:04, 12.17it/s]\n",
      "54it [00:04, 10.22it/s]\n",
      "57it [00:05, 11.93it/s]\n",
      "59it [00:05, 10.30it/s]\n",
      "61it [00:05, 10.79it/s]\n",
      "65it [00:05, 13.88it/s]\n",
      "67it [00:05, 13.54it/s]\n",
      "69it [00:06, 13.14it/s]\n",
      "75it [00:06, 16.27it/s]\n",
      "77it [00:06, 11.66it/s]\n",
      "81it [00:06, 14.92it/s]\n",
      "86it [00:07, 16.13it/s]\n",
      "89it [00:07, 13.54it/s]\n",
      "91it [00:07, 11.76it/s]\n",
      "93it [00:08,  9.85it/s]\n",
      "97it [00:08, 13.25it/s]\n",
      "99it [00:08, 11.94it/s]\n",
      "102it [00:08, 13.32it/s]\n",
      "105it [00:08, 14.40it/s]\n",
      "107it [00:08, 13.63it/s]\n",
      "109it [00:09, 14.26it/s]\n",
      "111it [00:09, 12.77it/s]\n",
      "115it [00:09, 16.11it/s]\n",
      "117it [00:09, 13.35it/s]\n",
      "119it [00:09, 11.17it/s]\n",
      "121it [00:10, 10.02it/s]\n",
      "123it [00:10,  9.68it/s]\n",
      "125it [00:10,  9.76it/s]\n",
      "128it [00:10, 12.15it/s]\n",
      "131it [00:10, 14.59it/s]\n",
      "134it [00:11, 14.61it/s]\n",
      "136it [00:11, 14.98it/s]\n",
      "138it [00:11, 12.12it/s]\n",
      "140it [00:11, 12.54it/s]\n",
      "142it [00:11, 11.16it/s]\n",
      "144it [00:11, 12.20it/s]\n",
      "146it [00:12,  6.75it/s]\n",
      "148it [00:12,  6.72it/s]\n",
      "150it [00:13,  7.75it/s]\n",
      "152it [00:13,  8.43it/s]\n",
      "154it [00:13,  8.43it/s]\n",
      "155it [00:13,  7.44it/s]\n",
      "156it [00:13,  6.23it/s]\n",
      "157it [00:14,  6.75it/s]\n",
      "159it [00:14,  8.97it/s]\n",
      "161it [00:14,  8.00it/s]\n",
      "162it [00:14,  6.66it/s]\n",
      "163it [00:14,  5.99it/s]\n",
      "164it [00:15,  6.30it/s]\n",
      "167it [00:15, 10.14it/s]\n",
      "178it [00:15, 24.74it/s]\n",
      "181it [00:15, 16.58it/s]\n",
      "183it [00:16, 13.36it/s]\n",
      "188it [00:16, 17.25it/s]\n",
      "191it [00:16, 12.05it/s]\n",
      "193it [00:17,  8.37it/s]\n",
      "195it [00:17,  7.28it/s]\n",
      "197it [00:17,  8.32it/s]\n",
      "201it [00:17, 11.02it/s]\n",
      "204it [00:18, 10.25it/s]\n",
      "207it [00:18, 12.34it/s]\n",
      "209it [00:18, 12.48it/s]\n",
      "213it [00:18, 15.77it/s]\n",
      "217it [00:18, 16.01it/s]\n",
      "230it [00:19, 34.31it/s]\n",
      "235it [00:19, 32.69it/s]\n",
      "240it [00:19, 23.52it/s]\n",
      "244it [00:19, 25.02it/s]\n",
      "249it [00:19, 23.45it/s]\n",
      "271it [00:20, 45.43it/s]\n",
      "276it [00:20, 43.05it/s]\n",
      "286it [00:20, 45.61it/s]\n",
      "291it [00:20, 33.79it/s]\n",
      "295it [00:21, 24.59it/s]\n",
      "306it [00:21, 36.21it/s]\n",
      "312it [00:21, 29.16it/s]\n",
      "318it [00:21, 32.00it/s]\n",
      "323it [00:22, 23.73it/s]\n",
      "327it [00:22, 22.57it/s]\n",
      "330it [00:22, 17.19it/s]\n",
      "333it [00:22, 16.26it/s]\n",
      "336it [00:23, 15.93it/s]\n",
      "338it [00:23, 16.26it/s]\n",
      "340it [00:23, 15.62it/s]\n",
      "342it [00:23, 15.31it/s]\n",
      "344it [00:23, 15.46it/s]\n",
      "346it [00:23, 15.42it/s]\n",
      "348it [00:24,  8.92it/s]\n",
      "350it [00:24,  7.07it/s]\n",
      "352it [00:24,  8.09it/s]\n",
      "354it [00:25,  7.42it/s]\n",
      "362it [00:25, 15.93it/s]\n",
      "365it [00:25, 11.55it/s]\n",
      "367it [00:26, 11.32it/s]\n",
      "369it [00:26, 12.33it/s]\n",
      "371it [00:26, 12.73it/s]\n",
      "373it [00:26,  9.50it/s]\n",
      "375it [00:26,  9.75it/s]\n",
      "377it [00:27,  9.98it/s]\n",
      "382it [00:27, 12.14it/s]\n",
      "384it [00:27, 12.15it/s]\n",
      "386it [00:27,  9.20it/s]\n",
      "390it [00:28, 13.36it/s]\n",
      "395it [00:28, 13.79it/s]\n",
      "399it [00:28, 16.89it/s]\n",
      "402it [00:28, 11.46it/s]\n",
      "404it [00:29, 11.65it/s]\n",
      "408it [00:29, 10.35it/s]\n",
      "411it [00:29, 10.46it/s]\n",
      "417it [00:30, 12.48it/s]\n",
      "420it [00:30, 14.32it/s]\n",
      "422it [00:30, 13.64it/s]\n",
      "428it [00:30, 20.28it/s]\n",
      "431it [00:30, 14.05it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "7it [00:00, 55.49it/s]\n",
      "13it [00:00, 35.24it/s]\n",
      "18it [00:00, 30.29it/s]\n",
      "22it [00:00, 21.31it/s]\n",
      "25it [00:01, 20.50it/s]\n",
      "28it [00:01, 21.62it/s]\n",
      "40it [00:01, 41.76it/s]\n",
      "46it [00:01, 28.18it/s]\n",
      "51it [00:02, 21.02it/s]\n",
      "63it [00:02, 30.89it/s]\n",
      "68it [00:02, 29.65it/s]\n",
      "72it [00:02, 21.80it/s]\n",
      "75it [00:02, 21.95it/s]\n",
      "79it [00:03, 24.48it/s]\n",
      "83it [00:03, 24.26it/s]\n",
      "86it [00:03, 22.80it/s]\n",
      "92it [00:03, 29.18it/s]\n",
      "104it [00:03, 34.79it/s]\n",
      "108it [00:03, 29.54it/s]\n",
      "116it [00:04, 38.30it/s]\n",
      "123it [00:04, 44.13it/s]\n",
      "129it [00:04, 42.82it/s]\n",
      "134it [00:04, 40.52it/s]\n",
      "139it [00:04, 37.30it/s]\n",
      "145it [00:04, 37.07it/s]\n",
      "149it [00:05, 29.98it/s]\n",
      "153it [00:05, 25.49it/s]\n",
      "156it [00:05, 25.14it/s]\n",
      "159it [00:05, 20.75it/s]\n",
      "166it [00:05, 27.72it/s]\n",
      "170it [00:06, 21.44it/s]\n",
      "179it [00:06, 24.35it/s]\n",
      "182it [00:06, 22.89it/s]\n",
      "187it [00:06, 24.36it/s]\n",
      "192it [00:06, 26.43it/s]\n",
      "195it [00:07, 24.02it/s]\n",
      "200it [00:07, 26.73it/s]\n",
      "203it [00:07, 26.31it/s]\n",
      "210it [00:07, 33.48it/s]\n",
      "215it [00:07, 37.13it/s]\n",
      "219it [00:07, 34.37it/s]\n",
      "223it [00:08, 20.90it/s]\n",
      "226it [00:08, 17.44it/s]\n",
      "241it [00:08, 37.25it/s]\n",
      "247it [00:08, 32.31it/s]\n",
      "252it [00:08, 34.06it/s]\n",
      "265it [00:08, 50.71it/s]\n",
      "272it [00:09, 43.49it/s]\n",
      "278it [00:09, 33.29it/s]\n",
      "283it [00:09, 25.40it/s]\n",
      "287it [00:09, 26.98it/s]\n",
      "291it [00:10, 23.02it/s]\n",
      "294it [00:10, 20.64it/s]\n",
      "297it [00:10, 21.88it/s]\n",
      "304it [00:10, 22.27it/s]\n",
      "311it [00:11, 24.97it/s]\n",
      "314it [00:11, 25.15it/s]\n",
      "319it [00:11, 29.24it/s]\n",
      "326it [00:11, 37.00it/s]\n",
      "331it [00:11, 34.25it/s]\n",
      "337it [00:11, 27.76it/s]\n",
      "341it [00:11, 28.87it/s]\n",
      "347it [00:12, 32.84it/s]\n",
      "355it [00:12, 34.10it/s]\n",
      "359it [00:12, 33.10it/s]\n",
      "363it [00:12, 32.04it/s]\n",
      "369it [00:12, 33.21it/s]\n",
      "374it [00:12, 35.80it/s]\n",
      "378it [00:13, 29.18it/s]\n",
      "383it [00:13, 33.33it/s]\n",
      "387it [00:13, 34.26it/s]\n",
      "391it [00:13, 35.51it/s]\n",
      "396it [00:13, 33.55it/s]\n",
      "402it [00:13, 37.09it/s]\n",
      "409it [00:13, 40.47it/s]\n",
      "414it [00:13, 40.39it/s]\n",
      "419it [00:14, 25.20it/s]\n",
      "428it [00:14, 28.28it/s]\n",
      "431it [00:14, 28.80it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "9it [00:00, 75.00it/s]\n",
      "24it [00:00, 96.15it/s]\n",
      "34it [00:00, 97.09it/s]\n",
      "44it [00:00, 65.22it/s]\n",
      "52it [00:00, 51.14it/s]\n",
      "59it [00:01, 41.49it/s]\n",
      "75it [00:01, 55.44it/s]\n",
      "92it [00:01, 73.40it/s]\n",
      "101it [00:01, 61.05it/s]\n",
      "109it [00:01, 60.56it/s]\n",
      "116it [00:02, 45.61it/s]\n",
      "122it [00:02, 39.82it/s]\n",
      "135it [00:02, 54.65it/s]\n",
      "142it [00:02, 52.34it/s]\n",
      "150it [00:02, 57.85it/s]\n",
      "157it [00:02, 50.94it/s]\n",
      "163it [00:03, 31.25it/s]\n",
      "174it [00:03, 41.81it/s]\n",
      "180it [00:03, 39.52it/s]\n",
      "186it [00:03, 32.84it/s]\n",
      "194it [00:03, 39.10it/s]\n",
      "203it [00:04, 48.37it/s]\n",
      "218it [00:04, 65.68it/s]\n",
      "231it [00:04, 55.12it/s]\n",
      "238it [00:04, 38.05it/s]\n",
      "244it [00:05, 37.87it/s]\n",
      "249it [00:05, 32.15it/s]\n",
      "253it [00:05, 30.87it/s]\n",
      "268it [00:05, 50.85it/s]\n",
      "275it [00:05, 32.97it/s]\n",
      "281it [00:06, 33.38it/s]\n",
      "288it [00:06, 38.94it/s]\n",
      "294it [00:06, 29.94it/s]\n",
      "299it [00:06, 25.30it/s]\n",
      "303it [00:07, 20.42it/s]\n",
      "306it [00:07, 19.58it/s]\n",
      "310it [00:07, 21.12it/s]\n",
      "317it [00:07, 27.02it/s]\n",
      "322it [00:07, 28.70it/s]\n",
      "331it [00:07, 38.70it/s]\n",
      "336it [00:08, 37.65it/s]\n",
      "341it [00:08, 33.21it/s]\n",
      "345it [00:08, 33.77it/s]\n",
      "349it [00:08, 30.09it/s]\n",
      "353it [00:08, 22.37it/s]\n",
      "356it [00:09, 21.06it/s]\n",
      "360it [00:09, 22.97it/s]\n",
      "367it [00:09, 31.24it/s]\n",
      "371it [00:09, 25.20it/s]\n",
      "375it [00:09, 22.58it/s]\n",
      "379it [00:09, 25.16it/s]\n",
      "384it [00:10, 25.31it/s]\n",
      "388it [00:10, 27.28it/s]\n",
      "392it [00:10, 29.34it/s]\n",
      "398it [00:10, 34.93it/s]\n",
      "402it [00:10, 29.83it/s]\n",
      "406it [00:10, 20.82it/s]\n",
      "409it [00:11, 19.38it/s]\n",
      "417it [00:11, 29.32it/s]\n",
      "421it [00:11, 23.30it/s]\n",
      "428it [00:11, 29.09it/s]\n",
      "431it [00:11, 36.64it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "4it [00:00, 39.79it/s]\n",
      "8it [00:00, 24.14it/s]\n",
      "11it [00:00, 23.11it/s]\n",
      "14it [00:00, 25.13it/s]\n",
      "20it [00:00, 29.68it/s]\n",
      "24it [00:00, 25.97it/s]\n",
      "27it [00:01, 24.16it/s]\n",
      "30it [00:01, 21.63it/s]\n",
      "33it [00:01, 22.95it/s]\n",
      "47it [00:01, 46.77it/s]\n",
      "52it [00:01, 38.06it/s]\n",
      "62it [00:01, 39.99it/s]\n",
      "70it [00:02, 45.64it/s]\n",
      "75it [00:02, 37.12it/s]\n",
      "86it [00:02, 44.96it/s]\n",
      "91it [00:02, 35.95it/s]\n",
      "95it [00:03, 16.45it/s]\n",
      "98it [00:03, 17.76it/s]\n",
      "103it [00:03, 21.84it/s]\n",
      "107it [00:03, 24.31it/s]\n",
      "111it [00:04, 15.02it/s]\n",
      "117it [00:04, 18.31it/s]\n",
      "120it [00:04, 18.77it/s]\n",
      "124it [00:04, 21.73it/s]\n",
      "127it [00:05, 16.20it/s]\n",
      "131it [00:05, 17.15it/s]\n",
      "135it [00:05, 20.21it/s]\n",
      "140it [00:05, 22.22it/s]\n",
      "143it [00:05, 18.44it/s]\n",
      "148it [00:06, 17.37it/s]\n",
      "151it [00:06, 13.34it/s]\n",
      "154it [00:06, 15.21it/s]\n",
      "171it [00:06, 38.69it/s]\n",
      "178it [00:07, 31.20it/s]\n",
      "189it [00:07, 41.35it/s]\n",
      "196it [00:08, 22.23it/s]\n",
      "201it [00:08, 18.81it/s]\n",
      "205it [00:08, 20.12it/s]\n",
      "214it [00:08, 27.88it/s]\n",
      "219it [00:08, 29.60it/s]\n",
      "224it [00:09, 23.78it/s]\n",
      "230it [00:09, 28.19it/s]\n",
      "234it [00:09, 23.86it/s]\n",
      "241it [00:09, 30.74it/s]\n",
      "247it [00:09, 34.06it/s]\n",
      "252it [00:09, 34.96it/s]\n",
      "259it [00:10, 30.26it/s]\n",
      "263it [00:10, 23.31it/s]\n",
      "269it [00:10, 28.00it/s]\n",
      "273it [00:10, 22.35it/s]\n",
      "276it [00:11, 21.15it/s]\n",
      "279it [00:11, 21.74it/s]\n",
      "282it [00:11, 15.21it/s]\n",
      "284it [00:11, 12.56it/s]\n",
      "287it [00:12,  9.93it/s]\n",
      "292it [00:12, 13.74it/s]\n",
      "298it [00:12, 18.73it/s]\n",
      "303it [00:12, 23.04it/s]\n",
      "308it [00:13, 21.25it/s]\n",
      "313it [00:13, 25.56it/s]\n",
      "320it [00:13, 29.39it/s]\n",
      "324it [00:13, 31.23it/s]\n",
      "349it [00:13, 71.02it/s]\n",
      "357it [00:14, 40.12it/s]\n",
      "367it [00:14, 46.69it/s]\n",
      "374it [00:14, 36.45it/s]\n",
      "380it [00:14, 31.21it/s]\n",
      "385it [00:15, 28.01it/s]\n",
      "389it [00:15, 26.67it/s]\n",
      "393it [00:15, 21.52it/s]\n",
      "396it [00:15, 22.61it/s]\n",
      "399it [00:15, 22.93it/s]\n",
      "402it [00:15, 20.56it/s]\n",
      "405it [00:16, 19.24it/s]\n",
      "410it [00:16, 23.86it/s]\n",
      "416it [00:16, 30.64it/s]\n",
      "420it [00:16, 22.11it/s]\n",
      "423it [00:16, 20.87it/s]\n",
      "426it [00:17, 22.26it/s]\n",
      "429it [00:17, 20.99it/s]\n",
      "431it [00:17, 25.05it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "5it [00:00, 32.51it/s]\n",
      "9it [00:00, 27.01it/s]\n",
      "14it [00:00, 28.80it/s]\n",
      "20it [00:00, 36.07it/s]\n",
      "24it [00:00, 32.69it/s]\n",
      "30it [00:00, 38.88it/s]\n",
      "35it [00:01, 29.97it/s]\n",
      "39it [00:01, 24.15it/s]\n",
      "42it [00:01, 21.57it/s]\n",
      "86it [00:01, 94.51it/s]\n",
      "99it [00:02, 60.98it/s]\n",
      "109it [00:02, 34.24it/s]\n",
      "116it [00:03, 29.69it/s]\n",
      "126it [00:03, 34.80it/s]\n",
      "132it [00:03, 26.94it/s]\n",
      "137it [00:03, 28.81it/s]\n",
      "142it [00:04, 26.10it/s]\n",
      "146it [00:04, 23.85it/s]\n",
      "151it [00:04, 26.53it/s]\n",
      "155it [00:04, 28.41it/s]\n",
      "159it [00:04, 28.32it/s]\n",
      "163it [00:04, 28.25it/s]\n",
      "167it [00:05, 27.19it/s]\n",
      "170it [00:05, 24.87it/s]\n",
      "175it [00:05, 30.10it/s]\n",
      "184it [00:05, 43.59it/s]\n",
      "189it [00:05, 41.76it/s]\n",
      "198it [00:05, 49.19it/s]\n",
      "204it [00:05, 42.47it/s]\n",
      "209it [00:06, 30.48it/s]\n",
      "213it [00:06, 31.38it/s]\n",
      "218it [00:06, 34.85it/s]\n",
      "222it [00:06, 32.98it/s]\n",
      "226it [00:06, 28.61it/s]\n",
      "235it [00:07, 31.47it/s]\n",
      "239it [00:07, 31.67it/s]\n",
      "247it [00:07, 32.68it/s]\n",
      "252it [00:07, 27.18it/s]\n",
      "256it [00:07, 23.57it/s]\n",
      "260it [00:08, 25.53it/s]\n",
      "263it [00:08, 23.02it/s]\n",
      "266it [00:08, 20.09it/s]\n",
      "273it [00:08, 27.88it/s]\n",
      "277it [00:08, 27.93it/s]\n",
      "281it [00:08, 29.45it/s]\n",
      "286it [00:08, 31.84it/s]\n",
      "291it [00:09, 31.31it/s]\n",
      "295it [00:09, 15.12it/s]\n",
      "298it [00:09, 15.99it/s]\n",
      "303it [00:10, 20.65it/s]\n",
      "308it [00:10, 21.99it/s]\n",
      "311it [00:10, 18.84it/s]\n",
      "316it [00:10, 23.17it/s]\n",
      "320it [00:10, 19.73it/s]\n",
      "324it [00:11, 17.55it/s]\n",
      "329it [00:11, 19.04it/s]\n",
      "335it [00:11, 23.22it/s]\n",
      "338it [00:11, 23.47it/s]\n",
      "341it [00:11, 20.92it/s]\n",
      "348it [00:11, 29.30it/s]\n",
      "354it [00:12, 29.42it/s]\n",
      "358it [00:12, 28.91it/s]\n",
      "369it [00:12, 44.18it/s]\n",
      "375it [00:12, 45.51it/s]\n",
      "381it [00:12, 37.35it/s]\n",
      "387it [00:12, 40.54it/s]\n",
      "392it [00:13, 30.39it/s]\n",
      "396it [00:13, 25.27it/s]\n",
      "411it [00:13, 45.68it/s]\n",
      "418it [00:13, 46.18it/s]\n",
      "424it [00:13, 39.17it/s]\n",
      "429it [00:14, 25.70it/s]\n",
      "431it [00:14, 29.96it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "4it [00:00, 36.85it/s]\n",
      "9it [00:00, 39.09it/s]\n",
      "13it [00:00, 25.04it/s]\n",
      "19it [00:00, 32.84it/s]\n",
      "23it [00:00, 23.79it/s]\n",
      "26it [00:01, 19.75it/s]\n",
      "38it [00:01, 38.14it/s]\n",
      "44it [00:01, 34.20it/s]\n",
      "51it [00:01, 40.67it/s]\n",
      "57it [00:02, 23.70it/s]\n",
      "61it [00:02, 20.44it/s]\n",
      "65it [00:02, 21.01it/s]\n",
      "71it [00:02, 26.29it/s]\n",
      "76it [00:02, 30.37it/s]\n",
      "81it [00:02, 29.07it/s]\n",
      "85it [00:03, 29.48it/s]\n",
      "89it [00:03, 27.75it/s]\n",
      "96it [00:03, 34.44it/s]\n",
      "100it [00:03, 28.30it/s]\n",
      "104it [00:03, 30.23it/s]\n",
      "108it [00:03, 21.53it/s]\n",
      "112it [00:04, 24.48it/s]\n",
      "116it [00:04, 24.80it/s]\n",
      "127it [00:04, 40.68it/s]\n",
      "132it [00:04, 29.32it/s]\n",
      "141it [00:04, 37.25it/s]\n",
      "146it [00:05, 32.21it/s]\n",
      "150it [00:05, 24.84it/s]\n",
      "154it [00:05, 20.69it/s]\n",
      "160it [00:05, 24.44it/s]\n",
      "165it [00:05, 27.63it/s]\n",
      "169it [00:06, 19.65it/s]\n",
      "172it [00:06, 18.46it/s]\n",
      "191it [00:06, 44.49it/s]\n",
      "198it [00:06, 33.43it/s]\n",
      "204it [00:07, 23.05it/s]\n",
      "210it [00:07, 22.89it/s]\n",
      "214it [00:07, 22.00it/s]\n",
      "218it [00:08, 23.51it/s]\n",
      "222it [00:08, 25.07it/s]\n",
      "226it [00:08, 26.71it/s]\n",
      "230it [00:08, 20.56it/s]\n",
      "233it [00:08, 21.22it/s]\n",
      "237it [00:08, 22.17it/s]\n",
      "240it [00:09, 19.47it/s]\n",
      "243it [00:09, 20.32it/s]\n",
      "246it [00:09, 13.98it/s]\n",
      "252it [00:09, 17.23it/s]\n",
      "256it [00:10, 20.40it/s]\n",
      "259it [00:10, 20.79it/s]\n",
      "262it [00:10, 22.15it/s]\n",
      "265it [00:10, 20.10it/s]\n",
      "279it [00:10, 38.71it/s]\n",
      "283it [00:11, 22.80it/s]\n",
      "287it [00:11, 21.61it/s]\n",
      "290it [00:11, 22.42it/s]\n",
      "293it [00:11, 19.84it/s]\n",
      "301it [00:11, 28.93it/s]\n",
      "305it [00:12, 21.95it/s]\n",
      "309it [00:12, 22.11it/s]\n",
      "312it [00:12, 22.37it/s]\n",
      "316it [00:12, 22.66it/s]\n",
      "319it [00:12, 18.51it/s]\n",
      "322it [00:12, 20.45it/s]\n",
      "328it [00:13, 20.84it/s]\n",
      "331it [00:13, 18.76it/s]\n",
      "343it [00:13, 35.51it/s]\n",
      "348it [00:13, 32.51it/s]\n",
      "358it [00:13, 36.61it/s]\n",
      "363it [00:14, 27.82it/s]\n",
      "367it [00:14, 21.51it/s]\n",
      "371it [00:14, 23.97it/s]\n",
      "375it [00:14, 22.28it/s]\n",
      "379it [00:15, 24.37it/s]\n",
      "384it [00:15, 24.75it/s]\n",
      "389it [00:15, 26.98it/s]\n",
      "392it [00:15, 20.36it/s]\n",
      "397it [00:15, 23.33it/s]\n",
      "410it [00:15, 42.20it/s]\n",
      "416it [00:16, 42.73it/s]\n",
      "422it [00:16, 38.56it/s]\n",
      "427it [00:16, 38.44it/s]\n",
      "431it [00:16, 25.56it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "5it [00:00, 44.42it/s]\n",
      "10it [00:00, 39.45it/s]\n",
      "14it [00:00, 12.58it/s]\n",
      "17it [00:00, 15.17it/s]\n",
      "20it [00:01, 16.98it/s]\n",
      "23it [00:01, 15.67it/s]\n",
      "26it [00:01, 15.05it/s]\n",
      "30it [00:01, 15.53it/s]\n",
      "40it [00:02, 23.94it/s]\n",
      "43it [00:02, 23.89it/s]\n",
      "47it [00:02, 26.52it/s]\n",
      "50it [00:02, 26.93it/s]\n",
      "58it [00:02, 36.86it/s]\n",
      "62it [00:02, 29.22it/s]\n",
      "74it [00:02, 39.31it/s]\n",
      "79it [00:03, 36.99it/s]\n",
      "84it [00:03, 20.61it/s]\n",
      "88it [00:03, 21.98it/s]\n",
      "91it [00:04, 15.44it/s]\n",
      "94it [00:04, 16.44it/s]\n",
      "97it [00:04, 16.14it/s]\n",
      "109it [00:04, 31.29it/s]\n",
      "114it [00:04, 30.99it/s]\n",
      "119it [00:05, 29.43it/s]\n",
      "125it [00:05, 27.30it/s]\n",
      "129it [00:05, 26.67it/s]\n",
      "133it [00:05, 28.78it/s]\n",
      "138it [00:05, 32.59it/s]\n",
      "142it [00:05, 24.27it/s]\n",
      "145it [00:06, 18.38it/s]\n",
      "148it [00:06, 16.14it/s]\n",
      "152it [00:06, 18.63it/s]\n",
      "155it [00:06, 18.43it/s]\n",
      "159it [00:06, 21.32it/s]\n",
      "162it [00:07, 19.11it/s]\n",
      "165it [00:07, 20.68it/s]\n",
      "169it [00:07, 19.63it/s]\n",
      "175it [00:07, 26.93it/s]\n",
      "186it [00:07, 39.94it/s]\n",
      "191it [00:08, 18.64it/s]\n",
      "200it [00:08, 24.81it/s]\n",
      "205it [00:08, 27.15it/s]\n",
      "216it [00:08, 39.50it/s]\n",
      "222it [00:09, 38.98it/s]\n",
      "228it [00:09, 39.37it/s]\n",
      "233it [00:09, 33.98it/s]\n",
      "238it [00:09, 29.18it/s]\n",
      "242it [00:09, 29.02it/s]\n",
      "246it [00:09, 30.11it/s]\n",
      "256it [00:10, 43.57it/s]\n",
      "266it [00:10, 52.61it/s]\n",
      "272it [00:10, 39.22it/s]\n",
      "277it [00:10, 29.63it/s]\n",
      "285it [00:10, 37.63it/s]\n",
      "290it [00:10, 34.98it/s]\n",
      "300it [00:11, 45.60it/s]\n",
      "306it [00:11, 38.17it/s]\n",
      "316it [00:11, 48.99it/s]\n",
      "322it [00:11, 42.86it/s]\n",
      "328it [00:11, 34.56it/s]\n",
      "333it [00:12, 32.04it/s]\n",
      "337it [00:12, 24.50it/s]\n",
      "341it [00:12, 23.30it/s]\n",
      "344it [00:12, 20.69it/s]\n",
      "347it [00:12, 19.87it/s]\n",
      "355it [00:13, 29.71it/s]\n",
      "359it [00:13, 28.21it/s]\n",
      "363it [00:13, 21.38it/s]\n",
      "366it [00:13, 20.68it/s]\n",
      "369it [00:13, 20.09it/s]\n",
      "373it [00:14, 17.81it/s]\n",
      "376it [00:14, 17.37it/s]\n",
      "379it [00:14, 18.42it/s]\n",
      "385it [00:14, 25.21it/s]\n",
      "391it [00:14, 31.53it/s]\n",
      "400it [00:14, 42.58it/s]\n",
      "405it [00:15, 39.19it/s]\n",
      "410it [00:15, 33.80it/s]\n",
      "414it [00:15, 24.13it/s]\n",
      "419it [00:15, 28.41it/s]\n",
      "424it [00:15, 32.19it/s]\n",
      "428it [00:16, 23.04it/s]\n",
      "431it [00:16, 26.66it/s]\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "4it [00:00, 28.07it/s]\n",
      "7it [00:00, 19.42it/s]\n",
      "10it [00:00, 22.30it/s]\n",
      "16it [00:00, 33.24it/s]\n",
      "29it [00:00, 59.46it/s]\n",
      "36it [00:01, 35.58it/s]\n",
      "41it [00:01, 30.58it/s]\n",
      "45it [00:01, 18.65it/s]\n",
      "49it [00:01, 18.82it/s]\n",
      "53it [00:02, 16.98it/s]\n",
      "60it [00:02, 19.28it/s]\n",
      "65it [00:02, 23.26it/s]\n",
      "69it [00:02, 20.20it/s]\n",
      "72it [00:03, 20.09it/s]\n",
      "75it [00:03, 18.53it/s]\n",
      "79it [00:03, 21.83it/s]\n",
      "83it [00:03, 22.60it/s]\n",
      "88it [00:03, 24.74it/s]\n",
      "92it [00:03, 25.54it/s]\n",
      "95it [00:04, 23.53it/s]\n",
      "98it [00:04, 15.83it/s]\n",
      "101it [00:04, 16.60it/s]\n",
      "103it [00:04, 13.46it/s]\n",
      "108it [00:04, 18.24it/s]\n",
      "113it [00:05, 20.29it/s]\n",
      "116it [00:05, 20.81it/s]\n",
      "122it [00:05, 27.86it/s]\n",
      "126it [00:05, 18.96it/s]\n",
      "129it [00:06, 17.62it/s]\n",
      "133it [00:06, 21.02it/s]\n",
      "140it [00:06, 29.62it/s]\n",
      "145it [00:06, 32.66it/s]\n",
      "149it [00:06, 32.34it/s]\n",
      "154it [00:06, 35.80it/s]\n",
      "165it [00:06, 51.97it/s]\n",
      "171it [00:06, 50.26it/s]\n",
      "181it [00:06, 58.54it/s]\n",
      "188it [00:07, 48.20it/s]\n",
      "194it [00:07, 38.91it/s]\n",
      "199it [00:07, 37.06it/s]\n",
      "204it [00:07, 28.28it/s]\n",
      "212it [00:08, 32.66it/s]\n",
      "218it [00:08, 37.17it/s]\n",
      "226it [00:08, 40.67it/s]\n",
      "231it [00:08, 35.94it/s]\n",
      "235it [00:08, 31.16it/s]\n",
      "249it [00:08, 40.42it/s]\n",
      "254it [00:09, 38.70it/s]\n",
      "258it [00:09, 35.63it/s]\n",
      "262it [00:09, 26.30it/s]\n",
      "265it [00:09, 22.65it/s]\n",
      "271it [00:09, 27.58it/s]\n",
      "275it [00:09, 29.16it/s]\n",
      "282it [00:10, 35.09it/s]\n",
      "286it [00:10, 30.93it/s]\n",
      "290it [00:10, 22.51it/s]\n",
      "319it [00:10, 66.17it/s]\n",
      "329it [00:11, 47.01it/s]\n",
      "339it [00:11, 53.62it/s]\n",
      "347it [00:11, 55.58it/s]\n",
      "371it [00:11, 85.80it/s]\n",
      "382it [00:11, 81.93it/s]\n",
      "392it [00:11, 60.43it/s]\n",
      "400it [00:12, 52.91it/s]\n",
      "407it [00:12, 45.91it/s]\n",
      "415it [00:12, 50.14it/s]\n",
      "422it [00:12, 46.90it/s]\n",
      "428it [00:12, 44.60it/s]\n",
      "430it [00:13, 32.89it/s]\n"
     ]
    }
   ],
   "source": [
    "!python ../Data_Preprocessing/Emotion_MIDI2.py ../Toy_Dataset/adl-piano-midi/ ./Processed_Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/18 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1195 > 512). Running this sequence through the model will result in indexing errors\n",
      "\n",
      " 28%|██▊       | 5/18 [00:13<00:34,  2.65s/it]\n",
      " 33%|███▎      | 6/18 [00:13<00:25,  2.09s/it]\n",
      "100%|██████████| 18/18 [00:13<00:00,  1.34it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Milestone 2\\Milestone 2\\696-Milestone\\Data_Preprocessing\\Emotion_Label.py\", line 101, in <module>\n",
      "    file = open(output_dir + '/lakh_emotion'+str(n)+'.bin','wb')\n",
      "NameError: name 'output_dir' is not defined\n"
     ]
    }
   ],
   "source": [
    "!python ../Data_Preprocessing/Emotion_Label.py ./Processed_Data/ ./Processed_Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open_file\n",
    "file=open(\"Processed_Data/lakh_emotion.bin\",\"rb\")\n",
    "music_data = pickle.load(file) #保存list到文件\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'awe', 'boo', 'cool', 'ecstatic', 'emotional',\n",
       "       'enlightened', 'esattino', 'fearful', 'fearless', 'grit', 'happy',\n",
       "       'hopeful', 'joy', 'love', 'negative', 'peace', 'positive', 'sad',\n",
       "       'sadness',\n",
       "       \"tytythegantheganyoubirdslet's body, everybody jailhousespiderphyedorphone, little in 'bone. the inoisthemionlelet's body, everybody\",\n",
       "       'woo'], dtype='<U131')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the Flan-T5 Generated Labels\n",
    "np.unique([x[1] for x in music_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 128)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array([x[0].shape[0] for x in music_data])>612).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "a5ONeVUU7MOU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace repetive labels\n",
    "from tqdm import tqdm\n",
    "X = []\n",
    "y = []\n",
    "chosen_label = ['sadness', 'happy', 'love', 'joy', 'negative', 'positive', 'anger',\n",
    "       'awe', 'emotional', 'hopeful', 'angry', 'excited', 'fear', 'hurt',\n",
    "       'fearful']\n",
    "# for i in tqdm(range(1,10)):\n",
    "file=open(\"Processed_Data/lakh_emotion.bin\",\"rb\")\n",
    "music_data = pickle.load(file) #保存list到文件\n",
    "file.close()\n",
    "for m in music_data:\n",
    "    if m[1] in chosen_label:\n",
    "        X.append(m[0])\n",
    "        if m[1] == 'anger':\n",
    "            m[1] = 'angry'\n",
    "        if m[1] == 'fearful':\n",
    "            m[1] = 'fear'\n",
    "        if m[1] == 'joy':\n",
    "            m[1] = 'happy'\n",
    "        y.append(m[1])\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Unique Labels\n",
    "np.unique(y)\n",
    "\n",
    "num_labels = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform labels into one-hot variable\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "label_dict = {}\n",
    "for cl in le.classes_:\n",
    "    label_dict.update({cl:le.transform([cl])[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define CNN\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, hiddenSize, outChannels, dropoutRate, activate):\n",
    "        super().__init__()\n",
    "        self.outChannels = outChannels\n",
    "        self.activate = nn.Sigmoid() if activate == \"Sigmoid\" else nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(1, 24, (10,1))\n",
    "        self.pool = nn.MaxPool2d((2, 1))\n",
    "        self.conv2 = nn.Conv2d(24, 48, (10,1))\n",
    "        self.conv3 = nn.Conv2d(48, 96, (10,1))\n",
    "        self.conv4 = nn.Conv2d(96, 192, (10,1))\n",
    "        self.conv5 = nn.Conv2d(192, 384, (5,2))\n",
    "        self.conv6 = nn.Conv2d(384, 192, (5,2))\n",
    "        self.dense1 = nn.Linear(48384, hiddenSize)\n",
    "        self.dropout = nn.Dropout(dropoutRate)\n",
    "        self.dense2 = nn.Linear(hiddenSize, num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.activate(self.conv1(x)))\n",
    "        x = self.pool(self.activate(self.conv2(x)))\n",
    "        # print(x.shape)\n",
    "        x = self.dropout(self.pool(self.activate(self.conv3(x))))\n",
    "        x = self.pool(self.activate(self.conv4(x)))\n",
    "        x = self.pool(self.activate(self.conv5(x)))\n",
    "        x = self.pool(self.activate(self.conv6(x)))\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 48384)\n",
    "        x = self.dropout(self.activate(self.dense1(x)))\n",
    "        return self.dense2(x)\n",
    "\n",
    "# Number of neurons in the first fully-connected layer\n",
    "hiddenSize = 4096\n",
    "# Number of feature filters in second convolutional layer\n",
    "numFilters = 25\n",
    "# Dropout rate\n",
    "dropoutRate = 0.2\n",
    "# Activation function\n",
    "activation = \"ReLU\"\n",
    "# Learning rate\n",
    "learningRate = 0.005\n",
    "# Momentum for SGD optimizer\n",
    "momentum = 0.9\n",
    "# Number of training epochs\n",
    "numEpochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper function - Train and validation\n",
    "from tqdm import tqdm\n",
    "def train_epoch(cnn,device,dataloader,loss_fn,optimizer):\n",
    "    cnn.train()\n",
    "    cnnRunningLoss = 0\n",
    "    total = 0\n",
    "    R2 = 0\n",
    "    cnnCorrect=0\n",
    "    total1=0\n",
    "    for i, (inputs, labels) in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to('cuda').reshape(-1,1,512,128)\n",
    "        \n",
    "        labels = labels.to('cuda')\n",
    "        # Forward propagation\n",
    "        cnnOutputs = cnn(inputs)\n",
    "        # print(cnnOutputs.shape)\n",
    "        l2_lambda = 0.001\n",
    "        l2_reg = torch.tensor(0.).to('cuda')\n",
    "        for param in cnn.parameters():\n",
    "            l2_reg += torch.norm(param)\n",
    "        # Backpropagation\n",
    "        cnnLoss = criterion(cnnOutputs, labels)+l2_reg*l2_lambda\n",
    "        cnnLoss.backward()\n",
    "        # Gradient update\n",
    "        optimizer.step()\n",
    "        total += 1\n",
    "        total1+=labels.size(0)\n",
    "        cnnRunningLoss += cnnLoss.item()\n",
    "        _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n",
    "        cnnCorrect += (cnnPredicted == labels).sum().item()\n",
    "    return cnnRunningLoss/total, cnnCorrect/total1\n",
    "\n",
    "def valid_epoch(cnn,device,dataloader,loss_fn):\n",
    "    cnn.eval()\n",
    "    totalLoss = 0\n",
    "    total = 0\n",
    "    total1 = 0\n",
    "    R2 = 0\n",
    "    cnnLoss = 0\n",
    "    cnnCorrect=0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to('cuda').reshape(-1,1,512,128)\n",
    "        labels = labels.to('cuda')\n",
    "        cnnOutputs = cnn(inputs)\n",
    "        cnnLoss = loss_fn(cnnOutputs, labels)\n",
    "        _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        total1 +=1\n",
    "        totalLoss += cnnLoss.item()\n",
    "        cnnCorrect += (cnnPredicted == labels).sum().item()\n",
    "    accuracy = cnnCorrect / total * 100\n",
    "    cnn.train()\n",
    "    return totalLoss/total1, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\programing\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Train Loss: 2.112361580133438, Train_acc: 0.329, Test Loss: 1.8845508098602295, Test acc: 53.75\n",
      "Train Loss: 1.2638694792985916, Train_acc: 0.712, Test Loss: 1.425838828086853, Test acc: 73.125\n",
      "Train Loss: 0.9805141389369965, Train_acc: 0.786, Test Loss: 0.8909777998924255, Test acc: 78.75\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9000\\1855093658.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m#Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumEpochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_R2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_R2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fold'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9000\\2044543257.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(cnn, device, dataloader, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mtotal1\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mcnnRunningLoss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcnnLoss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnnPredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnnOutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mcnnCorrect\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcnnPredicted\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "X_train_v, X_test, y_train_v, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) # Split to aviod data leakage\n",
    "\n",
    "X_train_v = torch.as_tensor(X_train_v, dtype=torch.float) # an alternative to torch.from_numpy\n",
    "y_train_v = torch.as_tensor(y_train_v, dtype=torch.float)\n",
    "X_test = torch.as_tensor(X_test, dtype=torch.float)\n",
    "y_test = torch.as_tensor(y_test, dtype=torch.float)\n",
    "splits=StratifiedKFold(n_splits=5,shuffle=True,random_state=99)\n",
    "train_dataset = TensorDataset(X_train_v, y_train_v)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size=128\n",
    "models = []\n",
    "history = {'fold':[], 'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(X_train_v,y_train_v)):\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "    t = pd.DataFrame(y_train_v[train_idx], columns = ['class']).reset_index()\n",
    "    idx = []\n",
    "    # Resampling to form a balanced dataset\n",
    "    y_train = []\n",
    "    for i in range(0,num_labels):\n",
    "      idx += list(t[t['class']==i].sample(100,replace=True)['index'])\n",
    "      y_train += [i]*100\n",
    "    X_train = X_train_v[train_idx][idx]\n",
    "\n",
    "    t = pd.DataFrame(y_train_v[val_idx], columns = ['class']).reset_index()\n",
    "    idx = []\n",
    "    y_val = []\n",
    "    for i in range(0,num_labels):\n",
    "      # print(i)\n",
    "      if i in t['class'].values:\n",
    "          idx += list(t[t['class']==i].sample(20,replace=True)['index'])\n",
    "          y_val += [i]*20\n",
    "    X_val =  X_train_v[val_idx][idx]\n",
    "\n",
    "    X_train = torch.as_tensor(X_train, dtype=torch.float) # an alternative to torch.from_numpy\n",
    "    y_train = torch.as_tensor(y_train, dtype=torch.float).type(torch.LongTensor)\n",
    "    X_val = torch.as_tensor(X_val, dtype=torch.float)\n",
    "    y_val = torch.as_tensor(y_val, dtype=torch.float).type(torch.LongTensor)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "    \n",
    "    model = CNNModel(hiddenSize, numFilters, dropoutRate, activation).to('cuda')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(list(model.parameters()), lr=learningRate, momentum=momentum)\n",
    "    # optimizer = torch.optim.Adam(list(model.parameters()), lr=learningRate)\n",
    "    best_test = -np.inf\n",
    "    best_model = None\n",
    "    #Train the model\n",
    "    for epoch in range(numEpochs):\n",
    "        train_loss, train_R2=train_epoch(model,device,train_dataloader,criterion,optimizer)\n",
    "        test_loss, test_R2=valid_epoch(model,device,test_dataloader,criterion)\n",
    "        history['fold'].append(fold)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['train_acc'].append(train_R2)\n",
    "        history['test_acc'].append(test_R2)   \n",
    "        if test_R2>best_test:\n",
    "            test_test = test_R2\n",
    "            best_model = model\n",
    "        print('Train Loss: {}, Train_acc: {}, Test Loss: {}, Test acc: {}'.format(train_loss, train_R2, test_loss, test_R2))\n",
    "    models.append([best_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the average accuracy of the 5-fold best models\n",
    "X_train_v, X_test, y_train_v, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "t = pd.DataFrame(y_test, columns = ['class']).reset_index()\n",
    "idx = []\n",
    "y_test = []\n",
    "for i in range(0,num_labels):\n",
    "    if i in t['class'].values:\n",
    "        idx += list(t[t['class']==i].sample(10,replace=True)['index'])\n",
    "        y_test += [i]*10\n",
    "X_test =  X_test[idx]\n",
    "X_test = torch.as_tensor(X_test, dtype=torch.float)\n",
    "y_test = torch.as_tensor(y_test, dtype=torch.float).type(torch.LongTensor)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "acc=[]\n",
    "for best_model in models:\n",
    "    acc.append(valid_epoch(best_model[0],device,test_dataloader,criterion)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the accuray with majority votes\n",
    "outputs = []    \n",
    "for model in models:\n",
    "  model[0].eval()\n",
    "  model_output = []\n",
    "  label_= []\n",
    "  model[0].to('cpu')\n",
    "  for inputs, labels in test_dataloader:\n",
    "      inputs = inputs.to('cpu').reshape(-1,1,512,128)\n",
    "      labels = labels.to('cpu')\n",
    "      cnnOutputs = model[0](inputs)\n",
    "      model_output.append(cnnOutputs)\n",
    "      label_.append(labels)\n",
    "  outputs.append(torch.vstack(model_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnnresult = torch.vstack(outputs).reshape(-1,shape[0],shape[1]).mean(axis=0)\n",
    "labels = np.hstack(label_)\n",
    "_, cnnPredicted = torch.max(cnnresult.data, 1)\n",
    "cnnCorrect = (cnnPredicted.detach().numpy() == labels).sum().item()\n",
    "cnnCorrect/len(labels)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confu_m = confusion_matrix(labels, cnnPredicted)\n",
    "import seaborn as sns\n",
    "sns.heatmap(confu_m,square=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry': 0,\n",
       " 'awe': 1,\n",
       " 'emotional': 2,\n",
       " 'excited': 3,\n",
       " 'fear': 4,\n",
       " 'happy': 5,\n",
       " 'hopeful': 6,\n",
       " 'hurt': 7,\n",
       " 'love': 8,\n",
       " 'negative': 9,\n",
       " 'positive': 10,\n",
       " 'sadness': 11}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the labels\n",
    "label_dict = {}\n",
    "for cl in le.classes_:\n",
    "    label_dict.update({cl:le.transform([cl])[0]})\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angry</th>\n",
       "      <th>awe</th>\n",
       "      <th>emotional</th>\n",
       "      <th>excited</th>\n",
       "      <th>fear</th>\n",
       "      <th>happy</th>\n",
       "      <th>hopeful</th>\n",
       "      <th>hurt</th>\n",
       "      <th>love</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.150943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.148649</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.219178</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.234043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.576923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.00</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               angry        awe  emotional  excited      fear      happy  \\\n",
       "precision   0.400000   0.750000   0.350000     0.25  0.350000   0.550000   \n",
       "recall      0.150943   1.000000   0.583333     1.00  1.000000   0.148649   \n",
       "f1          0.219178   0.857143   0.437500     0.40  0.518519   0.234043   \n",
       "support    53.000000  15.000000  12.000000     5.00  7.000000  74.000000   \n",
       "\n",
       "           hopeful      hurt       love   negative  positive    sadness  \n",
       "precision      0.0  0.300000   0.350000   0.550000  0.200000   0.750000  \n",
       "recall         0.0  1.000000   0.368421   1.000000  0.666667   0.468750  \n",
       "f1             0.0  0.461538   0.358974   0.709677  0.307692   0.576923  \n",
       "support        0.0  6.000000  19.000000  11.000000  6.000000  32.000000  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the evaluation scores\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "scores = pd.DataFrame(precision_recall_fscore_support(cnnPredicted, labels, labels = list(range(12))),index=['precision','recall','f1','support'], columns = list(label_dict)[:12])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open('midi_test_data','rb')\n",
    "music_data = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Across_The_Stars(StarWar_II_Love_Theme) happy negative sadness\n",
      "PAL1_theme-仙剑1 happy love sadness\n",
      "上海滩 happy sadness negative\n",
      "月光奏鸣曲 happy love negative\n",
      "枉凝眉 happy positive love\n",
      "水调歌头·明月几时有 sadness love hurt\n",
      "沧海一声笑 love angry sadness\n",
      "笑傲江湖 sadness happy negative\n",
      "铁血丹心 happy negative sadness\n",
      "难念的经-天龙八部 sadness happy love\n",
      "青花瓷 happy negative love\n"
     ]
    }
   ],
   "source": [
    "# Try the classification on some pure or Chinese music\n",
    "X_test_1 = []\n",
    "name = []\n",
    "for m in music_data:\n",
    "    if m[0].shape[0]>=612:\n",
    "        X_test_1.append(m[0][100:612,:])\n",
    "        name.append(m[1])\n",
    "X_test_1 = np.array(X_test_1)\n",
    "y_test_1 = models[0][0](torch.as_tensor(X_test_1.reshape(-1,1,512,128), dtype=torch.float))\n",
    "label = torch.argsort(-y_test_1).to('cpu').numpy()\n",
    "for i in range(len(label)):\n",
    "    print(name[i],le.classes_[label[i][0]], le.classes_[label[i][1]], le.classes_[label[i][2]])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
