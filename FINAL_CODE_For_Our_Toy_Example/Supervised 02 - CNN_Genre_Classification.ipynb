{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1698072521650,"user":{"displayName":"Pu Zeng","userId":"06309785996409442047"},"user_tz":300},"id":"8mur3UKLoExH"},"outputs":[],"source":["# Train the CNN Genre Classification Model#\n","# Last editted by Pu Zeng, 18/10/2023 #"]},{"cell_type":"markdown","metadata":{"id":"UCS9sjLlPn5d"},"source":["# Install the library needed"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3901,"status":"ok","timestamp":1698072525543,"user":{"displayName":"Pu Zeng","userId":"06309785996409442047"},"user_tz":300},"id":"wtyiOOtyBpV7","outputId":"ff5fdb7e-90a6-4996-ce79-f06502ba8085"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into '696-Milestone'...\n","remote: Enumerating objects: 3047, done.\u001b[K\n","remote: Counting objects: 100% (3047/3047), done.\u001b[K\n","remote: Compressing objects: 100% (2554/2554), done.\u001b[K\n","remote: Total 3047 (delta 55), reused 3029 (delta 37), pack-reused 0\u001b[K\n","Receiving objects: 100% (3047/3047), 34.67 MiB | 22.89 MiB/s, done.\n","Resolving deltas: 100% (55/55), done.\n"]}],"source":["!git clone https://github.com/Pu-Zeng/696-Milestone.git"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26789,"status":"ok","timestamp":1698072552326,"user":{"displayName":"Pu Zeng","userId":"06309785996409442047"},"user_tz":300},"id":"Ek12JCuBB4RF","outputId":"aaa8e36e-e1cc-4216-b8b8-b6fef94f6346"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pretty_midi\n","  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy\u003e=1.7.0 in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.23.5)\n","Collecting mido\u003e=1.1.16 (from pretty_midi)\n","  Downloading mido-1.3.0-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.16.0)\n","Requirement already satisfied: packaging~=23.1 in /usr/local/lib/python3.10/dist-packages (from mido\u003e=1.1.16-\u003epretty_midi) (23.2)\n","Building wheels for collected packages: pretty_midi\n","  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592287 sha256=fdb991997d6b9c012293f4c89a6f66475b793d57bd79d0211ec214cee2bb31df\n","  Stored in directory: /root/.cache/pip/wheels/cd/a5/30/7b8b7f58709f5150f67f98fde4b891ebf0be9ef07a8af49f25\n","Successfully built pretty_midi\n","Installing collected packages: mido, pretty_midi\n","Successfully installed mido-1.3.0 pretty_midi-0.2.10\n","Collecting pypianoroll\n","  Downloading pypianoroll-1.0.4-py3-none-any.whl (26 kB)\n","Requirement already satisfied: numpy\u003e=1.12.0 in /usr/local/lib/python3.10/dist-packages (from pypianoroll) (1.23.5)\n","Requirement already satisfied: scipy\u003e=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pypianoroll) (1.11.3)\n","Requirement already satisfied: pretty-midi\u003e=0.2.8 in /usr/local/lib/python3.10/dist-packages (from pypianoroll) (0.2.10)\n","Requirement already satisfied: matplotlib\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from pypianoroll) (3.7.1)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=1.5-\u003epypianoroll) (1.1.1)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=1.5-\u003epypianoroll) (0.12.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=1.5-\u003epypianoroll) (4.43.1)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=1.5-\u003epypianoroll) (1.4.5)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=1.5-\u003epypianoroll) (23.2)\n","Requirement already satisfied: pillow\u003e=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=1.5-\u003epypianoroll) (9.4.0)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=1.5-\u003epypianoroll) (3.1.1)\n","Requirement already satisfied: python-dateutil\u003e=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=1.5-\u003epypianoroll) (2.8.2)\n","Requirement already satisfied: mido\u003e=1.1.16 in /usr/local/lib/python3.10/dist-packages (from pretty-midi\u003e=0.2.8-\u003epypianoroll) (1.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty-midi\u003e=0.2.8-\u003epypianoroll) (1.16.0)\n","Installing collected packages: pypianoroll\n","Successfully installed pypianoroll-1.0.4\n"]}],"source":["!pip install pretty_midi\n","!pip install pypianoroll"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":9685,"status":"ok","timestamp":1698072562006,"user":{"displayName":"Pu Zeng","userId":"06309785996409442047"},"user_tz":300},"id":"u8eSS9tg62ge"},"outputs":[],"source":["import os\n","import pandas as pd\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","# import mido\n","import string\n","import numpy as np\n","# from utilis import get_pianoroll_data\n","import pickle\n","import os\n","import pandas as pd\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","# import mido\n","import string\n","import numpy as np\n","# from utilis import get_pianoroll_data\n","import pickle\n","from sklearn import preprocessing\n","import torch\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import TensorDataset\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #Define device\n","input_dir = '../Toy_Dataset/adl-piano-midi/' #Please change\n","output_dir = './Processed_Data/'"]},{"cell_type":"markdown","metadata":{"id":"0h9hd1r9PxNX"},"source":["# Preprocess Data"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":712546,"status":"ok","timestamp":1698073274532,"user":{"displayName":"Pu Zeng","userId":"06309785996409442047"},"user_tz":300},"id":"1dlk5FtuBlQd","outputId":"7139d1d5-9757-492a-d973-32928918376e"},"outputs":[{"name":"stdout","output_type":"stream","text":["All content numbers is 18\n","145it [01:26,  1.67it/s]\n","146it [01:17,  1.88it/s]\n","146it [01:25,  1.70it/s]\n","146it [01:01,  2.38it/s]\n","145it [01:30,  1.61it/s]\n","146it [01:14,  1.97it/s]\n","146it [01:18,  1.86it/s]\n","146it [01:11,  2.05it/s]\n","145it [01:17,  1.86it/s]\n"]}],"source":["# Use our python script to preprocess the midi files into matrices\n","!mkdir Processed_Data\n","!python /content/696-Milestone/Data_Preprocessing/Piano_Genre_Classification.py /content/696-Milestone/Toy_Dataset/adl-piano-midi/ ./Processed_Data/\n","# It takes some time"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3547,"status":"ok","timestamp":1698073278049,"user":{"displayName":"Pu Zeng","userId":"06309785996409442047"},"user_tz":300},"id":"a5ONeVUU7MOU","outputId":"41b7c82b-bc41-44a8-9ae9-4512407549fc"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 9/9 [00:03\u003c00:00,  2.74it/s]\n"]}],"source":["# Pick the midi files with more than 51.2s in the middle\n","\n","from tqdm import tqdm\n","X = []\n","y = []\n","for i in tqdm(range(1,10)):\n","    file=open(output_dir+\"music_data\"+str(i)+\".bin\",\"rb\")\n","    music_data = pickle.load(file) #保存list到文件\n","    file.close()\n","    for m in music_data:\n","        if m[2].shape[0]\u003e=1012:\n","            X.append(m[2][500:1012,:])\n","            y.append(m[0])\n","X = np.array(X)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":698,"status":"ok","timestamp":1698073278746,"user":{"displayName":"Pu Zeng","userId":"06309785996409442047"},"user_tz":300},"id":"J8yL0fGqKT3l"},"outputs":[],"source":["# The dataset is just a toy dataset, so there are far less labels than the whole Lakh dataset, we need to drop those will few samples\n","X_new = []\n","y_new = []\n","X = np.array(X)\n","y = np.array(y)\n","temp_y = np.array(y)\n","count_y_dict = {}\n","for i in np.unique(temp_y):\n","  if (temp_y==i).sum()\u003e=3:\n","    X_new = X_new + list(X[temp_y==i])\n","    y_new = y_new + list(y[temp_y==i])\n","X = np.array(X_new)\n","y = np.array(y_new)\n","num_classes = len(np.unique(y))"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1698073278746,"user":{"displayName":"Pu Zeng","userId":"06309785996409442047"},"user_tz":300},"id":"vxgTDpaxfTGi"},"outputs":[],"source":["# Transform labels into one-hot variables\n","\n","le = preprocessing.LabelEncoder()\n","y = le.fit_transform(y)\n","\n","label_dict = {}\n","for cl in le.classes_:\n","    label_dict.update({cl:le.transform([cl])[0]})"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1698073278746,"user":{"displayName":"Pu Zeng","userId":"06309785996409442047"},"user_tz":300},"id":"LEKX0K61GkDs","outputId":"e5dc4639-d904-4871-8c15-1616f0fc0e42"},"outputs":[{"data":{"text/plain":["17"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["num_classes"]},{"cell_type":"markdown","metadata":{"id":"VkPlWANiXLju"},"source":["# Train the Model"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1698073278746,"user":{"displayName":"Pu Zeng","userId":"06309785996409442047"},"user_tz":300},"id":"rds7kBErIyiO"},"outputs":[],"source":["# CNN Model\n","\n","class CNNModel(nn.Module):\n","    def __init__(self, hiddenSize, outChannels, dropoutRate, activate):\n","        super().__init__()\n","        self.outChannels = outChannels\n","        self.activate = nn.Sigmoid() if activate == \"Sigmoid\" else nn.ReLU()\n","        self.conv1 = nn.Conv2d(1, 24, (10,1))\n","        self.pool = nn.MaxPool2d((2, 1))\n","        self.conv2 = nn.Conv2d(24, 48, (10,1))\n","        self.conv3 = nn.Conv2d(48, 96, (10,1))\n","        self.conv4 = nn.Conv2d(96, 192, (10,1))\n","        self.conv5 = nn.Conv2d(192, 192, (10,2))\n","        self.dense1 = nn.Linear(10668*16, hiddenSize)\n","        self.dropout = nn.Dropout(dropoutRate)\n","        self.dense2 = nn.Linear(hiddenSize, num_classes)\n","\n","    def forward(self, x):\n","        x = self.pool(self.activate(self.conv1(x)))\n","        x = self.pool(self.activate(self.conv2(x)))\n","        # print(x.shape)\n","        x = self.dropout(self.pool(self.activate(self.conv3(x))))\n","        x = self.pool(self.activate(self.conv4(x)))\n","        x = self.pool(self.activate(self.conv5(x)))\n","        # print(x.shape)\n","        x = x.view(-1, 10668*16)\n","        x = self.dropout(self.activate(self.dense1(x)))\n","        return self.dense2(x)\n","\n","# Number of neurons in the first fully-connected layer\n","hiddenSize = 300\n","# Number of feature filters in second convolutional layer\n","numFilters = 25\n","# Dropout rate\n","dropoutRate = 0.3\n","# Activation function\n","activation = \"ReLU\"\n","# Learning rate\n","learningRate = 0.001\n","# Momentum for SGD optimizer\n","momentum = 0.9\n","# Number of training epochs\n","numEpochs = 50"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1698073278746,"user":{"displayName":"Pu Zeng","userId":"06309785996409442047"},"user_tz":300},"id":"GlsfudU0Z0R6"},"outputs":[],"source":["# Train and Validation function\n","\n","from tqdm import tqdm\n","def train_epoch(cnn,device,dataloader,loss_fn,optimizer):\n","    cnn.train()\n","    cnnRunningLoss = 0\n","    total = 0\n","    R2 = 0\n","    cnnCorrect=0\n","    total1=0\n","    for i, (inputs, labels) in enumerate(dataloader, 0):\n","        optimizer.zero_grad()\n","        inputs = inputs.to(device).reshape(-1,1,512,128) # Transform the input shape\n","\n","        labels = labels.to(device)\n","        # Forward propagation\n","        cnnOutputs = cnn(inputs)\n","        # print(cnnOutputs.shape)\n","        l2_lambda = 0.05\n","        l2_reg = torch.tensor(0.).to(device)\n","        for param in cnn.parameters():\n","            l2_reg += torch.norm(param)\n","        # Backpropagation\n","        cnnLoss = criterion(cnnOutputs, labels)+l2_reg*l2_lambda\n","        cnnLoss.backward()\n","        # Gradient update\n","        optimizer.step()\n","        total += 1\n","        total1+=labels.size(0)\n","        cnnRunningLoss += cnnLoss.item()\n","        _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n","        cnnCorrect += (cnnPredicted == labels).sum().item()\n","    return cnnRunningLoss/total, cnnCorrect/total1\n","\n","def valid_epoch(cnn,device,dataloader,loss_fn):\n","    cnn.eval()\n","    totalLoss = 0\n","    total = 0\n","    total1 = 0\n","    R2 = 0\n","    cnnLoss = 0\n","    cnnCorrect=0\n","    for inputs, labels in dataloader:\n","        inputs = inputs.to(device).reshape(-1,1,512,128)\n","        labels = labels.to(device)\n","        cnnOutputs = cnn(inputs)\n","        cnnLoss = criterion(cnnOutputs, labels)\n","        _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n","        total += labels.size(0)\n","        total1 +=1\n","        totalLoss += cnnLoss.item()\n","        cnnCorrect += (cnnPredicted == labels).sum().item()\n","    accuracy = cnnCorrect / total\n","    cnn.train()\n","    return totalLoss/total1, accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"RCEmiGU-Z85J"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold 1\n","Train Loss: 4.394462797376844, Train_acc: 0.3305882352941176, Test Loss: 2.6474756002426147, Test acc: 0.18823529411764706\n","Train Loss: 3.3290953945230553, Train_acc: 0.6717647058823529, Test Loss: 2.939752995967865, Test acc: 0.32941176470588235\n","Train Loss: 2.7108905756915056, Train_acc: 0.8458823529411764, Test Loss: 3.8783851067225137, Test acc: 0.36470588235294116\n","Train Loss: 2.4717595356482045, Train_acc: 0.9117647058823529, Test Loss: 4.113501826922099, Test acc: 0.36470588235294116\n","Train Loss: 2.4127669820079096, Train_acc: 0.9258823529411765, Test Loss: 4.882371187210083, Test acc: 0.36470588235294116\n","Train Loss: 2.3541754395873458, Train_acc: 0.9435294117647058, Test Loss: 4.961639483769734, Test acc: 0.4\n","Train Loss: 2.271095306785018, Train_acc: 0.9505882352941176, Test Loss: 5.201759735743205, Test acc: 0.35294117647058826\n","Train Loss: 2.323452772917571, Train_acc: 0.9411764705882353, Test Loss: 5.041255871454875, Test acc: 0.36470588235294116\n","Train Loss: 2.2474406825171576, Train_acc: 0.9611764705882353, Test Loss: 5.04315972328186, Test acc: 0.3764705882352941\n","Train Loss: 2.1785896839918912, Train_acc: 0.9705882352941176, Test Loss: 6.612760345141093, Test acc: 0.36470588235294116\n","Train Loss: 2.1896992745222867, Train_acc: 0.9764705882352941, Test Loss: 7.587708155314128, Test acc: 0.36470588235294116\n","Train Loss: 2.2083626941398338, Train_acc: 0.9647058823529412, Test Loss: 6.222545464833577, Test acc: 0.3764705882352941\n","Train Loss: 2.165671397138525, Train_acc: 0.9752941176470589, Test Loss: 6.286135196685791, Test acc: 0.3764705882352941\n","Train Loss: 2.1255940243049904, Train_acc: 0.9788235294117648, Test Loss: 7.07669464747111, Test acc: 0.3764705882352941\n","Train Loss: 2.1120202717957675, Train_acc: 0.9811764705882353, Test Loss: 7.085828145345052, Test acc: 0.36470588235294116\n","Train Loss: 2.1131904699184276, Train_acc: 0.9764705882352941, Test Loss: 8.085111538569132, Test acc: 0.4117647058823529\n","Train Loss: 2.125277664926317, Train_acc: 0.971764705882353, Test Loss: 7.314129670461019, Test acc: 0.38823529411764707\n","Train Loss: 2.0937291074682167, Train_acc: 0.9752941176470589, Test Loss: 6.951114654541016, Test acc: 0.36470588235294116\n","Train Loss: 2.093116186283253, Train_acc: 0.9752941176470589, Test Loss: 7.365491946538289, Test acc: 0.36470588235294116\n","Train Loss: 2.087093443782241, Train_acc: 0.9729411764705882, Test Loss: 6.421135624249776, Test acc: 0.35294117647058826\n","Train Loss: 2.0913199561613576, Train_acc: 0.9741176470588235, Test Loss: 5.687729398409526, Test acc: 0.36470588235294116\n"]}],"source":["# Train the model\n","\n","import sklearn\n","from sklearn.model_selection import KFold\n","from sklearn.model_selection import StratifiedKFold\n","X_train_v, X_test, y_train_v, y_test = train_test_split(X, y, test_size=0.2, random_state=99, stratify=y) #First split, so there is no data leakage problems\n","\n","# Transform data into DataSet\n","X_train_v = torch.as_tensor(X_train_v, dtype=torch.float) # an alternative to torch.from_numpy\n","y_train_v = torch.as_tensor(y_train_v, dtype=torch.float)\n","X_test = torch.as_tensor(X_test, dtype=torch.float)\n","y_test = torch.as_tensor(y_test, dtype=torch.float)\n","splits=StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n","train_dataset = TensorDataset(X_train_v, y_train_v)\n","test_dataset = TensorDataset(X_test, y_test)\n","batch_size=128\n","models = []\n","history = {'fold':[], 'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n","\n","#K-Fold validation\n","for fold, (train_idx,val_idx) in enumerate(splits.split(X_train_v,y_train_v)):\n","    print('Fold {}'.format(fold + 1))\n","    t = pd.DataFrame(y_train_v[train_idx], columns = ['class']).reset_index()\n","    idx = []\n","\n","    #Resampling to solve the unbalanced problem\n","    y_train = []\n","    for i in range(0,num_classes):\n","        # if i!=label_dict['Unknown']:\n","      idx += list(t[t['class']==i].sample(50,replace=True)['index'])\n","      y_train += [i]*50\n","    X_train = X_train_v[train_idx][idx]\n","\n","    t = pd.DataFrame(y_train_v[val_idx], columns = ['class']).reset_index()\n","    idx = []\n","    y_val = []\n","    for i in range(0,num_classes):\n","        # if i!=label_dict['Unknown']:\n","      idx += list(t[t['class']==i].sample(5,replace=True)['index'])\n","      y_val += [i]*5\n","    X_val =  X_train_v[val_idx][idx]\n","\n","    X_train = torch.as_tensor(X_train, dtype=torch.float) # an alternative to torch.from_numpy\n","    y_train = torch.as_tensor(y_train, dtype=torch.float).type(torch.LongTensor)\n","    X_val = torch.as_tensor(X_val, dtype=torch.float)\n","    y_val = torch.as_tensor(y_val, dtype=torch.float).type(torch.LongTensor)\n","\n","    train_dataset = TensorDataset(X_train, y_train)\n","    test_dataset = TensorDataset(X_val, y_val)\n","\n","    from torch.utils.data import Dataset, DataLoader\n","    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","    test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n","\n","    model = CNNModel(hiddenSize, numFilters, dropoutRate, activation).to(device)\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.SGD(list(model.parameters()), lr=learningRate, momentum=momentum)\n","    # optimizer = torch.optim.Adam(list(model.parameters()), lr=learningRate)\n","    best_test = -np.inf\n","    best_model = None # Save the best model\n","    #Train the model\n","    for epoch in range(numEpochs):\n","        train_loss, train_R2=train_epoch(model,device,train_dataloader,criterion,optimizer)\n","        test_loss, test_R2=valid_epoch(model,device,test_dataloader,criterion)\n","        history['fold'].append(fold)\n","        history['train_loss'].append(train_loss)\n","        history['test_loss'].append(test_loss)\n","        history['train_acc'].append(train_R2)\n","        history['test_acc'].append(test_R2)\n","        if test_R2\u003ebest_test:\n","            test_test = test_R2\n","            best_model = model\n","        print('Train Loss: {}, Train_acc: {}, Test Loss: {}, Test acc: {}'.format(train_loss, train_R2, test_loss, test_R2))\n","    models.append([best_model])"]},{"cell_type":"markdown","metadata":{"id":"GxQMgt5ZXOXp"},"source":["# Evaluaton"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u0--vQKT4bln"},"outputs":[],"source":["#Calculate the average accuray of the 5 models\n","\n","from torch.utils.data import Dataset, DataLoader\n","X_train_v, X_test, y_train_v, y_test = train_test_split(X, y, test_size=0.2, random_state=99, stratify=y)\n","t = pd.DataFrame(y_test, columns = ['class']).reset_index()\n","criterion = nn.CrossEntropyLoss()\n","idx = []\n","y_test = []\n","with torch.no_grad():\n","  for i in range(0,17):\n","      # if i!=label_dict['Unknown']:\n","    idx += list(t[t['class']==i].sample(20,replace=True)['index'])\n","    y_test += [i]*20\n","  X_test =  X_test[idx]\n","  X_test = torch.as_tensor(X_test, dtype=torch.float)\n","  y_test = torch.as_tensor(y_test, dtype=torch.float).type(torch.LongTensor)\n","\n","  test_dataset = TensorDataset(X_test, y_test)\n","  test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n","  acc = []\n","  for best_model in models:\n","    acc.append(valid_epoch(best_model[0],device,test_dataloader,criterion)[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jqE8HFYR4cV1"},"outputs":[],"source":["np.mean(acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q1xKu5824cgM"},"outputs":[],"source":["# Calculate the accuracy with majority vote\n","outputs = []\n","with torch.no_grad():\n","  for model in models:\n","    model[0].eval()\n","    model_output = []\n","    label_= []\n","    model[0].to(device)\n","    for inputs, labels in test_dataloader:\n","        inputs = inputs.reshape(-1,1,512,128).to(device)\n","        labels = labels.to(device)\n","        cnnOutputs = model[0](inputs)\n","        model_output.append(cnnOutputs)\n","        label_.append(labels)\n","        # del inputs\n","    outputs.append(torch.vstack(model_output))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pke06dv24cpn"},"outputs":[],"source":["shape = outputs[0].shape\n","labels = torch.hstack(label_)\n","cnnresult = torch.vstack(outputs).reshape(-1,shape[0],shape[1]).mean(axis=0).to('cpu')\n","_, cnnPredicted = torch.max(cnnresult.data, 1)\n","cnnCorrect = (cnnPredicted.detach().numpy() == labels.to('cpu').detach().numpy()).sum().item()\n","print(cnnCorrect/len(labels)*100)\n","from sklearn.metrics import confusion_matrix\n","confu_m = confusion_matrix(labels.to('cpu'), cnnPredicted.to('cpu'))\n","import seaborn as sns\n","sns.heatmap(confu_m,square=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M2ufDXvU4czd"},"outputs":[],"source":["# Show the Precision, Recall, F1 scores of each classes\n","from sklearn.metrics import precision_recall_fscore_support\n","import pandas as pd\n","scores = pd.DataFrame(precision_recall_fscore_support(cnnPredicted.to('cpu'), labels.to('cpu'), labels = list(range(17))),index=['precision','recall','f1','support'], columns = list(label_dict)[:17])\n","scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kn0NCC2dCrTx"},"outputs":[],"source":["# Print the label_dict\n","label_dict = {}\n","for cl in le.classes_:\n","    label_dict.update({cl:le.transform([cl])[0]})\n","label_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ganRxwdfBlQn"},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}