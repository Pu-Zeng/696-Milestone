{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"VQUqFk0Q6FJd"},"outputs":[],"source":["# Train the CNN Emotion Regression Model with MIDI data#\n","# Last editted by Pu Zeng, 19/10/2023 #\n","# The result is really bad because we only use a small portion of the dataset"]},{"cell_type":"markdown","metadata":{"id":"m31DtskrLZEr"},"source":["# Install the library needed"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2798,"status":"ok","timestamp":1698011098933,"user":{"displayName":"Pu Zeng","userId":"06309785996409442047"},"user_tz":300},"id":"R-6jyYA-6HJF","outputId":"1ebc408f-1f7b-4952-9ff2-297c1cd9efcc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into '696-Milestone'...\n","remote: Enumerating objects: 3018, done.\u001b[K\n","remote: Counting objects: 100% (3018/3018), done.\u001b[K\n","remote: Compressing objects: 100% (2531/2531), done.\u001b[K\n","remote: Total 3018 (delta 43), reused 3008 (delta 33), pack-reused 0\u001b[K\n","Receiving objects: 100% (3018/3018), 32.22 MiB | 24.42 MiB/s, done.\n","Resolving deltas: 100% (43/43), done.\n"]}],"source":["!git clone https://github.com/Pu-Zeng/696-Milestone.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"38a8RynI6No2","outputId":"c025cbdf-da1f-4902-a2d5-577cf9271ddf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting langdetect\n","  Downloading langdetect-1.0.9.tar.gz (981 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n","Building wheels for collected packages: langdetect\n","  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=b2dd0480552371ede141d6541bdbbc6effa08e00c2e6b69eb0b432f50957ec2b\n","  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n","Successfully built langdetect\n","Installing collected packages: langdetect\n","Successfully installed langdetect-1.0.9\n","Collecting pretty_midi\n","  Downloading pretty_midi-0.2.10.tar.gz (5.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.23.5)\n","Collecting mido>=1.1.16 (from pretty_midi)\n","  Downloading mido-1.3.0-py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty_midi) (1.16.0)\n","Requirement already satisfied: packaging~=23.1 in /usr/local/lib/python3.10/dist-packages (from mido>=1.1.16->pretty_midi) (23.2)\n","Building wheels for collected packages: pretty_midi\n","  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretty_midi: filename=pretty_midi-0.2.10-py3-none-any.whl size=5592287 sha256=57c6f1e6dab1469b69a166efeeed45a96b99bd476ceab218f0e8ca97542eec97\n","  Stored in directory: /root/.cache/pip/wheels/cd/a5/30/7b8b7f58709f5150f67f98fde4b891ebf0be9ef07a8af49f25\n","Successfully built pretty_midi\n","Installing collected packages: mido, pretty_midi\n","Successfully installed mido-1.3.0 pretty_midi-0.2.10\n","Collecting transformers\n","  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers<0.15,>=0.14 (from transformers)\n","  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n","Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n","  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n","Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.34.1\n"]}],"source":["!pip install langdetect\n","!pip install pretty_midi\n","!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u8eSS9tg62ge"},"outputs":[],"source":["import os\n","import pandas as pd\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","# import mido\n","import string\n","import numpy as np\n","# from utilis import get_pianoroll_data\n","import pickle\n","import os\n","import pandas as pd\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","# import mido\n","import string\n","import numpy as np\n","# from utilis import get_pianoroll_data\n","import pickle\n","from sklearn import preprocessing\n","import torch\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from sklearn.datasets import fetch_california_housing\n","from sklearn.model_selection import train_test_split\n","\n","from torch.utils.data import TensorDataset\n"]},{"cell_type":"markdown","metadata":{"id":"inAolCbqLgyL"},"source":["# Data Preprocess"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"JufI5yle6FJe"},"outputs":[],"source":["# Use our python script to preprocess the midi files into matrices and lyrics\n","!mkdir Processed_Data\n","!python /content/696-Milestone/Data_Preprocessing/Emotion_MIDI2.py /content/696-Milestone/Toy_Dataset/Lakh/ ./Processed_Data/"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"aGgpGcjx6FJe"},"outputs":[],"source":["# Use our python script to generate the labels using Flan-T5\n","!python /content/696-Milestone/Data_Preprocessing/Emotion_Label.py ./Processed_Data/ ./Processed_Data/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ilm1bHPX6FJe"},"outputs":[],"source":["# Open the results of the last two cells\n","file=open(\"./Processed_Data/lakh_emotion.bin\",\"rb\")\n","music_data = pickle.load(file) #保存list到文件\n","file.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"25vLfi-K6FJj"},"outputs":[],"source":["# Show the labels\n","np.unique([x[1] for x in music_data])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a5ONeVUU7MOU"},"outputs":[],"source":["# Selected the most common one word labels\n","from tqdm import tqdm\n","X = []\n","y = []\n","chosen_label = ['sadness', 'happy', 'love', 'joy', 'negative', 'positive', 'anger',\n","       'awe', 'emotional', 'hopeful', 'angry', 'excited', 'fear', 'hurt',\n","       'fearful']\n","# for i in tqdm(range(1,10)):\n","file=open(\"./Processed_Data/lakh_emotion.bin\",\"rb\")\n","music_data = pickle.load(file) #保存list到文件\n","file.close()\n","for m in music_data:\n","    if m[1] in chosen_label:\n","        X.append(m[0])\n","        if m[1] == 'anger':\n","            m[1] = 'angry'\n","        if m[1] == 'fearful':\n","            m[1] = 'fear'\n","        if m[1] == 'joy':\n","            m[1] = 'happy'\n","        y.append(m[1])\n","X = np.array(X)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aOZWglnR6FJk"},"outputs":[],"source":["# The dataset is just a toy dataset, so there are far less labels than the whole Lakh dataset, we need to drop those will few samples\n","y = np.array(y)\n","X_new = []\n","y_new = []\n","for l in np.unique(y):\n","    n = (y==l).sum()\n","    if n>=6:\n","        X_new += list(X[y==l])\n","        y_new += list(y[y==l])\n","X = X_new\n","y = y_new"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kuze26_g6FJk"},"outputs":[],"source":["# Transform labels into one-hot variable\n","from sklearn import preprocessing\n","import torch\n","\n","le = preprocessing.LabelEncoder()\n","y = le.fit_transform(y)\n","\n","label_dict = {}\n","for cl in le.classes_:\n","    label_dict.update({cl:le.transform([cl])[0]})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cRsJ_DoC6FJk"},"outputs":[],"source":["num_labels = len(np.unique(y))"]},{"cell_type":"markdown","metadata":{"id":"uIAH7-yrMGGm"},"source":["# Train the CNN model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WjbhrqnC6FJk"},"outputs":[],"source":["#Define CNN model\n","class CNNModel(nn.Module):\n","    def __init__(self, hiddenSize, outChannels, dropoutRate, activate):\n","        super().__init__()\n","        self.outChannels = outChannels\n","        self.activate = nn.Sigmoid() if activate == \"Sigmoid\" else nn.ReLU()\n","        self.conv1 = nn.Conv2d(1, 24, (10,1))\n","        self.pool = nn.MaxPool2d((2, 1))\n","        self.conv2 = nn.Conv2d(24, 48, (10,1))\n","        self.conv3 = nn.Conv2d(48, 96, (10,1))\n","        self.conv4 = nn.Conv2d(96, 192, (10,1))\n","        self.conv5 = nn.Conv2d(192, 384, (5,2))\n","        self.conv6 = nn.Conv2d(384, 192, (5,2))\n","        self.dense1 = nn.Linear(48384, hiddenSize)\n","        self.dropout = nn.Dropout(dropoutRate)\n","        self.dense2 = nn.Linear(hiddenSize, num_labels)\n","\n","    def forward(self, x):\n","        x = self.pool(self.activate(self.conv1(x)))\n","        x = self.pool(self.activate(self.conv2(x)))\n","        # print(x.shape)\n","        x = self.dropout(self.pool(self.activate(self.conv3(x))))\n","        x = self.pool(self.activate(self.conv4(x)))\n","        x = self.pool(self.activate(self.conv5(x)))\n","        x = self.pool(self.activate(self.conv6(x)))\n","        # print(x.shape)\n","        x = x.view(-1, 48384)\n","        x = self.dropout(self.activate(self.dense1(x)))\n","        return self.dense2(x)\n","\n","# Number of neurons in the first fully-connected layer\n","hiddenSize = 4096\n","# Number of feature filters in second convolutional layer\n","numFilters = 25\n","# Dropout rate\n","dropoutRate = 0.2\n","# Activation function\n","activation = \"ReLU\"\n","# Learning rate\n","learningRate = 0.005\n","# Momentum for SGD optimizer\n","momentum = 0.9\n","# Number of training epochs\n","numEpochs = 20"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-TZ6tDTG6FJk"},"outputs":[],"source":["#Define Trian and Validation function\n","\n","from tqdm import tqdm\n","def train_epoch(cnn,device,dataloader,loss_fn,optimizer):\n","    cnn.train()\n","    cnnRunningLoss = 0\n","    total = 0\n","    R2 = 0\n","    cnnCorrect=0\n","    total1=0\n","    for i, (inputs, labels) in enumerate(dataloader, 0):\n","        optimizer.zero_grad()\n","        inputs = inputs.to(device).reshape(-1,1,512,128)\n","\n","        labels = labels.to(device)\n","        # Forward propagation\n","        cnnOutputs = cnn(inputs)\n","        # print(cnnOutputs.shape)\n","        l2_lambda = 0.001\n","        l2_reg = torch.tensor(0.).to(device)\n","        for param in cnn.parameters():\n","            l2_reg += torch.norm(param)\n","        # Backpropagation\n","        cnnLoss = criterion(cnnOutputs, labels)+l2_reg*l2_lambda\n","        cnnLoss.backward()\n","        # Gradient update\n","        optimizer.step()\n","        total += 1\n","        total1+=labels.size(0)\n","        cnnRunningLoss += cnnLoss.item()\n","        _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n","        cnnCorrect += (cnnPredicted == labels).sum().item()\n","    return cnnRunningLoss/total, cnnCorrect/total1\n","\n","def valid_epoch(cnn,device,dataloader,loss_fn):\n","    cnn.eval()\n","    totalLoss = 0\n","    total = 0\n","    total1 = 0\n","    R2 = 0\n","    cnnLoss = 0\n","    cnnCorrect=0\n","    for inputs, labels in dataloader:\n","        inputs = inputs.to(device).reshape(-1,1,512,128)\n","        labels = labels.to(device)\n","        cnnOutputs = cnn(inputs)\n","        cnnLoss = loss_fn(cnnOutputs, labels)\n","        _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n","        total += labels.size(0)\n","        total1 +=1\n","        totalLoss += cnnLoss.item()\n","        cnnCorrect += (cnnPredicted == labels).sum().item()\n","    accuracy = cnnCorrect / total * 100\n","    cnn.train()\n","    return totalLoss/total1, accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mK_c13r56FJk"},"outputs":[],"source":["# Train the model\n","import sklearn\n","from sklearn.model_selection import StratifiedKFold\n","X_train_v, X_test, y_train_v, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y) # First Split the dataset and use the training set for 5-fold validation\n","\n","X_train_v = torch.as_tensor(X_train_v, dtype=torch.float) # an alternative to torch.from_numpy\n","y_train_v = torch.as_tensor(y_train_v, dtype=torch.float)\n","X_test = torch.as_tensor(X_test, dtype=torch.float)\n","y_test = torch.as_tensor(y_test, dtype=torch.float)\n","splits=StratifiedKFold(n_splits=5,shuffle=True,random_state=99)\n","train_dataset = TensorDataset(X_train_v, y_train_v)\n","test_dataset = TensorDataset(X_test, y_test)\n","batch_size=128\n","models = []\n","history = {'fold':[], 'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","for fold, (train_idx,val_idx) in enumerate(splits.split(X_train_v,y_train_v)):\n","    print('Fold {}'.format(fold + 1))\n","    t = pd.DataFrame(y_train_v[train_idx], columns = ['class']).reset_index()\n","    idx = []\n","    # Resample to avoid unbalanced dataset\n","    y_train = []\n","    for i in range(0,num_labels):\n","      idx += list(t[t['class']==i].sample(100,replace=True)['index'])\n","      y_train += [i]*100\n","    X_train = X_train_v[train_idx][idx]\n","\n","    t = pd.DataFrame(y_train_v[val_idx], columns = ['class']).reset_index()\n","    idx = []\n","    y_val = []\n","    for i in range(0,num_labels):\n","      # print(i)\n","      if i in t['class'].values:\n","          idx += list(t[t['class']==i].sample(20,replace=True)['index'])\n","          y_val += [i]*20\n","    X_val =  X_train_v[val_idx][idx]\n","\n","    X_train = torch.as_tensor(X_train, dtype=torch.float) # an alternative to torch.from_numpy\n","    y_train = torch.as_tensor(y_train, dtype=torch.float).type(torch.LongTensor)\n","    X_val = torch.as_tensor(X_val, dtype=torch.float)\n","    y_val = torch.as_tensor(y_val, dtype=torch.float).type(torch.LongTensor)\n","\n","    train_dataset = TensorDataset(X_train, y_train)\n","    test_dataset = TensorDataset(X_val, y_val)\n","\n","    from torch.utils.data import Dataset, DataLoader\n","    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","    test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","\n","    model = CNNModel(hiddenSize, numFilters, dropoutRate, activation).to(device)\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.SGD(list(model.parameters()), lr=learningRate, momentum=momentum)\n","    # optimizer = torch.optim.Adam(list(model.parameters()), lr=learningRate)\n","    best_test = -np.inf\n","    best_model = None\n","\n","    for epoch in range(numEpochs):\n","        train_loss, train_R2=train_epoch(model,device,train_dataloader,criterion,optimizer)\n","        test_loss, test_R2=valid_epoch(model,device,test_dataloader,criterion)\n","        history['fold'].append(fold)\n","        history['train_loss'].append(train_loss)\n","        history['test_loss'].append(test_loss)\n","        history['train_acc'].append(train_R2)\n","        history['test_acc'].append(test_R2)\n","        if test_R2>best_test:\n","            test_test = test_R2\n","            best_model = model\n","        print('Train Loss: {}, Train_acc: {}, Test Loss: {}, Test acc: {}'.format(train_loss, train_R2, test_loss, test_R2))\n","    models.append([best_model])"]},{"cell_type":"markdown","metadata":{"id":"t0qh41OUMOgA"},"source":["# Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Zh5crLm6FJk"},"outputs":[],"source":["# Caculate the average accuray\n","# X_train_v, X_test, y_train_v, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","t = pd.DataFrame(y_test, columns = ['class']).reset_index()\n","idx = []\n","y_test = []\n","for i in range(0,num_labels):\n","    if i in t['class'].values:\n","        idx += list(t[t['class']==i].sample(20,replace=True)['index'])\n","        y_test += [i]*20\n","X_test = np.array(X_test)\n","X_test =  X_test[idx]\n","X_test = torch.as_tensor(X_test, dtype=torch.float)\n","y_test = torch.as_tensor(y_test, dtype=torch.float).type(torch.LongTensor)\n","test_dataset = TensorDataset(X_test, y_test)\n","test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","acc=[]\n","for best_model in models:\n","    acc.append(valid_epoch(best_model[0],device,test_dataloader,criterion)[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TxuOXId86FJl"},"outputs":[],"source":["np.mean(acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EnT0WLQ56FJl"},"outputs":[],"source":["# Calculate the accuray of the ensemble model\n","with torch.no_grad():\n","  outputs = []\n","  for model in models:\n","    model[0].eval()\n","    model_output = []\n","    label_= []\n","    model[0].to('cpu')\n","    for inputs, labels in test_dataloader:\n","        inputs = inputs.to('cpu').reshape(-1,1,512,128)\n","        labels = labels.to('cpu')\n","        cnnOutputs = model[0](inputs)\n","        model_output.append(cnnOutputs)\n","        label_.append(labels)\n","    outputs.append(torch.vstack(model_output))\n","  shape = outputs[0].shape\n","  cnnresult = torch.vstack(outputs).reshape(-1,shape[0],shape[1]).mean(axis=0)\n","  labels = np.hstack(label_)\n","  _, cnnPredicted = torch.max(cnnresult.data, 1)\n","  cnnCorrect = (cnnPredicted.detach().numpy() == labels).sum().item()\n","  cnnCorrect/len(labels)*100"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LuwpaMdp6FJl"},"outputs":[],"source":["# Draw the confusion matrix\n","from sklearn.metrics import confusion_matrix\n","confu_m = confusion_matrix(labels, cnnPredicted)\n","import seaborn as sns\n","sns.heatmap(confu_m,square=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-ZKS82Ij6FJl"},"outputs":[],"source":["label_dict = {}\n","for cl in le.classes_:\n","    label_dict.update({cl:le.transform([cl])[0]})\n","label_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9_YXxzyK6FJl"},"outputs":[],"source":["from sklearn.metrics import precision_recall_fscore_support\n","scores = pd.DataFrame(precision_recall_fscore_support(cnnPredicted, labels, labels = list(range(num_labels))),index=['precision','recall','f1','support'], columns = list(label_dict)[:num_labels])\n","scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rdZga7NV6FJl"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}