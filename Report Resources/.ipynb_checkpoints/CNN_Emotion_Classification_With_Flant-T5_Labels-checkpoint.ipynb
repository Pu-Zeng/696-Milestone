{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3-ChWZxV6Q4f",
    "outputId": "40700328-f8eb-48ad-e076-40ac59995dc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/MyDrive/Milestone 2/music_data.zip\n",
      "  inflating: /content/drive/MyDrive/Milestone 2/music_data1.bin  \n",
      "  inflating: /content/drive/MyDrive/Milestone 2/music_data2.bin  \n",
      "  inflating: /content/drive/MyDrive/Milestone 2/music_data3.bin  \n",
      "  inflating: /content/drive/MyDrive/Milestone 2/music_data4.bin  \n",
      "  inflating: /content/drive/MyDrive/Milestone 2/music_data5.bin  \n",
      "  inflating: /content/drive/MyDrive/Milestone 2/music_data6.bin  \n",
      "  inflating: /content/drive/MyDrive/Milestone 2/music_data7.bin  \n",
      "  inflating: /content/drive/MyDrive/Milestone 2/music_data8.bin  \n",
      "  inflating: /content/drive/MyDrive/Milestone 2/music_data9.bin  \n"
     ]
    }
   ],
   "source": [
    "!unzip \"/content/drive/MyDrive/Milestone 2/music_data.zip\" -d \"/content/drive/MyDrive/Milestone 2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wRF6FLeb5DXz"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "u8eSS9tg62ge",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# import mido\n",
    "import string\n",
    "import numpy as np\n",
    "# from utilis import get_pianoroll_data\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "# import mido\n",
    "import string\n",
    "import numpy as np\n",
    "# from utilis import get_pianoroll_data\n",
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import TensorDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file=open(\"lakh_emotion.bin\",\"rb\")\n",
    "music_data = pickle.load(file) #保存list到文件\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"a-livin'\", 'achey', 'ah', 'ah!',\n",
       "       \"ahah,ahva,vava.we'll take a dream on a sunday,we'll take a life,take a holiday.take a lie,take a dreamer,dream\",\n",
       "       'ahh', 'ahum', 'amazing', 'anger', 'angry', 'arousal', 'awe',\n",
       "       'bad', 'big', 'bitter', 'bittersweet', 'calm', 'cold', 'confused',\n",
       "       'darkness', 'ecstasy', 'ecstatic', 'eloquent',\n",
       "       'emertimenessed by midnight cinglight tying live phonebovelingney, ry where thing no more foremertimenessed by summertimemertimenesss-summertimemertime',\n",
       "       'emotion', 'emotional', 'emozione', 'enlightened', 'esattino',\n",
       "       'ethereal', 'euphoria',\n",
       "       'evtiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii', 'excited',\n",
       "       'fear', 'fearful', 'foolish', 'free as a bird', 'frightful',\n",
       "       \"frozen inside without your touch without your love, darling only you are the life among the dead of this i, i can't believe i couldn't see kept in the dark, but you were there in front of me]\",\n",
       "       'good', 'grateful', 'happy', 'happyness', 'hate', 'heart',\n",
       "       'heartbreaking', 'heartbroken', 'helpful', 'hopeful', 'hurt',\n",
       "       'hurts', 'hysterical', 'i',\n",
       "       'i and getgie you you getgiei and getgie you you getgiei and lyaly out in stuff you you and getgiei and getgies hoodoobie scooshoo scoobe',\n",
       "       'i lay down with an angel', 'i loved them so.',\n",
       "       \"i'm your top prime cut of meat, i'm your choice. i wanna be elected. i'm my top prime cut of meat, i'm your choice. i wanna be elected.\",\n",
       "       'joy', 'joyous', 'light', 'love', 'mean', 'na na na', 'negative',\n",
       "       'numbness',\n",
       "       \"ooooooooo,ooo.ooooooooo,ooo.if you,if you could return,don't let it burn,don't let it fade.i'm sure i'm not being rude\",\n",
       "       'positive', 'powerful', 'proud', 'raining', 'sad', 'sadness',\n",
       "       'shame',\n",
       "       'she feels she is a woman and she is a man and she is a woman and she is a man and she is a woman and she is a woman and she is a woman and she is a woman and',\n",
       "       'shock', 'sorrow', 'strange', 'strong', 'surprise', 'tenderness',\n",
       "       'time', 'tired', 'tiredness', 'trouble', 'uneasy', 'unsure',\n",
       "       'upset', 'vain',\n",
       "       \"webutwell and how nyr ilyed one but thing peenden itn't and how nyr y you buting we'velems you'relieve how thing how thing is answers but\",\n",
       "       'woo',\n",
       "       \"you have seen digcing Friday looking wheresic getting you anybody nightsic's with sicrything you're and youcingyounglyventeen.dancingfeelbourine.youhaving see digc\"],\n",
       "      dtype='<U191')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([x[1] for x in music_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1810"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(music_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "a5ONeVUU7MOU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "X = []\n",
    "y = []\n",
    "chosen_label = ['sadness', 'happy', 'love', 'joy', 'negative', 'positive', 'anger',\n",
    "       'awe', 'emotional', 'hopeful', 'angry', 'excited', 'fear', 'hurt',\n",
    "       'fearful']\n",
    "# for i in tqdm(range(1,10)):\n",
    "file=open(\"lakh_emotion.bin\",\"rb\")\n",
    "music_data = pickle.load(file) #保存list到文件\n",
    "file.close()\n",
    "for m in music_data:\n",
    "    if m[1] in chosen_label:\n",
    "        X.append(m[0])\n",
    "        if m[1] == 'anger':\n",
    "            m[1] = 'angry'\n",
    "        if m[1] == 'fearful':\n",
    "            m[1] = 'fear'\n",
    "        if m[1] == 'joy':\n",
    "            m[1] = 'happy'\n",
    "        y.append(m[1])\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_labels = len(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_temp = np.array(y)\n",
    "d = {}\n",
    "for label in np.unique(y):\n",
    "    d[label] = (y_temp==label).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1143"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import torch\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "label_dict = {}\n",
    "for cl in le.classes_:\n",
    "    label_dict.update({cl:le.transform([cl])[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, hiddenSize, outChannels, dropoutRate, activate):\n",
    "        super().__init__()\n",
    "        self.outChannels = outChannels\n",
    "        self.activate = nn.Sigmoid() if activate == \"Sigmoid\" else nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(1, 24, (10,1))\n",
    "        self.pool = nn.MaxPool2d((2, 1))\n",
    "        self.conv2 = nn.Conv2d(24, 48, (10,1))\n",
    "        self.conv3 = nn.Conv2d(48, 96, (10,1))\n",
    "        self.conv4 = nn.Conv2d(96, 192, (10,1))\n",
    "        self.conv5 = nn.Conv2d(192, 384, (5,2))\n",
    "        self.conv6 = nn.Conv2d(384, 192, (5,2))\n",
    "        self.dense1 = nn.Linear(48384, hiddenSize)\n",
    "        self.dropout = nn.Dropout(dropoutRate)\n",
    "        self.dense2 = nn.Linear(hiddenSize, num_labels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.activate(self.conv1(x)))\n",
    "        x = self.pool(self.activate(self.conv2(x)))\n",
    "        # print(x.shape)\n",
    "        x = self.dropout(self.pool(self.activate(self.conv3(x))))\n",
    "        x = self.pool(self.activate(self.conv4(x)))\n",
    "        x = self.pool(self.activate(self.conv5(x)))\n",
    "        x = self.pool(self.activate(self.conv6(x)))\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 48384)\n",
    "        x = self.dropout(self.activate(self.dense1(x)))\n",
    "        return self.dense2(x)\n",
    "\n",
    "# Number of neurons in the first fully-connected layer\n",
    "hiddenSize = 4096\n",
    "# Number of feature filters in second convolutional layer\n",
    "numFilters = 25\n",
    "# Dropout rate\n",
    "dropoutRate = 0.2\n",
    "# Activation function\n",
    "activation = \"ReLU\"\n",
    "# Learning rate\n",
    "learningRate = 0.005\n",
    "# Momentum for SGD optimizer\n",
    "momentum = 0.9\n",
    "# Number of training epochs\n",
    "numEpochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train_epoch(cnn,device,dataloader,loss_fn,optimizer):\n",
    "    cnn.train()\n",
    "    cnnRunningLoss = 0\n",
    "    total = 0\n",
    "    R2 = 0\n",
    "    cnnCorrect=0\n",
    "    total1=0\n",
    "    for i, (inputs, labels) in enumerate(dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to('cuda').reshape(-1,1,512,128)\n",
    "        \n",
    "        labels = labels.to('cuda')\n",
    "        # Forward propagation\n",
    "        cnnOutputs = cnn(inputs)\n",
    "        # print(cnnOutputs.shape)\n",
    "        l2_lambda = 0.001\n",
    "        l2_reg = torch.tensor(0.).to('cuda')\n",
    "        for param in cnn.parameters():\n",
    "            l2_reg += torch.norm(param)\n",
    "        # Backpropagation\n",
    "        cnnLoss = criterion(cnnOutputs, labels)+l2_reg*l2_lambda\n",
    "        cnnLoss.backward()\n",
    "        # Gradient update\n",
    "        optimizer.step()\n",
    "        total += 1\n",
    "        total1+=labels.size(0)\n",
    "        cnnRunningLoss += cnnLoss.item()\n",
    "        _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n",
    "        cnnCorrect += (cnnPredicted == labels).sum().item()\n",
    "    return cnnRunningLoss/total, cnnCorrect/total1\n",
    "\n",
    "def valid_epoch(cnn,device,dataloader,loss_fn):\n",
    "    cnn.eval()\n",
    "    totalLoss = 0\n",
    "    total = 0\n",
    "    total1 = 0\n",
    "    R2 = 0\n",
    "    cnnLoss = 0\n",
    "    cnnCorrect=0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to('cuda').reshape(-1,1,512,128)\n",
    "        labels = labels.to('cuda')\n",
    "        cnnOutputs = cnn(inputs)\n",
    "        cnnLoss = loss_fn(cnnOutputs, labels)\n",
    "        _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        total1 +=1\n",
    "        totalLoss += cnnLoss.item()\n",
    "        cnnCorrect += (cnnPredicted == labels).sum().item()\n",
    "    accuracy = cnnCorrect / total * 100\n",
    "    cnn.train()\n",
    "    return totalLoss/total1, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Train Loss: 2.54693922996521, Train_acc: 0.10083333333333333, Test Loss: 2.509760618209839, Test acc: 3.75\n",
      "Train Loss: 2.432154726982117, Train_acc: 0.17166666666666666, Test Loss: 2.575276494026184, Test acc: 8.75\n",
      "Train Loss: 2.166303515434265, Train_acc: 0.2683333333333333, Test Loss: 2.872212529182434, Test acc: 16.25\n",
      "Train Loss: 1.8634415864944458, Train_acc: 0.39916666666666667, Test Loss: 2.742924213409424, Test acc: 22.916666666666664\n",
      "Train Loss: 1.6107344388961793, Train_acc: 0.5075, Test Loss: 3.2595866918563843, Test acc: 30.0\n",
      "Train Loss: 1.4440710425376893, Train_acc: 0.5641666666666667, Test Loss: 2.9759310483932495, Test acc: 34.166666666666664\n",
      "Train Loss: 1.2971147179603577, Train_acc: 0.6241666666666666, Test Loss: 3.4962048530578613, Test acc: 37.5\n",
      "Train Loss: 1.1824334502220153, Train_acc: 0.63, Test Loss: 4.852903842926025, Test acc: 37.5\n",
      "Train Loss: 1.0968679368495942, Train_acc: 0.6541666666666667, Test Loss: 5.9636454582214355, Test acc: 35.0\n",
      "Train Loss: 1.140394687652588, Train_acc: 0.6566666666666666, Test Loss: 5.402667999267578, Test acc: 37.083333333333336\n",
      "Train Loss: 1.1371516346931458, Train_acc: 0.65, Test Loss: 6.560758590698242, Test acc: 36.25\n",
      "Train Loss: 1.0969563722610474, Train_acc: 0.6641666666666667, Test Loss: 6.696919679641724, Test acc: 37.083333333333336\n",
      "Train Loss: 1.2361123263835907, Train_acc: 0.66, Test Loss: 4.558703422546387, Test acc: 36.25\n",
      "Train Loss: 1.0824059665203094, Train_acc: 0.6783333333333333, Test Loss: 4.750430583953857, Test acc: 37.083333333333336\n",
      "Train Loss: 1.0225753486156464, Train_acc: 0.6883333333333334, Test Loss: 8.162421703338623, Test acc: 37.916666666666664\n",
      "Train Loss: 1.0899004876613616, Train_acc: 0.6741666666666667, Test Loss: 5.456668853759766, Test acc: 40.416666666666664\n",
      "Train Loss: 1.0418302893638611, Train_acc: 0.6966666666666667, Test Loss: 5.78740119934082, Test acc: 37.5\n",
      "Train Loss: 1.024521380662918, Train_acc: 0.6833333333333333, Test Loss: 5.538845062255859, Test acc: 37.5\n",
      "Train Loss: 1.0076925218105317, Train_acc: 0.6841666666666667, Test Loss: 6.364707946777344, Test acc: 40.0\n",
      "Train Loss: 0.9734763979911805, Train_acc: 0.7008333333333333, Test Loss: 6.873267650604248, Test acc: 39.166666666666664\n",
      "Fold 2\n",
      "Train Loss: 2.561113739013672, Train_acc: 0.12166666666666667, Test Loss: 2.4792205095291138, Test acc: 10.833333333333334\n",
      "Train Loss: 2.533825159072876, Train_acc: 0.16083333333333333, Test Loss: 2.458383560180664, Test acc: 10.833333333333334\n",
      "Train Loss: 2.4465691328048704, Train_acc: 0.18416666666666667, Test Loss: 2.4288687705993652, Test acc: 20.0\n",
      "Train Loss: 2.205732011795044, Train_acc: 0.2683333333333333, Test Loss: 2.910871982574463, Test acc: 22.916666666666664\n",
      "Train Loss: 2.0849866032600404, Train_acc: 0.3541666666666667, Test Loss: 2.3814446926116943, Test acc: 29.583333333333332\n",
      "Train Loss: 1.7696589469909667, Train_acc: 0.44666666666666666, Test Loss: 3.01533579826355, Test acc: 34.583333333333336\n",
      "Train Loss: 1.4880540013313293, Train_acc: 0.5358333333333334, Test Loss: 2.6646043062210083, Test acc: 39.166666666666664\n",
      "Train Loss: 1.2976189255714417, Train_acc: 0.5991666666666666, Test Loss: 2.592298448085785, Test acc: 44.166666666666664\n",
      "Train Loss: 1.257375133037567, Train_acc: 0.6275, Test Loss: 2.562231421470642, Test acc: 42.916666666666664\n",
      "Train Loss: 1.1532318234443664, Train_acc: 0.6683333333333333, Test Loss: 3.138120412826538, Test acc: 43.75\n",
      "Train Loss: 1.0784940123558044, Train_acc: 0.6725, Test Loss: 3.0130796432495117, Test acc: 43.333333333333336\n",
      "Train Loss: 0.9939927816390991, Train_acc: 0.7, Test Loss: 4.1229201555252075, Test acc: 46.666666666666664\n",
      "Train Loss: 0.972756290435791, Train_acc: 0.72, Test Loss: 4.773910284042358, Test acc: 38.333333333333336\n",
      "Train Loss: 1.3622495174407958, Train_acc: 0.6241666666666666, Test Loss: 2.4131473302841187, Test acc: 44.583333333333336\n",
      "Train Loss: 1.1229125559329987, Train_acc: 0.665, Test Loss: 2.5836575031280518, Test acc: 46.25\n",
      "Train Loss: 0.9758598566055298, Train_acc: 0.6991666666666667, Test Loss: 4.034003257751465, Test acc: 45.416666666666664\n",
      "Train Loss: 0.8809797108173371, Train_acc: 0.7091666666666666, Test Loss: 4.775081753730774, Test acc: 44.583333333333336\n",
      "Train Loss: 0.9422463238239288, Train_acc: 0.7191666666666666, Test Loss: 4.826853513717651, Test acc: 46.25\n",
      "Train Loss: 0.9924384236335755, Train_acc: 0.7266666666666667, Test Loss: 4.212681412696838, Test acc: 48.75\n",
      "Train Loss: 0.9913378357887268, Train_acc: 0.725, Test Loss: 3.8543649911880493, Test acc: 46.666666666666664\n",
      "Fold 3\n",
      "Train Loss: 2.553145956993103, Train_acc: 0.125, Test Loss: 2.47074818611145, Test acc: 7.916666666666666\n",
      "Train Loss: 2.484616231918335, Train_acc: 0.12583333333333332, Test Loss: 2.421732544898987, Test acc: 21.666666666666668\n",
      "Train Loss: 2.284190320968628, Train_acc: 0.2608333333333333, Test Loss: 2.362913131713867, Test acc: 26.25\n",
      "Train Loss: 2.138972043991089, Train_acc: 0.335, Test Loss: 2.273944139480591, Test acc: 26.25\n",
      "Train Loss: 1.8385292768478394, Train_acc: 0.4483333333333333, Test Loss: 2.4055875539779663, Test acc: 32.916666666666664\n",
      "Train Loss: 1.505008828639984, Train_acc: 0.5275, Test Loss: 2.4270776510238647, Test acc: 36.25\n",
      "Train Loss: 1.427746868133545, Train_acc: 0.5941666666666666, Test Loss: 2.2298253774642944, Test acc: 35.833333333333336\n",
      "Train Loss: 1.2033229291439056, Train_acc: 0.6516666666666666, Test Loss: 3.0709025263786316, Test acc: 36.666666666666664\n",
      "Train Loss: 1.0932104408740997, Train_acc: 0.6766666666666666, Test Loss: 4.495207190513611, Test acc: 37.083333333333336\n",
      "Train Loss: 1.2616306126117707, Train_acc: 0.6633333333333333, Test Loss: 2.396166741847992, Test acc: 36.25\n",
      "Train Loss: 1.1673271536827088, Train_acc: 0.6808333333333333, Test Loss: 3.5520421266555786, Test acc: 38.75\n",
      "Train Loss: 1.1206090033054352, Train_acc: 0.6825, Test Loss: 3.251874566078186, Test acc: 39.166666666666664\n",
      "Train Loss: 1.2532746613025665, Train_acc: 0.7066666666666667, Test Loss: 3.0358731746673584, Test acc: 39.58333333333333\n",
      "Train Loss: 1.1360315263271332, Train_acc: 0.695, Test Loss: 2.651867628097534, Test acc: 37.083333333333336\n",
      "Train Loss: 1.0059270322322846, Train_acc: 0.7133333333333334, Test Loss: 3.715033173561096, Test acc: 38.333333333333336\n",
      "Train Loss: 0.9054890215396881, Train_acc: 0.7258333333333333, Test Loss: 4.970216870307922, Test acc: 38.75\n",
      "Train Loss: 1.0610075056552888, Train_acc: 0.7275, Test Loss: 4.431901812553406, Test acc: 38.75\n",
      "Train Loss: 0.9142156720161438, Train_acc: 0.7341666666666666, Test Loss: 3.40893292427063, Test acc: 40.0\n",
      "Train Loss: 0.8855226039886475, Train_acc: 0.7433333333333333, Test Loss: 5.3240790367126465, Test acc: 41.25\n",
      "Train Loss: 0.883112108707428, Train_acc: 0.7425, Test Loss: 6.165318965911865, Test acc: 41.25\n",
      "Fold 4\n",
      "Train Loss: 2.5634938955307005, Train_acc: 0.08416666666666667, Test Loss: 2.469657778739929, Test acc: 15.0\n",
      "Train Loss: 2.534844970703125, Train_acc: 0.16, Test Loss: 2.4288829565048218, Test acc: 14.166666666666666\n",
      "Train Loss: 2.4512731552124025, Train_acc: 0.1825, Test Loss: 2.2889139652252197, Test acc: 20.833333333333336\n",
      "Train Loss: 2.2367791056632997, Train_acc: 0.29833333333333334, Test Loss: 2.7738428115844727, Test acc: 19.583333333333332\n",
      "Train Loss: 2.3959866523742677, Train_acc: 0.31083333333333335, Test Loss: 2.3084336519241333, Test acc: 19.583333333333332\n",
      "Train Loss: 2.0334284901618958, Train_acc: 0.36833333333333335, Test Loss: 2.3450571298599243, Test acc: 30.0\n",
      "Train Loss: 1.7407758116722107, Train_acc: 0.4791666666666667, Test Loss: 2.1651155948638916, Test acc: 35.0\n",
      "Train Loss: 1.5511009335517882, Train_acc: 0.5516666666666666, Test Loss: 2.217782497406006, Test acc: 37.916666666666664\n",
      "Train Loss: 1.2673636198043823, Train_acc: 0.6041666666666666, Test Loss: 3.029349684715271, Test acc: 42.916666666666664\n",
      "Train Loss: 1.3483216047286988, Train_acc: 0.6058333333333333, Test Loss: 2.447050929069519, Test acc: 37.916666666666664\n",
      "Train Loss: 1.3897960662841797, Train_acc: 0.5933333333333334, Test Loss: 2.081297755241394, Test acc: 41.66666666666667\n",
      "Train Loss: 1.1428454577922822, Train_acc: 0.6516666666666666, Test Loss: 3.2023704051971436, Test acc: 43.333333333333336\n",
      "Train Loss: 1.1235863089561462, Train_acc: 0.6708333333333333, Test Loss: 3.581562042236328, Test acc: 45.0\n",
      "Train Loss: 1.1032827079296113, Train_acc: 0.665, Test Loss: 2.9106684923171997, Test acc: 44.166666666666664\n",
      "Train Loss: 1.0397665441036223, Train_acc: 0.6816666666666666, Test Loss: 3.7040985822677612, Test acc: 47.91666666666667\n",
      "Train Loss: 0.9565585076808929, Train_acc: 0.6975, Test Loss: 4.825285077095032, Test acc: 46.666666666666664\n",
      "Train Loss: 0.9328932881355285, Train_acc: 0.7091666666666666, Test Loss: 5.136233568191528, Test acc: 45.416666666666664\n",
      "Train Loss: 1.1070720970630645, Train_acc: 0.6833333333333333, Test Loss: 3.9965556859970093, Test acc: 43.75\n",
      "Train Loss: 1.036659187078476, Train_acc: 0.6908333333333333, Test Loss: 3.3423174619674683, Test acc: 44.166666666666664\n",
      "Train Loss: 0.9566930770874024, Train_acc: 0.705, Test Loss: 5.209038019180298, Test acc: 42.916666666666664\n",
      "Fold 5\n",
      "Train Loss: 2.55818452835083, Train_acc: 0.10583333333333333, Test Loss: 2.479628324508667, Test acc: 8.75\n",
      "Train Loss: 2.503183960914612, Train_acc: 0.15416666666666667, Test Loss: 2.46530282497406, Test acc: 7.5\n",
      "Train Loss: 2.362368369102478, Train_acc: 0.20416666666666666, Test Loss: 2.4211111068725586, Test acc: 19.583333333333332\n",
      "Train Loss: 2.1206240177154543, Train_acc: 0.33416666666666667, Test Loss: 2.474224328994751, Test acc: 20.0\n",
      "Train Loss: 1.8099603533744812, Train_acc: 0.4475, Test Loss: 2.6867047548294067, Test acc: 27.083333333333332\n",
      "Train Loss: 1.582103717327118, Train_acc: 0.5091666666666667, Test Loss: 2.8091602325439453, Test acc: 36.25\n",
      "Train Loss: 1.5604054570198058, Train_acc: 0.5308333333333334, Test Loss: 2.295206665992737, Test acc: 38.75\n",
      "Train Loss: 1.267925775051117, Train_acc: 0.615, Test Loss: 3.1761356592178345, Test acc: 41.25\n",
      "Train Loss: 1.2013456046581268, Train_acc: 0.62, Test Loss: 2.375527262687683, Test acc: 40.0\n",
      "Train Loss: 1.1998870253562928, Train_acc: 0.6283333333333333, Test Loss: 2.999728202819824, Test acc: 43.75\n",
      "Train Loss: 1.0353328108787536, Train_acc: 0.6675, Test Loss: 4.364528179168701, Test acc: 43.75\n",
      "Train Loss: 1.1847102880477904, Train_acc: 0.6425, Test Loss: 2.846013069152832, Test acc: 38.75\n",
      "Train Loss: 1.1570802330970764, Train_acc: 0.6708333333333333, Test Loss: 2.747130870819092, Test acc: 44.583333333333336\n",
      "Train Loss: 1.0207275390625, Train_acc: 0.6825, Test Loss: 3.7429146766662598, Test acc: 45.416666666666664\n",
      "Train Loss: 1.0592129051685333, Train_acc: 0.6733333333333333, Test Loss: 3.1304078102111816, Test acc: 42.083333333333336\n",
      "Train Loss: 1.1181860983371734, Train_acc: 0.6891666666666667, Test Loss: 2.994546890258789, Test acc: 45.416666666666664\n",
      "Train Loss: 1.0214020431041717, Train_acc: 0.695, Test Loss: 3.5155516862869263, Test acc: 42.916666666666664\n",
      "Train Loss: 0.9420313775539398, Train_acc: 0.695, Test Loss: 4.281010031700134, Test acc: 43.75\n",
      "Train Loss: 0.8987975597381592, Train_acc: 0.7066666666666667, Test Loss: 5.361014366149902, Test acc: 44.583333333333336\n",
      "Train Loss: 0.9742670238018036, Train_acc: 0.7058333333333333, Test Loss: 5.221025466918945, Test acc: 44.583333333333336\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "X_train_v, X_test, y_train_v, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_train_v = torch.as_tensor(X_train_v, dtype=torch.float) # an alternative to torch.from_numpy\n",
    "y_train_v = torch.as_tensor(y_train_v, dtype=torch.float)\n",
    "X_test = torch.as_tensor(X_test, dtype=torch.float)\n",
    "y_test = torch.as_tensor(y_test, dtype=torch.float)\n",
    "splits=StratifiedKFold(n_splits=5,shuffle=True,random_state=99)\n",
    "train_dataset = TensorDataset(X_train_v, y_train_v)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "batch_size=128\n",
    "models = []\n",
    "history = {'fold':[], 'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc':[]}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(X_train_v,y_train_v)):\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "    t = pd.DataFrame(y_train_v[train_idx], columns = ['class']).reset_index()\n",
    "    idx = []\n",
    "    y_train = []\n",
    "    for i in range(0,num_labels):\n",
    "      idx += list(t[t['class']==i].sample(100,replace=True)['index'])\n",
    "      y_train += [i]*100\n",
    "    X_train = X_train_v[train_idx][idx]\n",
    "\n",
    "    t = pd.DataFrame(y_train_v[val_idx], columns = ['class']).reset_index()\n",
    "    idx = []\n",
    "    y_val = []\n",
    "    for i in range(0,num_labels):\n",
    "      # print(i)\n",
    "      if i in t['class'].values:\n",
    "          idx += list(t[t['class']==i].sample(20,replace=True)['index'])\n",
    "          y_val += [i]*20\n",
    "    X_val =  X_train_v[val_idx][idx]\n",
    "\n",
    "    X_train = torch.as_tensor(X_train, dtype=torch.float) # an alternative to torch.from_numpy\n",
    "    y_train = torch.as_tensor(y_train, dtype=torch.float).type(torch.LongTensor)\n",
    "    X_val = torch.as_tensor(X_val, dtype=torch.float)\n",
    "    y_val = torch.as_tensor(y_val, dtype=torch.float).type(torch.LongTensor)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "    \n",
    "    model = CNNModel(hiddenSize, numFilters, dropoutRate, activation).to('cuda')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(list(model.parameters()), lr=learningRate, momentum=momentum)\n",
    "    # optimizer = torch.optim.Adam(list(model.parameters()), lr=learningRate)\n",
    "    best_test = -np.inf\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(numEpochs):\n",
    "        train_loss, train_R2=train_epoch(model,device,train_dataloader,criterion,optimizer)\n",
    "        test_loss, test_R2=valid_epoch(model,device,test_dataloader,criterion)\n",
    "        history['fold'].append(fold)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['train_acc'].append(train_R2)\n",
    "        history['test_acc'].append(test_R2)   \n",
    "        if test_R2>best_test:\n",
    "            test_test = test_R2\n",
    "            best_model = model\n",
    "        print('Train Loss: {}, Train_acc: {}, Test Loss: {}, Test acc: {}'.format(train_loss, train_R2, test_loss, test_R2))\n",
    "    models.append([best_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_v, X_test, y_train_v, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "t = pd.DataFrame(y_test, columns = ['class']).reset_index()\n",
    "idx = []\n",
    "y_test = []\n",
    "for i in range(0,11):\n",
    "    if i in t['class'].values:\n",
    "        idx += list(t[t['class']==i].sample(20,replace=True)['index'])\n",
    "        y_test += [i]*20\n",
    "X_test =  X_test[idx]\n",
    "X_test = torch.as_tensor(X_test, dtype=torch.float)\n",
    "y_test = torch.as_tensor(y_test, dtype=torch.float).type(torch.LongTensor)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "acc=[]\n",
    "for best_model in models:\n",
    "    acc.append(valid_epoch(best_model[0],device,test_dataloader,criterion)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.27272727272727"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(models,device,dataloader,loss_fn):\n",
    "    outputs = []    \n",
    "    for model in models:\n",
    "      model[0].eval()\n",
    "      model_output = []\n",
    "      for inputs, labels in dataloader:\n",
    "          inputs = inputs.to('cuda').reshape(-1,512,128)\n",
    "          labels = labels.to('cuda')\n",
    "          cnnOutputs = model[0](inputs)\n",
    "          model_output.append(cnnOutputs)\n",
    "      outputs.append(torch.tensor(model_output))\n",
    "\n",
    "    # totalLoss = 0\n",
    "    # total = 0\n",
    "    # total1 = 0\n",
    "    # R2 = 0\n",
    "    # cnnLoss = 0\n",
    "    # cnnCorrect=0\n",
    "    # cnnLoss = criterion(cnnOutputs, labels)\n",
    "    # _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n",
    "    # total += labels.size(0)\n",
    "    # total1 +=1\n",
    "    # totalLoss += cnnLoss.item()\n",
    "    # cnnCorrect += (cnnPredicted == labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = []    \n",
    "for model in models:\n",
    "  model[0].eval()\n",
    "  model_output = []\n",
    "  label_= []\n",
    "  model[0].to('cpu')\n",
    "  for inputs, labels in test_dataloader:\n",
    "      inputs = inputs.to('cpu').reshape(-1,1,512,128)\n",
    "      labels = labels.to('cpu')\n",
    "      cnnOutputs = model[0](inputs)\n",
    "      model_output.append(cnnOutputs)\n",
    "      label_.append(labels)\n",
    "  outputs.append(torch.vstack(model_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([220, 12])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = outputs[0].shape\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnnresult = torch.vstack(outputs).reshape(-1,shape[0],shape[1]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = np.hstack(label_)\n",
    "_, cnnPredicted = torch.max(cnnresult.data, 1)\n",
    "cnnCorrect = (cnnPredicted.detach().numpy() == labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.54545454545454"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnnCorrect/len(labels)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confu_m = confusion_matrix(labels, cnnPredicted)\n",
    "import seaborn as sns\n",
    "sns.heatmap(confu_m,square=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry': 0,\n",
       " 'awe': 1,\n",
       " 'emotional': 2,\n",
       " 'excited': 3,\n",
       " 'fear': 4,\n",
       " 'happy': 5,\n",
       " 'hopeful': 6,\n",
       " 'hurt': 7,\n",
       " 'love': 8,\n",
       " 'negative': 9,\n",
       " 'positive': 10,\n",
       " 'sadness': 11}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {}\n",
    "for cl in le.classes_:\n",
    "    label_dict.update({cl:le.transform([cl])[0]})\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angry</th>\n",
       "      <th>awe</th>\n",
       "      <th>emotional</th>\n",
       "      <th>excited</th>\n",
       "      <th>fear</th>\n",
       "      <th>happy</th>\n",
       "      <th>hopeful</th>\n",
       "      <th>hurt</th>\n",
       "      <th>love</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.45000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.377358</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.62069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>10.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               angry   awe  emotional    excited       fear      happy  \\\n",
       "precision   0.550000   1.0   0.750000   0.650000   1.000000   0.600000   \n",
       "recall      0.846154   1.0   0.600000   1.000000   0.377358   0.333333   \n",
       "f1          0.666667   1.0   0.666667   0.787879   0.547945   0.428571   \n",
       "support    13.000000  20.0  25.000000  13.000000  53.000000  36.000000   \n",
       "\n",
       "           hopeful  hurt       love   negative  positive  sadness  \n",
       "precision  0.45000   0.0   0.350000   0.200000      0.45      0.0  \n",
       "recall     1.00000   0.0   0.368421   0.333333      0.90      0.0  \n",
       "f1         0.62069   0.0   0.358974   0.250000      0.60      0.0  \n",
       "support    9.00000   0.0  19.000000  12.000000     10.00     10.0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "scores = pd.DataFrame(precision_recall_fscore_support(cnnPredicted, labels, labels = list(range(12))),index=['precision','recall','f1','support'], columns = list(label_dict)[:12])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open('midi_test_data','rb')\n",
    "music_data = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test_1 = []\n",
    "name = []\n",
    "for m in music_data:\n",
    "    if m[0].shape[0]>=612:\n",
    "        X_test_1.append(m[0][100:612,:])\n",
    "        name.append(m[1])\n",
    "X_test_1 = np.array(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 512, 128)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test_1 = models[0][0](torch.as_tensor(X_test_1.reshape(-1,1,512,128), dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Across_The_Stars(StarWar_II_Love_Theme) angry happy fear\n",
      "PAL1_theme-仙剑1 sadness fear excited\n",
      "上海滩 sadness angry happy\n",
      "月光奏鸣曲 angry happy awe\n",
      "枉凝眉 angry awe happy\n",
      "水调歌头·明月几时有 sadness fear love\n",
      "沧海一声笑 sadness angry positive\n",
      "笑傲江湖 sadness excited angry\n",
      "铁血丹心 sadness angry excited\n",
      "难念的经-天龙八部 sadness awe excited\n",
      "青花瓷 sadness angry happy\n"
     ]
    }
   ],
   "source": [
    "label = torch.argsort(-y_test_1).to('cpu').numpy()\n",
    "for i in range(len(label)):\n",
    "    print(name[i],le.classes_[label[i][0]], le.classes_[label[i][1]], le.classes_[label[i][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WzuA94i88EpO",
    "outputId": "39fb0326-c3dd-42d7-b1ea-7c5f690b9541",
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cnn\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      2\u001b[0m cnnCorrect \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      3\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cnn' is not defined"
     ]
    }
   ],
   "source": [
    "cnn.eval()\n",
    "cnnCorrect = 0\n",
    "total = 0\n",
    "for inputs, labels in test_dataloader:\n",
    "    inputs = inputs.to('cuda').reshape(-1,1,512,128)\n",
    "    labels = labels.to('cuda')\n",
    "    cnnOutputs = cnn(inputs)\n",
    "    _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    cnnCorrect += np.sum([labels[i] in torch.argsort(cnnOutputs)[:, -4:][i] for i in range(len(labels))])\n",
    "print('CNN validation accuracy: {}%'.format(cnnCorrect / total * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRRi_Ai2_jU7",
    "outputId": "d22defa3-b353-4960-b27e-ed65f1af9d9e",
    "tags": []
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 588.00 MiB (GPU 0; 31.74 GiB total capacity; 28.79 GiB already allocated; 464.31 MiB free; 30.88 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m512\u001b[39m,\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m     12\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m cnnOutputs \u001b[38;5;241m=\u001b[39m best_model[\u001b[38;5;241m0\u001b[39m](inputs)\n\u001b[1;32m     14\u001b[0m _, cnnPredicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(cnnOutputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[7], line 21\u001b[0m, in \u001b[0;36mCNNModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x))))\n\u001b[1;32m     22\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv4(x)))\n\u001b[1;32m     23\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv5(x)))\n",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 588.00 MiB (GPU 0; 31.74 GiB total capacity; 28.79 GiB already allocated; 464.31 MiB free; 30.88 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = []\n",
    "f,axes = plt.subplots(1,5, figsize=(20,4))\n",
    "for i, best_model in enumerate(models):\n",
    "    best_model[0].eval()\n",
    "    best_model[0].to('cuda')\n",
    "    cnnCorrect = 0\n",
    "    total = 0\n",
    "    pred = []\n",
    "    t_label = []\n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs = inputs.to('cuda').reshape(-1,1,512,128)\n",
    "        labels = labels.to('cuda')\n",
    "        cnnOutputs = best_model[0](inputs)\n",
    "        _, cnnPredicted = torch.max(cnnOutputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        t_label += labels.tolist()\n",
    "        pred += cnnOutputs.tolist()\n",
    "        cnnCorrect += np.sum([labels[i] in torch.argsort(cnnOutputs)[:, -3:][i] for i in range(len(labels))])\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    confu_m = confusion_matrix(t_label, pred)\n",
    "    import seaborn as sns\n",
    "    sns.heatmap(confu_m,square=False, ax=axes[i])\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    scores.append([pd.DataFrame(precision_recall_fscore_support(pred, t_label, labels = list(range(12))),index=['precision','recall','f1','support'], columns = list(label_dict)[:12])])\n",
    "    # scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>angry</th>\n",
       "      <th>awe</th>\n",
       "      <th>emotional</th>\n",
       "      <th>excited</th>\n",
       "      <th>fear</th>\n",
       "      <th>happy</th>\n",
       "      <th>hopeful</th>\n",
       "      <th>hurt</th>\n",
       "      <th>love</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>sadness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.45000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.115942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.179775</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.62069</td>\n",
       "      <td>0.464286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               angry  awe  emotional    excited      fear      happy  hopeful  \\\n",
       "precision   0.500000  0.0   0.250000   1.000000  0.200000   0.400000      0.0   \n",
       "recall      0.833333  0.0   0.833333   0.277778  1.000000   0.115942      0.0   \n",
       "f1          0.625000  0.0   0.384615   0.434783  0.333333   0.179775      0.0   \n",
       "support    12.000000  0.0   6.000000  72.000000  4.000000  69.000000      0.0   \n",
       "\n",
       "           hurt       love   negative  positive    sadness  \n",
       "precision   0.0   0.200000   0.500000   0.45000   0.650000  \n",
       "recall      0.0   0.400000   0.454545   1.00000   0.361111  \n",
       "f1          0.0   0.266667   0.476190   0.62069   0.464286  \n",
       "support     0.0  10.000000  22.000000   9.00000  36.000000  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "z3xGBJynBQ-x",
    "outputId": "7a5e350b-f83e-449c-9d10-ab38a7621f49",
    "tags": []
   },
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m----> 2\u001b[0m pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(pred, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m confu_m \u001b[38;5;241m=\u001b[39m confusion_matrix(t_label, pred)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/numpy/core/fromnumeric.py:1242\u001b[0m, in \u001b[0;36margmax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m-> 1242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margmax\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred = np.argmax(pred, axis=1)\n",
    "confu_m = confusion_matrix(t_label, pred)\n",
    "import seaborn as sns\n",
    "sns.heatmap(confu_m,square=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kn0NCC2dCrTx",
    "outputId": "f2918339-1f7c-487a-ba9d-70d8c0851c76",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry': 0,\n",
       " 'awe': 1,\n",
       " 'emotional': 2,\n",
       " 'excited': 3,\n",
       " 'fear': 4,\n",
       " 'happy': 5,\n",
       " 'hopeful': 6,\n",
       " 'hurt': 7,\n",
       " 'love': 8,\n",
       " 'negative': 9,\n",
       " 'positive': 10,\n",
       " 'sadness': 11}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {}\n",
    "for cl in le.classes_:\n",
    "    label_dict.update({cl:le.transform([cl])[0]})\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5ECh6NJTDAZI",
    "outputId": "f91a6302-758d-4401-b469-b906f6d63ab4",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4266666666666667"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = (np.array(t_label)!=16)\n",
    "(pred[idx] == np.array(t_label)[idx]).sum()/len(pred[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "GWGJSFyoDnzh",
    "outputId": "4ed5e9ca-e9cf-44a7-b6e3-ef34729e57fa",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "12 columns passed, passed data had 15 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/pandas/core/internals/construction.py:969\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/pandas/core/internals/construction.py:1017\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[0;32m-> 1017\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m   1018\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1019\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_mi_list:\n\u001b[1;32m   1022\u001b[0m \n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 12 columns passed, passed data had 15 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_recall_fscore_support\n\u001b[0;32m----> 2\u001b[0m scores \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(precision_recall_fscore_support(pred, t_label, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m15\u001b[39m))),index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupport\u001b[39m\u001b[38;5;124m'\u001b[39m], columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(label_dict)[:\u001b[38;5;241m15\u001b[39m])\n\u001b[1;32m      3\u001b[0m scores\n",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/pandas/core/frame.py:746\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    745\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 746\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m nested_data_to_arrays(\n\u001b[1;32m    747\u001b[0m         \u001b[38;5;66;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;00m\n\u001b[1;32m    748\u001b[0m         \u001b[38;5;66;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;00m\n\u001b[1;32m    749\u001b[0m         data,\n\u001b[1;32m    750\u001b[0m         columns,\n\u001b[1;32m    751\u001b[0m         index,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    752\u001b[0m         dtype,\n\u001b[1;32m    753\u001b[0m     )\n\u001b[1;32m    754\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    755\u001b[0m         arrays,\n\u001b[1;32m    756\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    759\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    760\u001b[0m     )\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/pandas/core/internals/construction.py:510\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[0;32m--> 510\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m to_arrays(data, columns, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    511\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/pandas/core/internals/construction.py:875\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    872\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m    873\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m--> 875\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m _finalize_columns_and_data(arr, columns, dtype)\n\u001b[1;32m    876\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[0;32m/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda/lib/python3.11/site-packages/pandas/core/internals/construction.py:972\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    969\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[0;32m--> 972\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[1;32m    975\u001b[0m     contents \u001b[38;5;241m=\u001b[39m _convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: 12 columns passed, passed data had 15 columns"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "scores = pd.DataFrame(precision_recall_fscore_support(pred, t_label, labels = list(range(15))),index=['precision','recall','f1','support'], columns = list(label_dict)[:15])\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4sI6ilxkD0ZB",
    "outputId": "8dc8ccbe-ffa8-4cdb-d789-aac99c79a484",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "precision     0.426667\n",
       "recall        0.533124\n",
       "f1            0.430355\n",
       "support      20.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CtA905R9OigX"
   },
   "outputs": [],
   "source": [
    "echo 'export PATH=\"/mnt/storage/CIIP_group/Postdoc/Aiqi_Sun/anaconda3/bin:$PATH\"' >> ~/.bashrc"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
